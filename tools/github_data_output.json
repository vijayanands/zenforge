{
  "Sud0x67": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25559",
        "id": 2605852725,
        "number": 25559,
        "state": "open",
        "title": "[FLINK-36502] [TABLE-SQL] Remove deprecated methods in FactoryUtil.",
        "body": "## What is the purpose of the change\r\n\r\n[[FLINK-36476](https://issues.apache.org/jira/browse/FLINK-36476)](https://issues.apache.org/jira/browse/FLINK-36476) Remove all deprecated methods under public APIs in table modules\r\n\r\nsubtask:\r\n\r\n[FLINK-36502](https://issues.apache.org/jira/browse/FLINK-36502) Remove all deprecated methods in `FactoryUtil`\r\n\r\n\r\n## Brief change log\r\n\r\nRemove deprecated methods\r\n\r\n\r\n## Verifying this change\r\n\r\n\r\nThis change is already covered by existing tests, see *org.apache.flink.table.factories.FactoryUtilTest*.\r\n\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): (no)\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes)\r\n  - The serializers: ( no)\r\n  - The runtime per-record code paths (performance sensitive): ( no )\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: (no)\r\n  - The S3 file system connector: (no)\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? (no)\r\n",
        "labels": [
          {
            "id": 1289893384,
            "name": "component=TableSQL/API",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-22T15:50:30Z",
        "updated_at": "2024-10-22T17:24:06Z",
        "closed_at": null,
        "merged_at": null
      }
    ]
  },
  "ferenc-csaky": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25558",
        "id": 2605459363,
        "number": 25558,
        "state": "open",
        "title": "[BP-1.19][docs] Update Java 17 compatibility docs",
        "body": "Trivial docs backport of https://github.com/apache/flink/pull/25342 to `release-1.19`.",
        "labels": [],
        "milestone": null,
        "created_at": "2024-10-22T13:26:25Z",
        "updated_at": "2024-10-22T15:24:48Z",
        "closed_at": null,
        "merged_at": null
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25557",
        "id": 2605451206,
        "number": 25557,
        "state": "open",
        "title": "[BP-1.20][docs] Update Java 17 compatibility docs",
        "body": "Trivial docs backport of https://github.com/apache/flink/pull/25342 to `release-1.20`.",
        "labels": [],
        "milestone": null,
        "created_at": "2024-10-22T13:23:18Z",
        "updated_at": "2024-10-22T15:29:48Z",
        "closed_at": null,
        "merged_at": null
      }
    ],
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25550#discussion_r1808220796",
        "pull_request_review_id": 2381124339,
        "id": 1808220796,
        "commit_id": "7b6668395240827901e226cd5c5d9e1a03ae0722",
        "original_commit_id": "68c5b4e99d71672271e9bf2d631b6c2d7f54c315",
        "in_reply_to_id": null,
        "body": "This should be changed to `4.1.91.Final` according to the [root POM](https://github.com/apache/flink/blob/60cba350d7638592ea771dc7cf512798e6248886/pom.xml#L369C14-L369C26).",
        "created_at": "2024-10-21T07:10:14Z"
      }
    ]
  },
  "wForget": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25556",
        "id": 2604530704,
        "number": 25556,
        "state": "open",
        "title": "[FLINK-25546][FOLLOWUP] Fix illegal file name",
        "body": "<!--\r\n*Thank you very much for contributing to Apache Flink - we are happy that you want to help us improve Flink. To help the community review your contribution in the best possible way, please go through the checklist below, which will get the contribution into a shape in which it can be best reviewed.*\r\n\r\n*Please understand that we do not do this to make contributions to Flink a hassle. In order to uphold a high standard of quality for code contributions, while at the same time managing a large number of contributions, we need contributors to prepare the contributions well, and give reviewers enough contextual information for the review. Please also understand that contributions that do not follow this guide will take longer to review and thus typically be picked up with lower priority by the community.*\r\n\r\n## Contribution Checklist\r\n\r\n  - Make sure that the pull request corresponds to a [JIRA issue](https://issues.apache.org/jira/projects/FLINK/issues). Exceptions are made for typos in JavaDoc or documentation files, which need no JIRA issue.\r\n  \r\n  - Name the pull request in the form \"[FLINK-XXXX] [component] Title of the pull request\", where *FLINK-XXXX* should be replaced by the actual issue number. Skip *component* if you are unsure about which is the best component.\r\n  Typo fixes that have no associated JIRA issue should be named following this pattern: `[hotfix] [docs] Fix typo in event time introduction` or `[hotfix] [javadocs] Expand JavaDoc for PuncuatedWatermarkGenerator`.\r\n\r\n  - Fill out the template below to describe the changes contributed by the pull request. That will give reviewers the context they need to do the review.\r\n  \r\n  - Make sure that the change passes the automated tests, i.e., `mvn clean verify` passes. You can set up Azure Pipelines CI to do that following [this guide](https://cwiki.apache.org/confluence/display/FLINK/Azure+Pipelines#AzurePipelines-Tutorial:SettingupAzurePipelinesforaforkoftheFlinkrepository).\r\n\r\n  - Each pull request should address only one issue, not mix up code from multiple issues.\r\n  \r\n  - Each commit in the pull request has a meaningful commit message (including the JIRA id)\r\n\r\n  - Once all items of the checklist are addressed, remove the above text and this checklist, leaving only the filled out template below.\r\n\r\n\r\n**(The sections below can be removed for hotfixes of typos)**\r\n-->\r\n\r\n## What is the purpose of the change\r\n\r\nI get an error when I run 'git rebase upstream/master' on windows:\r\n\r\n```\r\nerror: invalid path 'flink-connectors/flink-connector-base/src/test/resources/META-INF/services/org.junit.jupiter.api.extension.Extension '\r\nerror: could not detach HEAD\r\n```\r\n\r\nThe error is caused by the `org.junit.jupiter.api.extension.Extension` file name having a space, and this change was introduced in #21161\r\n\r\n## Brief change log\r\n\r\nRename `org.junit.jupiter.api.extension.Extension` to remove a space\r\n\r\n\r\n## Verifying this change\r\n\r\nminor fix\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\nno\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? no\r\n",
        "labels": [
          {
            "id": 1273164140,
            "name": "component=Tests",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-22T07:28:58Z",
        "updated_at": "2024-10-23T02:08:24Z",
        "closed_at": null,
        "merged_at": null
      }
    ]
  },
  "atu-sharm": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25555",
        "id": 2604297377,
        "number": 25555,
        "state": "open",
        "title": "FLINK-36506: Remove all deprecated methods in `ColumnStats`",
        "body": "<!--\r\n*Thank you very much for contributing to Apache Flink - we are happy that you want to help us improve Flink. To help the community review your contribution in the best possible way, please go through the checklist below, which will get the contribution into a shape in which it can be best reviewed.*\r\n\r\n*Please understand that we do not do this to make contributions to Flink a hassle. In order to uphold a high standard of quality for code contributions, while at the same time managing a large number of contributions, we need contributors to prepare the contributions well, and give reviewers enough contextual information for the review. Please also understand that contributions that do not follow this guide will take longer to review and thus typically be picked up with lower priority by the community.*\r\n\r\n## Contribution Checklist\r\n\r\n  - Make sure that the pull request corresponds to a [JIRA issue](https://issues.apache.org/jira/projects/FLINK/issues). Exceptions are made for typos in JavaDoc or documentation files, which need no JIRA issue.\r\n  \r\n  - Name the pull request in the form \"[FLINK-XXXX] [component] Title of the pull request\", where *FLINK-XXXX* should be replaced by the actual issue number. Skip *component* if you are unsure about which is the best component.\r\n  Typo fixes that have no associated JIRA issue should be named following this pattern: `[hotfix] [docs] Fix typo in event time introduction` or `[hotfix] [javadocs] Expand JavaDoc for PuncuatedWatermarkGenerator`.\r\n\r\n  - Fill out the template below to describe the changes contributed by the pull request. That will give reviewers the context they need to do the review.\r\n  \r\n  - Make sure that the change passes the automated tests, i.e., `mvn clean verify` passes. You can set up Azure Pipelines CI to do that following [this guide](https://cwiki.apache.org/confluence/display/FLINK/Azure+Pipelines#AzurePipelines-Tutorial:SettingupAzurePipelinesforaforkoftheFlinkrepository).\r\n\r\n  - Each pull request should address only one issue, not mix up code from multiple issues.\r\n  \r\n  - Each commit in the pull request has a meaningful commit message (including the JIRA id)\r\n\r\n  - Once all items of the checklist are addressed, remove the above text and this checklist, leaving only the filled out template below.\r\n\r\n\r\n**(The sections below can be removed for hotfixes of typos)**\r\n-->\r\n\r\n## What is the purpose of the change\r\n\r\nRemoving all deprecated methods as per [FLINK-36506](https://issues.apache.org/jira/browse/FLINK-36506) in `ColumnStats`\r\n*(For example: This pull request makes task deployment go through the blob server, rather than through RPC. That way we avoid re-transferring them on each deployment (during recovery).)*\r\n\r\n\r\n## Brief change log\r\n\r\n*(for example:)*\r\n  - *The TaskInfo is stored in the blob store on job creation time as a persistent artifact*\r\n  - *Deployments RPC transmits only the blob storage reference*\r\n  - *TaskManagers retrieve the TaskInfo from the blob cache*\r\n\r\n\r\n## Verifying this change\r\n\r\nPlease make sure both new and modified tests in this PR follow [the conventions for tests defined in our code quality guide](https://flink.apache.org/how-to-contribute/code-style-and-quality-common/#7-testing).\r\n\r\n*(Please pick either of the following options)*\r\n\r\nThis change is a trivial rework / code cleanup without any test coverage.\r\n\r\n*(or)*\r\n\r\nThis change is already covered by existing tests, such as *(please describe tests)*.\r\n\r\n*(or)*\r\n\r\nThis change added tests and can be verified as follows:\r\n\r\n*(example:)*\r\n  - *Added integration tests for end-to-end deployment with large payloads (100MB)*\r\n  - *Extended integration test for recovery after master (JobManager) failure*\r\n  - *Added test that validates that TaskInfo is transferred only once across recoveries*\r\n  - *Manually verified the change by running a 4 node cluster with 2 JobManagers and 4 TaskManagers, a stateful streaming program, and killing one JobManager and two TaskManagers during the execution, verifying that recovery happens correctly.*\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): (yes / no)\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes / no)\r\n  - The serializers: (yes / no / don't know)\r\n  - The runtime per-record code paths (performance sensitive): (yes / no / don't know)\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: (yes / no / don't know)\r\n  - The S3 file system connector: (yes / no / don't know)\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? (yes / no)\r\n  - If yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)\r\n",
        "labels": [
          {
            "id": 1289893384,
            "name": "component=TableSQL/API",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-22T05:26:23Z",
        "updated_at": "2024-10-22T09:21:35Z",
        "closed_at": null,
        "merged_at": null
      }
    ]
  },
  "xiangyuf": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25554",
        "id": 2604295285,
        "number": 25554,
        "state": "open",
        "title": " [FLINK-36521][runtime] Introduce TtlAwareSerializer and TtlAwareSerializerSnapshot",
        "body": "## What is the purpose of the change\r\n\r\nIntroduce TtlAwareSerializer and TtlAwareSerializerSnapshot to resolve the compatibility check between ttlSerializer and original serializer\r\n\r\n\r\n## Brief change log\r\n\r\n*(for example:)*\r\n\r\n- Add serializer-snapshot and test-data for `TtlAwareSerializerUpgradeTest` \r\n- Introduce the implementation of `TtlAwareSerializer` and `TtlAwareSerializerSnapshot`\r\n- Introduce the implementation of `TtlAwareSerializerSnapshotWrapper`\r\n\r\n\r\n## Verifying this change\r\n\r\nThis change added tests and can be verified as follows:\r\n\r\n  - Added Unit Test in `TtlAwareSerializerTest`\r\n  - Added Unit Test in `TtlAwareSerializerTtlMigrationTest`\r\n  - Added Unit Test in `TtlAwareSerializerUpgradeTest`\r\n  - Added Unit Test in `TtlAwareSerializerSnapshotWrapperTest`\r\n\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): no\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: no\r\n  - The serializers: yes\r\n  - The runtime per-record code paths (performance sensitive): no\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: no\r\n  - The S3 file system connector: no\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? no",
        "labels": [
          {
            "id": 1273319732,
            "name": "component=Runtime/StateBackends",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-22T05:25:01Z",
        "updated_at": "2024-10-22T16:22:19Z",
        "closed_at": null,
        "merged_at": null
      }
    ]
  },
  "eaugene": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25553",
        "id": 2602790087,
        "number": 25553,
        "state": "open",
        "title": "[FLINK-36194][Runtime] Handle the Graceful close of ExecutionGraphInfoStore from ClusterEntrypoint",
        "body": "\r\n<!--\r\n*Thank you very much for contributing to Apache Flink - we are happy that you want to help us improve Flink. To help the community review your contribution in the best possible way, please go through the checklist below, which will get the contribution into a shape in which it can be best reviewed.*\r\n\r\n*Please understand that we do not do this to make contributions to Flink a hassle. In order to uphold a high standard of quality for code contributions, while at the same time managing a large number of contributions, we need contributors to prepare the contributions well, and give reviewers enough contextual information for the review. Please also understand that contributions that do not follow this guide will take longer to review and thus typically be picked up with lower priority by the community.*\r\n\r\n## Contribution Checklist\r\n\r\n  - Make sure that the pull request corresponds to a [JIRA issue](https://issues.apache.org/jira/projects/FLINK/issues). Exceptions are made for typos in JavaDoc or documentation files, which need no JIRA issue.\r\n  \r\n  - Name the pull request in the form \"[FLINK-XXXX] [component] Title of the pull request\", where *FLINK-XXXX* should be replaced by the actual issue number. Skip *component* if you are unsure about which is the best component.\r\n  Typo fixes that have no associated JIRA issue should be named following this pattern: `[hotfix] [docs] Fix typo in event time introduction` or `[hotfix] [javadocs] Expand JavaDoc for PuncuatedWatermarkGenerator`.\r\n\r\n  - Fill out the template below to describe the changes contributed by the pull request. That will give reviewers the context they need to do the review.\r\n  \r\n  - Make sure that the change passes the automated tests, i.e., `mvn clean verify` passes. You can set up Azure Pipelines CI to do that following [this guide](https://cwiki.apache.org/confluence/display/FLINK/Azure+Pipelines#AzurePipelines-Tutorial:SettingupAzurePipelinesforaforkoftheFlinkrepository).\r\n\r\n  - Each pull request should address only one issue, not mix up code from multiple issues.\r\n  \r\n  - Each commit in the pull request has a meaningful commit message (including the JIRA id)\r\n\r\n  - Once all items of the checklist are addressed, remove the above text and this checklist, leaving only the filled out template below.\r\n\r\n\r\n**(The sections below can be removed for hotfixes of typos)**\r\n-->\r\n\r\n## What is the purpose of the change\r\nThis fixes the race-condition of writing to a closed file in the cluster shutdown is triggered \r\n\r\n\r\n## Brief change log\r\n- removing the shutdown hook from `ExecutionGraphInfoStore` and waiting for the `ClusterEntrypoint` ( which holds an instance of  `ExecutionGraphInfoStore` ) to close it\r\n\r\n\r\n## Verifying this change\r\nThis change is already covered by existing tests\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): (no)\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)\r\n  - The serializers: (no)\r\n  - The runtime per-record code paths (performance sensitive): (no)\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: (no)\r\n  - The S3 file system connector: (no)\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? (no)\r\n  - If yes, how is the feature documented? (JavaDocs)\r\n",
        "labels": [
          {
            "id": 1272994322,
            "name": "component=Runtime/Coordination",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-21T14:47:01Z",
        "updated_at": "2024-10-21T18:11:59Z",
        "closed_at": null,
        "merged_at": null
      }
    ]
  },
  "noorall": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25552",
        "id": 2601743713,
        "number": 25552,
        "state": "open",
        "title": "[FLINK-36576][runtime] Improving amount-based data balancing distribution algorithm for DefaultVertexParallelismAndInputInfosDecider",
        "body": "## What is the purpose of the change\r\n\r\nCurrently, the DefaultVertexParallelismAndInputInfosDecider is able to implement a balanced distribution algorithm based on the amount of data and the number of subpartitions, however it also has some limitations:\r\n\r\n1. Currently, Decider selects the data distribution algorithm via the AllToAll or Pointwise attribute of the input, which limits the ability of the operator to dynamically modify the data distribution algorithm.\r\n2. Doesn't support data volume-based balanced distribution for Pointwise inputs.\r\n3. For AllToAll type inputs, it does not support splitting the data corresponding to the specific key, i.e., it cannot solve the data skewing caused by single-key hotspot.\r\n\r\nFor that we plan to introduce the following improvements:\r\n\r\n1. Introducing InterInputsKeyCorrelation and IntraInputKeyCorrelation to the input characterisation which allows the operator to flexibly choose the data balanced distribution algorithm.\r\n2. Introducing a data volume-based data balanced distribution algorithm for Pointwise inputs\r\n3. Introducing the ability to split data corresponding to the specific key to optimise AllToAll's data volume-based data balancing distribution algorithm.\r\n\r\n## Brief change log\r\n\r\n  - Introducing InterInputsKeyCorrelation and IntraInputKeyCorrelation.\r\n  - Introducing amount-based data balanced distribution algorithm for Pointwise.\r\n  - Introducing the ability to split data corresponding to the specific key for AllToAll\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): (no)\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)\r\n  - The serializers: (no)\r\n  - The runtime per-record code paths (performance sensitive): (no)\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: (no)\r\n  - The S3 file system connector: (no)\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? (no)\r\n  - If yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)\r\n",
        "labels": [
          {
            "id": 1272994322,
            "name": "component=Runtime/Coordination",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-21T08:18:21Z",
        "updated_at": "2024-10-23T03:32:14Z",
        "closed_at": null,
        "merged_at": null
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25551",
        "id": 2601693719,
        "number": 25551,
        "state": "open",
        "title": "[FLINK-36575][runtime] ExecutionVertexInputInfo supports consuming subpartition groups",
        "body": "## What is the purpose of the change\r\n\r\nCurrently, the ExecutionVertexInputInfo describes the task's input through a combination of a PartitionRange and a SubpartitionRange. However, in the case of skewed join optimization, we need to split a group of data corresponding to the specific key, which may result in a downstream task subscribing to multiple combinations of PartitionRanges and SubpartitionRanges.\r\n\r\nTherefore, we need to modify the ExecutionVertexInputInfo to describe the input data as multiple combinations of PartitionRanges and SubpartitionRanges to meet the requirements of the aforementioned scenario and improve Flink's flexibility in describing the task's inputs.\r\n\r\n\r\n## Brief change log\r\n\r\n  - Modify the description of the input in ExecutionVertexInputInfo.\r\n  - Modify the connect function for edges.\r\n  - Modify the InputGate creation logic of the network layer to adapt to this change.\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): (no)\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)\r\n  - The serializers: (no)\r\n  - The runtime per-record code paths (performance sensitive): (no)\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: (no)\r\n  - The S3 file system connector: (yes / no / don't know)\r\n\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? (no)\r\n  - If yes, how is the feature documented? (not documented)\r\n",
        "labels": [
          {
            "id": 1272994322,
            "name": "component=Runtime/Coordination",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-21T07:57:31Z",
        "updated_at": "2024-10-23T03:28:00Z",
        "closed_at": null,
        "merged_at": null
      }
    ]
  },
  "gracegrimwood": {
    "pull_requests": [
      {
        "html_url": "https://github.com/apache/flink/pull/25550",
        "id": 2600878287,
        "number": 25550,
        "state": "closed",
        "title": "[FLINK-36510][rpc] bump pekko to 1.1.2, remove netty 3 (backport to release-1.20)",
        "body": "<!--\r\n*Thank you very much for contributing to Apache Flink - we are happy that you want to help us improve Flink. To help the community review your contribution in the best possible way, please go through the checklist below, which will get the contribution into a shape in which it can be best reviewed.*\r\n\r\n*Please understand that we do not do this to make contributions to Flink a hassle. In order to uphold a high standard of quality for code contributions, while at the same time managing a large number of contributions, we need contributors to prepare the contributions well, and give reviewers enough contextual information for the review. Please also understand that contributions that do not follow this guide will take longer to review and thus typically be picked up with lower priority by the community.*\r\n\r\n## Contribution Checklist\r\n\r\n  - Make sure that the pull request corresponds to a [JIRA issue](https://issues.apache.org/jira/projects/FLINK/issues). Exceptions are made for typos in JavaDoc or documentation files, which need no JIRA issue.\r\n  \r\n  - Name the pull request in the form \"[FLINK-XXXX] [component] Title of the pull request\", where *FLINK-XXXX* should be replaced by the actual issue number. Skip *component* if you are unsure about which is the best component.\r\n  Typo fixes that have no associated JIRA issue should be named following this pattern: `[hotfix] [docs] Fix typo in event time introduction` or `[hotfix] [javadocs] Expand JavaDoc for PuncuatedWatermarkGenerator`.\r\n\r\n  - Fill out the template below to describe the changes contributed by the pull request. That will give reviewers the context they need to do the review.\r\n  \r\n  - Make sure that the change passes the automated tests, i.e., `mvn clean verify` passes. You can set up Azure Pipelines CI to do that following [this guide](https://cwiki.apache.org/confluence/display/FLINK/Azure+Pipelines#AzurePipelines-Tutorial:SettingupAzurePipelinesforaforkoftheFlinkrepository).\r\n\r\n  - Each pull request should address only one issue, not mix up code from multiple issues.\r\n  \r\n  - Each commit in the pull request has a meaningful commit message (including the JIRA id)\r\n\r\n  - Once all items of the checklist are addressed, remove the above text and this checklist, leaving only the filled out template below.\r\n\r\n\r\n**(The sections below can be removed for hotfixes of typos)**\r\n-->\r\n\r\n## What is the purpose of the change\r\n\r\nUpdates Pekko dependency to 1.1.2 which in turn upgrades Netty 3 to 4 (addressing [FLINK-29065](https://issues.apache.org/jira/browse/FLINK-29065) and removing several CVEs from Flink). Pekko 1.1 also upgrades other dependencies such as slf4j and Jackson. For more details see the [Pekko 1.1 release notes](https://pekko.apache.org/docs/pekko/current/release-notes/releases-1.1.html). CC @ferenc-csaky :smile:\r\n\r\n\r\n## Brief change log\r\n\r\n  - Update Pekko version from 1.0.1 to 1.1.2\r\n  - Replace Pekko Netty 3 dependency with flink-shaded Netty 4 (and test-scoped direct Netty 4 dependency)\r\n  - Update Netty imports in `ActorSystemBootstrapTools` and `PekkoUtils`\r\n  - Update NOTICE file\r\n\r\n\r\n## Verifying this change\r\n\r\nThis change is covered by existing tests in flink-rpc.\r\n\r\n## Does this pull request potentially affect one of the following parts:\r\n\r\n  - Dependencies (does it add or upgrade a dependency): yes\r\n  - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: no\r\n  - The serializers: no\r\n  - The runtime per-record code paths (performance sensitive): don't know\r\n  - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn, ZooKeeper: no\r\n  - The S3 file system connector: no\r\n## Documentation\r\n\r\n  - Does this pull request introduce a new feature? no\r\n  - If yes, how is the feature documented? not applicable",
        "labels": [
          {
            "id": 1272994322,
            "name": "component=Runtime/Coordination",
            "description": null
          }
        ],
        "milestone": null,
        "created_at": "2024-10-20T21:16:35Z",
        "updated_at": "2024-10-22T16:58:42Z",
        "closed_at": "2024-10-22T16:58:42Z",
        "merged_at": "2024-10-22T16:58:42Z"
      }
    ],
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25550#discussion_r1808227768",
        "pull_request_review_id": 2381136171,
        "id": 1808227768,
        "commit_id": "7b6668395240827901e226cd5c5d9e1a03ae0722",
        "original_commit_id": "68c5b4e99d71672271e9bf2d631b6c2d7f54c315",
        "in_reply_to_id": 1808220796,
        "body": "Nice catch! Changed this now :)",
        "created_at": "2024-10-21T07:16:02Z"
      }
    ],
    "commits": [
      {
        "sha": "a83f24f9926e4a2830db42adedbead5c9c55e44c",
        "html_url": "https://github.com/apache/flink/commit/a83f24f9926e4a2830db42adedbead5c9c55e44c",
        "message": "[FLINK-36510][rpc] Bump Pekko to 1.1.2, remove Netty 3\n\nSigned-off-by: Grace Grimwood <ggrimwoo@redhat.com>",
        "date": "2024-10-22T16:58:13Z"
      }
    ]
  },
  "twalthr": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/24981#discussion_r1808198097",
        "pull_request_review_id": 2381080608,
        "id": 1808198097,
        "commit_id": "bdb76285d78797c9e77b4e9c236c51e8fc1dd251",
        "original_commit_id": "bdb76285d78797c9e77b4e9c236c51e8fc1dd251",
        "in_reply_to_id": null,
        "body": "Please add a test.",
        "created_at": "2024-10-21T06:51:53Z"
      }
    ],
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/764da8183b6dfd0fe00eebe96fb619ca8d096047#r30030402",
        "id": 30030402,
        "body": "@zentol The test does a correct job. It assumes a library folder that contains a few SQL jars. The goal of SQL jars was to have uber jars that do not interfere with each other and to avoid having to deal with dependency conflicts. It is a problem of the built jar files. ",
        "commit_id": "764da8183b6dfd0fe00eebe96fb619ca8d096047",
        "created_at": "2018-08-10T07:23:35Z",
        "updated_at": "2018-08-10T07:23:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a17c2485469931b0460a81f9fa7dab9826c04884#r30972553",
        "id": 30972553,
        "body": "Introduce a constant in this class for \"key\".",
        "commit_id": "a17c2485469931b0460a81f9fa7dab9826c04884",
        "created_at": "2018-10-19T14:31:40Z",
        "updated_at": "2018-10-19T14:31:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a17c2485469931b0460a81f9fa7dab9826c04884#r30972570",
        "id": 30972570,
        "body": "nit: use `NO_CODE` constant.",
        "commit_id": "a17c2485469931b0460a81f9fa7dab9826c04884",
        "created_at": "2018-10-19T14:32:45Z",
        "updated_at": "2018-10-19T14:33:00Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a17c2485469931b0460a81f9fa7dab9826c04884#r30972766",
        "id": 30972766,
        "body": "We could remove the generics in the entire code generator. There are not checked by the compiler.",
        "commit_id": "a17c2485469931b0460a81f9fa7dab9826c04884",
        "created_at": "2018-10-19T14:44:44Z",
        "updated_at": "2018-10-19T14:44:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a17c2485469931b0460a81f9fa7dab9826c04884#r30973529",
        "id": 30973529,
        "body": "Please add a test for this change.",
        "commit_id": "a17c2485469931b0460a81f9fa7dab9826c04884",
        "created_at": "2018-10-19T15:31:31Z",
        "updated_at": "2018-10-19T15:31:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2923a4e68da8f6cc2c6b8d770e5df18f971226f3#r31104224",
        "id": 31104224,
        "body": "Don't we also need to update the final name as well?",
        "commit_id": "2923a4e68da8f6cc2c6b8d770e5df18f971226f3",
        "created_at": "2018-10-30T15:34:56Z",
        "updated_at": "2018-10-30T15:34:56Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2aa667f8ce48b0ad606063c7a6328c65f4713421#r45128265",
        "id": 45128265,
        "body": "this method is dangerous because it also returns computed and metadata columns, we should only allow persistable columns?",
        "commit_id": "2aa667f8ce48b0ad606063c7a6328c65f4713421",
        "created_at": "2020-12-15T08:32:38Z",
        "updated_at": "2020-12-15T08:32:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2aa667f8ce48b0ad606063c7a6328c65f4713421#r45128376",
        "id": 45128376,
        "body": "If you are confident that the node needs no further modification, I think is is fine to push it. But I would definitely not do it in some nested method, because it has side effects to the outer method.",
        "commit_id": "2aa667f8ce48b0ad606063c7a6328c65f4713421",
        "created_at": "2020-12-15T08:37:05Z",
        "updated_at": "2020-12-15T08:37:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2aa667f8ce48b0ad606063c7a6328c65f4713421#r45128461",
        "id": 45128461,
        "body": "I'm wondering why we need to split reordering and inserting casts in two steps? Can't we do this in one projection combined?",
        "commit_id": "2aa667f8ce48b0ad606063c7a6328c65f4713421",
        "created_at": "2020-12-15T08:40:22Z",
        "updated_at": "2020-12-15T08:40:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/439d1091daa12803268bb8ff7c0642bcc5f9127c#r137410612",
        "id": 137410612,
        "body": "@yunfengzhou-hub @reswqa This adds transitive dependencies and causes issues in the planner module https://github.com/apache/flink/pull/24138. Do we need this particular type of exception or can it be a generic IOException?",
        "commit_id": "439d1091daa12803268bb8ff7c0642bcc5f9127c",
        "created_at": "2024-01-19T05:14:26Z",
        "updated_at": "2024-01-19T05:14:26Z"
      }
    ]
  },
  "zhuzhurk": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25472#discussion_r1808402242",
        "pull_request_review_id": 2381430424,
        "id": 1808402242,
        "commit_id": "ccfc1576fade82064247df18509a7cef4a561f87",
        "original_commit_id": "eecbca0f1d78e402d033b61b2ef7f72dba912a9c",
        "in_reply_to_id": null,
        "body": "maybe\r\n```\r\n} else if (executionPlan instanceof StreamGraph) {\r\n...\r\n} else {\r\n    throw FlinkException(\"Unsupported execution plan \" + executionPlan.getClass().getCanonicalName());\r\n}\r\n```",
        "created_at": "2024-10-21T09:18:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25472#discussion_r1808632267",
        "pull_request_review_id": 2381430424,
        "id": 1808632267,
        "commit_id": "ccfc1576fade82064247df18509a7cef4a561f87",
        "original_commit_id": "eecbca0f1d78e402d033b61b2ef7f72dba912a9c",
        "in_reply_to_id": null,
        "body": "Comments above are for the original line.",
        "created_at": "2024-10-21T11:47:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25472#discussion_r1809056263",
        "pull_request_review_id": 2381430424,
        "id": 1809056263,
        "commit_id": "ccfc1576fade82064247df18509a7cef4a561f87",
        "original_commit_id": "eecbca0f1d78e402d033b61b2ef7f72dba912a9c",
        "in_reply_to_id": null,
        "body": "Is this method required? If not, we can keep `jobConfiguration` final.",
        "created_at": "2024-10-21T15:35:54Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25472#discussion_r1809082421",
        "pull_request_review_id": 2381430424,
        "id": 1809082421,
        "commit_id": "ccfc1576fade82064247df18509a7cef4a561f87",
        "original_commit_id": "eecbca0f1d78e402d033b61b2ef7f72dba912a9c",
        "in_reply_to_id": null,
        "body": "Looks to me the 2 lines above are unrelated to the serialization work.",
        "created_at": "2024-10-21T15:52:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25472#discussion_r1809101863",
        "pull_request_review_id": 2381430424,
        "id": 1809101863,
        "commit_id": "ccfc1576fade82064247df18509a7cef4a561f87",
        "original_commit_id": "eecbca0f1d78e402d033b61b2ef7f72dba912a9c",
        "in_reply_to_id": null,
        "body": "How about to ensure `JobCheckpointingSettings` is created right after `stateBackend` and `checkpointStorage` are set, and let it be the holder of `serializedStateBackend` and `serializedCheckpointStorage`? Looks to me it can simplify things a lot.",
        "created_at": "2024-10-21T16:06:00Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25472#discussion_r1810402076",
        "pull_request_review_id": 2384641932,
        "id": 1810402076,
        "commit_id": "ccfc1576fade82064247df18509a7cef4a561f87",
        "original_commit_id": "939377b3d021ac1534a8346e0d277057e89ff3cd",
        "in_reply_to_id": null,
        "body": "`createJobCheckpointingSettings()` should happen after setting `ENABLE_STATE_CHANGE_LOG`.\r\nI prefer to let the generator explicitly call  `createJobCheckpointingSettings()` in the end of `setBatchStateBackendAndTimerService()`.",
        "created_at": "2024-10-22T09:56:44Z"
      }
    ]
  },
  "tinaselenge": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25445#discussion_r1808630829",
        "pull_request_review_id": 2381803058,
        "id": 1808630829,
        "commit_id": "b8fb2923ad5c958a7af8664f536effb987aad16f",
        "original_commit_id": "cd62a86d0e197accda756e7c3de8c6085e1db9ef",
        "in_reply_to_id": 1794173964,
        "body": "good idea!",
        "created_at": "2024-10-21T11:46:46Z"
      }
    ]
  },
  "jnh5y": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/24699#discussion_r1809434479",
        "pull_request_review_id": 2383186284,
        "id": 1809434479,
        "commit_id": "0fee492a076714f17aa8548b94cb55c4f52fc446",
        "original_commit_id": "0fee492a076714f17aa8548b94cb55c4f52fc446",
        "in_reply_to_id": null,
        "body": "As a question, do we need to change all of the tests from using PROCTIME() to ts?\r\n\r\nE.g., can the existing behavior remain?",
        "created_at": "2024-10-21T19:56:06Z"
      }
    ],
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/1543c72455629842a9424aa11ea7641fb5d13760#r147198711",
        "id": 147198711,
        "body": "I'm not sure about this.",
        "commit_id": "1543c72455629842a9424aa11ea7641fb5d13760",
        "created_at": "2024-09-25T17:06:42Z",
        "updated_at": "2024-09-25T17:06:42Z"
      }
    ]
  },
  "yunfengzhou-hub": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25501#discussion_r1809757295",
        "pull_request_review_id": 2383625981,
        "id": 1809757295,
        "commit_id": "abb6a17cc035b7f0b282bdbb7b570464d23534f1",
        "original_commit_id": "abb6a17cc035b7f0b282bdbb7b570464d23534f1",
        "in_reply_to_id": null,
        "body": "Are there cases in which an operator needs to use async timer service and sync timer service simultaneously? I'm wondering if we could reduce `internalTimerServiceManager()` and `asyncInternalTimerServiceManager()` into one method, given that they have the same return type, and it might better help hiding implementation details from invokers.",
        "created_at": "2024-10-22T02:24:06Z"
      }
    ]
  },
  "fredia": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25501#discussion_r1809809121",
        "pull_request_review_id": 2383697713,
        "id": 1809809121,
        "commit_id": "abb6a17cc035b7f0b282bdbb7b570464d23534f1",
        "original_commit_id": "abb6a17cc035b7f0b282bdbb7b570464d23534f1",
        "in_reply_to_id": 1809757295,
        "body": "> Are there cases in which an operator needs to use async timer service and sync timer service simultaneously? \r\n\r\nNo, it is up to the developer to decide which one to use. \r\n\r\nThis is to keep it consistent with the current `asyncStateBackend` and `KeyedStateBackend`, we will sort out the relationship between `asyncStateBackend`/`keyedStateBackend`  and `asyncTimerManager`/`timerManager` in subsequent PR.",
        "created_at": "2024-10-22T03:49:10Z"
      }
    ],
    "commits": [
      {
        "sha": "039a07d09cf20f457ddc0d25beba434ca7f932fe",
        "html_url": "https://github.com/apache/flink/commit/039a07d09cf20f457ddc0d25beba434ca7f932fe",
        "message": "[FLINK-35029][state/forst] Store timer in JVM heap when use async state backend (#25501)",
        "date": "2024-10-23T03:17:22Z"
      }
    ]
  },
  "xuyangzhong": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/25418#discussion_r1810065899",
        "pull_request_review_id": 2384105085,
        "id": 1810065899,
        "commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "original_commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "in_reply_to_id": null,
        "body": "Can you check if opBinding is an instance of SqlCallBinding just like the if block below?\r\n\r\nWhat about ?\r\n```\r\n        boolean forceOutputTypeNullable = false;\r\n        if (opBinding instanceof SqlCallBinding\r\n                && ((SqlCallBinding) opBinding).getValidator()\r\n                        instanceof FlinkCalciteSqlValidator) {\r\n            FlinkCalciteSqlValidator validator =\r\n                    (FlinkCalciteSqlValidator) ((SqlCallBinding) opBinding).getValidator();\r\n\r\n            TableConfig tableConfig =\r\n                    ShortcutUtils.unwrapContext(validator.getRelOptCluster()).getTableConfig();\r\n            forceOutputTypeNullable =\r\n                    tableConfig\r\n                            .get(ExecutionConfigOptions.TABLE_EXEC_LEGACY_CAST_BEHAVIOUR)\r\n                            .isEnabled();\r\n        }\r\n\r\n        ret =\r\n                opBinding\r\n                        .getTypeFactory()\r\n                        .createTypeWithNullability(\r\n                                ret, firstType.isNullable() || forceOutputTypeNullable);\r\n```",
        "created_at": "2024-10-22T07:01:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25418#discussion_r1810079375",
        "pull_request_review_id": 2384105085,
        "id": 1810079375,
        "commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "original_commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "in_reply_to_id": null,
        "body": "Please include a note about this behavior in the class comment as well.",
        "created_at": "2024-10-22T07:11:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25418#discussion_r1810080838",
        "pull_request_review_id": 2384105085,
        "id": 1810080838,
        "commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "original_commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "in_reply_to_id": null,
        "body": "ditto. Avoid forced type casts to prevent unexpected errors.",
        "created_at": "2024-10-22T07:12:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25418#discussion_r1810106412",
        "pull_request_review_id": 2384105085,
        "id": 1810106412,
        "commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "original_commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "in_reply_to_id": null,
        "body": "nit: update the line number.",
        "created_at": "2024-10-22T07:24:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25418#discussion_r1810108405",
        "pull_request_review_id": 2384105085,
        "id": 1810108405,
        "commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "original_commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "in_reply_to_id": null,
        "body": "Add comments \r\n```\r\n// BEGIN FLINK MODIFICATION\r\n...\r\n// END FLINK MODIFICATION\r\n```",
        "created_at": "2024-10-22T07:25:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/25418#discussion_r1810111039",
        "pull_request_review_id": 2384105085,
        "id": 1810111039,
        "commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "original_commit_id": "be9baf03f2ffc39f31e46adcb5439d159d3ee79f",
        "in_reply_to_id": null,
        "body": "IIUC, you only tested runtime issues and did not test for constant folding issues, right?",
        "created_at": "2024-10-22T07:26:22Z"
      }
    ]
  },
  "dylanhz": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/24981#discussion_r1810623732",
        "pull_request_review_id": 2385034474,
        "id": 1810623732,
        "commit_id": "bdb76285d78797c9e77b4e9c236c51e8fc1dd251",
        "original_commit_id": "bdb76285d78797c9e77b4e9c236c51e8fc1dd251",
        "in_reply_to_id": 1808198097,
        "body": "A pull request regarding this issue has been merged (see [PR #25404](https://github.com/apache/flink/pull/25404)). However, I have some concerns about its solution. Could you please have a look?",
        "created_at": "2024-10-22T12:22:42Z"
      }
    ]
  },
  "dawidwys": {
    "pull_request_comments": [
      {
        "html_url": "https://github.com/apache/flink/pull/24699#discussion_r1811135576",
        "pull_request_review_id": 2385882794,
        "id": 1811135576,
        "commit_id": "0fee492a076714f17aa8548b94cb55c4f52fc446",
        "original_commit_id": "0fee492a076714f17aa8548b94cb55c4f52fc446",
        "in_reply_to_id": null,
        "body": "Do we need the sorting before the `MATCH` operator? Won't the sorting of `CepOperator` be enough?",
        "created_at": "2024-10-22T17:38:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/pull/24699#discussion_r1811139271",
        "pull_request_review_id": 2385888577,
        "id": 1811139271,
        "commit_id": "0fee492a076714f17aa8548b94cb55c4f52fc446",
        "original_commit_id": "0fee492a076714f17aa8548b94cb55c4f52fc446",
        "in_reply_to_id": 1811135576,
        "body": "I know this sorting is more performant in batch. Maybe we could disable the sorting in the `CepOperator`? Could we always run the `CepOperator` in processing time without a comparator in batch and depend on this `SortOperator`?",
        "created_at": "2024-10-22T17:41:15Z"
      }
    ],
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/a2533f406d46b1c5acb5f70c263f9afad839dffe#r27262545",
        "id": 27262545,
        "body": "You're right. Will create a hotfix PR, that removes it.",
        "commit_id": "a2533f406d46b1c5acb5f70c263f9afad839dffe",
        "created_at": "2018-02-01T13:50:34Z",
        "updated_at": "2018-02-01T13:50:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/71828fc8540c6693110a1a13850be9bd6e15fab3#commitcomment-31378792",
        "id": 31378792,
        "body": "Please ask such question either in ML or corresponding JIRA ticket. Yes it will be released with 1.7.0 version.",
        "commit_id": "71828fc8540c6693110a1a13850be9bd6e15fab3",
        "created_at": "2018-11-21T09:08:56Z",
        "updated_at": "2018-11-21T09:08:56Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d69528004bd7c361828c60ad78ec63f39e3122e4#r31976399",
        "id": 31976399,
        "body": "remove one empty line",
        "commit_id": "d69528004bd7c361828c60ad78ec63f39e3122e4",
        "created_at": "2019-01-17T15:15:28Z",
        "updated_at": "2019-01-17T15:15:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32021879",
        "id": 32021879,
        "body": "nit: How about we remove `hashCode` and use the one from `TypeSerializerSingleton`",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T13:40:45Z",
        "updated_at": "2019-01-22T13:40:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32021914",
        "id": 32021914,
        "body": "I don't know about all the implications of those change. Why can't we actually return a proper length for the data?",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T13:43:27Z",
        "updated_at": "2019-01-22T13:43:27Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32021954",
        "id": 32021954,
        "body": "Can we put a note that this field should actually be `final`. The only obstacle is the backward compatible deserialization logic.",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T13:46:40Z",
        "updated_at": "2019-01-22T13:46:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32021975",
        "id": 32021975,
        "body": "How about we accept `TypeSerializer<NodeId>` etc.?",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T13:48:17Z",
        "updated_at": "2019-01-22T13:48:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32021998",
        "id": 32021998,
        "body": "Isn't this commit missing resource files for this test?",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T13:50:43Z",
        "updated_at": "2019-01-22T13:50:43Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32022687",
        "id": 32022687,
        "body": "Correct.",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T14:37:53Z",
        "updated_at": "2019-01-22T14:37:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/810321d988a8284eb54c2963f22a049dc06ac8aa#r40871955",
        "id": 40871955,
        "body": "Shall we prefix it with `sink`? -> `sink.subject`",
        "commit_id": "810321d988a8284eb54c2963f22a049dc06ac8aa",
        "created_at": "2020-07-24T09:39:59Z",
        "updated_at": "2020-07-24T09:39:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/810321d988a8284eb54c2963f22a049dc06ac8aa#r40872020",
        "id": 40872020,
        "body": "I think we aimed to reduce the prefixes. Shouldn't it be just `url` or `schema-registry-url`.\r\nIn the case of subject I think we should not prefix it with `schema-registry`.\r\n\r\nHowever I am not good at coming up with the options therefore would like to hear what @wuchong or @twalthr think about this.",
        "commit_id": "810321d988a8284eb54c2963f22a049dc06ac8aa",
        "created_at": "2020-07-24T09:43:15Z",
        "updated_at": "2020-07-24T09:43:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/efc12ca13743c2562d297a511d82cbdccc718cd0#r45843592",
        "id": 45843592,
        "body": "Because that's the suggested way by Avro. Moreover that's the only way to make a field optional.",
        "commit_id": "efc12ca13743c2562d297a511d82cbdccc718cd0",
        "created_at": "2021-01-11T13:18:16Z",
        "updated_at": "2021-01-11T13:18:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/efc12ca13743c2562d297a511d82cbdccc718cd0#r45874322",
        "id": 45874322,
        "body": "Probably we could support both why not, I am not against it. I am sure though the current version should be the default one as it is the only one that allows for schema evolution (e.g. adding columns).",
        "commit_id": "efc12ca13743c2562d297a511d82cbdccc718cd0",
        "created_at": "2021-01-12T09:08:06Z",
        "updated_at": "2021-01-12T09:08:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7de4b6452df09aee2ceb0b9b242bdf9f21301ece#r133252356",
        "id": 133252356,
        "body": "nit: `AfterRestoreState` -> `AfterRestoreSource`\r\n\r\nThe enum name already contains the `AfterRestore` prefix, we can drop it from the enum values:\r\n\r\n```\r\nAfterRestoreSource.FINITE or AfterRestoreSource.INFINITE\r\n```",
        "commit_id": "7de4b6452df09aee2ceb0b9b242bdf9f21301ece",
        "created_at": "2023-11-22T12:40:42Z",
        "updated_at": "2023-11-22T12:40:42Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/74f3b69430d7f55fb385d1463e71dbbb8142a29f#r134235906",
        "id": 134235906,
        "body": "Could you please adapt the id according to the javadoc:\r\nhttps://github.com/apache/flink/blob/52d8d3583e5c989da84126a8805ab335408c46c2/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/test/program/TableTestProgram.java#L117\r\n?",
        "commit_id": "74f3b69430d7f55fb385d1463e71dbbb8142a29f",
        "created_at": "2023-12-05T13:34:47Z",
        "updated_at": "2023-12-05T13:34:47Z"
      }
    ]
  },
  "lihaosky": {
    "commits": [
      {
        "sha": "2d17f6148796c30890d38c830f772f8f38bfd495",
        "html_url": "https://github.com/apache/flink/commit/2d17f6148796c30890d38c830f772f8f38bfd495",
        "message": "[FLINK-35016][table] Add model to catalog interfaces",
        "date": "2024-10-21T12:28:51Z"
      }
    ]
  },
  "JunRuiLee": {
    "commits": [
      {
        "sha": "2c830898640fe65016763c747c05110bd79b8894",
        "html_url": "https://github.com/apache/flink/commit/2c830898640fe65016763c747c05110bd79b8894",
        "message": "[FLINK-36568][rest] Fix incorrect http url for ClientCoordinationHeaders.",
        "date": "2024-10-16T13:12:26Z"
      }
    ],
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/821836faa3d769d82e65ebf6485c7900744f4ee5#r135878286",
        "id": 135878286,
        "body": "\u8fd9\u4e2a\u597d\u50cf\u6ca1\u770b\u5230\u4f7f\u7528\uff0c\u5f15\u5165\u8fd9\u4e2a\u7684\u610f\u56fe\u662f\u4ec0\u4e48\u5462",
        "commit_id": "821836faa3d769d82e65ebf6485c7900744f4ee5",
        "created_at": "2023-12-29T07:04:21Z",
        "updated_at": "2023-12-29T07:04:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c677de0ed625c83e8b3053ca299ce1b89cd5d313#r136457578",
        "id": 136457578,
        "body": "\u56e0\u4e3ainternalCoordinator\u521b\u5efa\u662f\u5f02\u6b65\u7684\uff0c\u8fd9\u513f\u8be5\u6539\u4e3agetInternalCoordinator().supportsBatchSnapshot()",
        "commit_id": "c677de0ed625c83e8b3053ca299ce1b89cd5d313",
        "created_at": "2024-01-08T04:14:01Z",
        "updated_at": "2024-01-08T04:14:01Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/01d1e1cb153411c74ff15bd9253bf04ea3f947b7#r137423854",
        "id": 137423854,
        "body": "\u8fd9\u4e2acommit\u7684\u4fee\u6539\u597d\u50cf\u6ca1\u7528\u5230\uff0c\u8fd9\u4e2a\u4e3b\u8981\u662f\u7528\u6765\u5e72\u5565\u7684\uff1f",
        "commit_id": "01d1e1cb153411c74ff15bd9253bf04ea3f947b7",
        "created_at": "2024-01-19T10:37:21Z",
        "updated_at": "2024-01-19T10:37:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/01d1e1cb153411c74ff15bd9253bf04ea3f947b7#r137685189",
        "id": 137685189,
        "body": "\u6062\u590dExecutionGraphID\uff0c\u8fd9\u4e2a\u4e8b\u5728flip\u597d\u50cf\u6ca1\u63d0",
        "commit_id": "01d1e1cb153411c74ff15bd9253bf04ea3f947b7",
        "created_at": "2024-01-24T02:15:11Z",
        "updated_at": "2024-01-24T02:15:11Z"
      }
    ]
  },
  "StephanEwen": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/191dd1d2ec1759a9065ba76a700dfd32f0eb8137#r6755062",
        "id": 6755062,
        "body": "As a general comment: I think such blocks can also catch `Throwable`, if it is crucial that they never fail and return just \"unknown\" in the worst case.\n",
        "commit_id": "191dd1d2ec1759a9065ba76a700dfd32f0eb8137",
        "created_at": "2014-06-21T21:27:18Z",
        "updated_at": "2014-06-21T21:27:18Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/73c6fec2b709d3007bba157e95c08cf471d9c365#commitcomment-7998721",
        "id": 7998721,
        "body": "Doesn't this fail the hadoop 2.5.0 builds?\n",
        "commit_id": "73c6fec2b709d3007bba157e95c08cf471d9c365",
        "created_at": "2014-10-01T16:12:20Z",
        "updated_at": "2014-10-01T16:12:20Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/028fcf55c41f4b2a7677eb31d0ead3973e457efc#r8118729",
        "id": 8118729,
        "body": "I agree. Must have been accidentally. Is that the reason for the shutdown hang?\n",
        "commit_id": "028fcf55c41f4b2a7677eb31d0ead3973e457efc",
        "created_at": "2014-10-10T17:31:24Z",
        "updated_at": "2014-10-10T17:31:24Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/69ae3047797fa2ec8f249accc7e8de62ef9d8a66#commitcomment-8201282",
        "id": 8201282,
        "body": "An iterator in scala allows \"for comprehensions\", correct?\n",
        "commit_id": "69ae3047797fa2ec8f249accc7e8de62ef9d8a66",
        "created_at": "2014-10-17T11:09:23Z",
        "updated_at": "2014-10-17T11:09:23Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/818ebda0f4d0070499446d2958532af5addc3a17#r8554785",
        "id": 8554785,
        "body": "Why is there a `4` as a parameter here and nowhere else?\n",
        "commit_id": "818ebda0f4d0070499446d2958532af5addc3a17",
        "created_at": "2014-11-13T11:19:37Z",
        "updated_at": "2014-11-13T11:19:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/818ebda0f4d0070499446d2958532af5addc3a17#r8554795",
        "id": 8554795,
        "body": "Should this be a `4` or no argument at all?\n",
        "commit_id": "818ebda0f4d0070499446d2958532af5addc3a17",
        "created_at": "2014-11-13T11:21:27Z",
        "updated_at": "2014-11-13T11:21:27Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7df6a3d7266b0f934b76722732176dbf5469bdb4#r9381873",
        "id": 9381873,
        "body": "This seems a bit wrong here. The caller calls the `next()` function, which creates an element (potentially large) to pass it to the `next(T reuse)` function, which in turn ignores the value.\n\nI would move the logic to the `next()` function and have the `next(T reuse)` function simply call the `next()` function, ignoring any reusable element.\n",
        "commit_id": "7df6a3d7266b0f934b76722732176dbf5469bdb4",
        "created_at": "2015-01-21T18:45:11Z",
        "updated_at": "2015-01-21T18:45:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7df6a3d7266b0f934b76722732176dbf5469bdb4#r9381927",
        "id": 9381927,
        "body": "Similar as for the inline comment above, I would switch the logic between `next()` and `next(T reuse)` here to prevent creating unnecessary and ignored objects\n",
        "commit_id": "7df6a3d7266b0f934b76722732176dbf5469bdb4",
        "created_at": "2015-01-21T18:48:21Z",
        "updated_at": "2015-01-21T18:48:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2bea79341eb0f2fafd1537b15ca212eb5792f950#commitcomment-9582468",
        "id": 9582468,
        "body": "I think it would actually be fine to throw an error in that case and abort the start. There is obviously something very wrong, and this is a good point to loudly mention it, rather than having people wonder about it later why the JVMs are so small...\n",
        "commit_id": "2bea79341eb0f2fafd1537b15ca212eb5792f950",
        "created_at": "2015-02-04T12:46:33Z",
        "updated_at": "2015-02-04T12:46:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a18994aabfba7c3775f6dc911bd9d59016216817#r12961159",
        "id": 12961159,
        "body": "Would be good if that one was moved to `flink-core` as well, if the class it tests was moved to `flink-core`.\n",
        "commit_id": "a18994aabfba7c3775f6dc911bd9d59016216817",
        "created_at": "2015-08-29T12:44:55Z",
        "updated_at": "2015-08-29T12:44:55Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a18994aabfba7c3775f6dc911bd9d59016216817#r12961618",
        "id": 12961618,
        "body": "If the method is only to draw a serialization copy, we could also add that to the `InstantiationUtil` or use `commons-lang`'s `SerializationUtil` class.\n",
        "commit_id": "a18994aabfba7c3775f6dc911bd9d59016216817",
        "created_at": "2015-08-29T15:31:36Z",
        "updated_at": "2015-08-29T15:31:36Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/554b77bcd9ed66d57d99d4990774a43f35f6a835#commitcomment-12965831",
        "id": 12965831,
        "body": "At some points there were thoughts about a \"hadoop-free\" version. How would this play together?\n",
        "commit_id": "554b77bcd9ed66d57d99d4990774a43f35f6a835",
        "created_at": "2015-08-30T15:07:30Z",
        "updated_at": "2015-08-30T15:07:30Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/554b77bcd9ed66d57d99d4990774a43f35f6a835#commitcomment-12965891",
        "id": 12965891,
        "body": "I think this is a good addition. In the future (Hadoop not present), we may have to go for reflection, true.\n",
        "commit_id": "554b77bcd9ed66d57d99d4990774a43f35f6a835",
        "created_at": "2015-08-30T15:22:28Z",
        "updated_at": "2015-08-30T15:22:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/976bacc65908cc35382ddbbcdc80249a700bc2d3#r14333396",
        "id": 14333396,
        "body": "true, so this gives formatting errors on Windows\n",
        "commit_id": "976bacc65908cc35382ddbbcdc80249a700bc2d3",
        "created_at": "2015-11-11T16:35:02Z",
        "updated_at": "2015-11-11T16:35:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/08318e1a7649b6f78b2c2d4fba7004c547d05961#commitcomment-14478619",
        "id": 14478619,
        "body": "BTW: I think the usual style for git commit messages is to write what the commit does, not what the original problem was. So something like \"Fix Cancel Button for YARN\" would be better...\n",
        "commit_id": "08318e1a7649b6f78b2c2d4fba7004c547d05961",
        "created_at": "2015-11-18T17:51:31Z",
        "updated_at": "2015-11-18T17:51:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a7d4334f1843fd341be49605c2814e01bc786ccf#commitcomment-15679008",
        "id": 15679008,
        "body": "That's a good idea!\n",
        "commit_id": "a7d4334f1843fd341be49605c2814e01bc786ccf",
        "created_at": "2016-01-26T14:59:45Z",
        "updated_at": "2016-01-26T14:59:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f8f747f2290ad623bd8a4f0d8ff4708fada6792a#commitcomment-15890284",
        "id": 15890284,
        "body": "So, actually is that exception comes, we can safely ignore it?\n",
        "commit_id": "f8f747f2290ad623bd8a4f0d8ff4708fada6792a",
        "created_at": "2016-02-04T16:12:43Z",
        "updated_at": "2016-02-04T16:12:43Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/21a715867d655bb61df9a9f7eef37e42b99e206a#commitcomment-15932805",
        "id": 15932805,
        "body": "In the current master, the `DataStream` class imports the correct `o.a.f.api.common.operators.Keys`.\n\nhttps://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.java#L43\n\nIs it possible that your Maven cache has mixed versions?\n",
        "commit_id": "21a715867d655bb61df9a9f7eef37e42b99e206a",
        "created_at": "2016-02-06T14:40:08Z",
        "updated_at": "2016-02-06T14:40:08Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/21a715867d655bb61df9a9f7eef37e42b99e206a#commitcomment-15944874",
        "id": 15944874,
        "body": "No problem, it's quite a common problem that maven caches get inconsistent.\n",
        "commit_id": "21a715867d655bb61df9a9f7eef37e42b99e206a",
        "created_at": "2016-02-08T08:37:25Z",
        "updated_at": "2016-02-08T08:37:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf256c7fbe05accdadc8470013879f567341d1aa#r17644300",
        "id": 17644300,
        "body": "Sorry, this was a partial change that accidentally sneaked into this patch.\nMy bad :-(\n",
        "commit_id": "bf256c7fbe05accdadc8470013879f567341d1aa",
        "created_at": "2016-05-27T10:42:48Z",
        "updated_at": "2016-05-27T10:42:48Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7206b0ed2adb10c94e1ffd3dbe851250b44edcf4#r18116237",
        "id": 18116237,
        "body": "It makes the code nice and clean if you use a final field with a `SerializableObject`.\n",
        "commit_id": "7206b0ed2adb10c94e1ffd3dbe851250b44edcf4",
        "created_at": "2016-07-04T16:33:20Z",
        "updated_at": "2016-07-04T16:33:20Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2477161352e12e75e2f0f85b5833ad04dc6d31f2#r18252297",
        "id": 18252297,
        "body": "The pattern is\n- cache the reference on stack (immutable against concurrent modifications)\n- set the heap reference to null\n- proceed based on the stack reference\n\nI think that should work. If the heap reference was non null initially before, the stack reference is non null, and the condition is true.\n",
        "commit_id": "2477161352e12e75e2f0f85b5833ad04dc6d31f2",
        "created_at": "2016-07-14T20:42:37Z",
        "updated_at": "2016-07-14T20:42:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2477161352e12e75e2f0f85b5833ad04dc6d31f2#r18252310",
        "id": 18252310,
        "body": "The change I made was to clear the heap references earlier. Less chance of redundant work when concurrent disposals happen.\n",
        "commit_id": "2477161352e12e75e2f0f85b5833ad04dc6d31f2",
        "created_at": "2016-07-14T20:43:36Z",
        "updated_at": "2016-07-14T20:43:36Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/19dae21b00cfbf68ee64af80672d25974a3cd346#commitcomment-18339131",
        "id": 18339131,
        "body": "Quick question in this: Why don't we make the default behavior of the JMX reporter to not start an extra server, and only start an extra server if a port parameter is set?\n",
        "commit_id": "19dae21b00cfbf68ee64af80672d25974a3cd346",
        "created_at": "2016-07-21T13:35:41Z",
        "updated_at": "2016-07-21T13:35:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/19dae21b00cfbf68ee64af80672d25974a3cd346#commitcomment-18339788",
        "id": 18339788,
        "body": "Let's leave the remainder as it is for now, at least as long as we do not have the name collisions fully resolved. I am filing a followup issue about JMX and names.\n",
        "commit_id": "19dae21b00cfbf68ee64af80672d25974a3cd346",
        "created_at": "2016-07-21T14:08:19Z",
        "updated_at": "2016-07-21T14:08:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/444315a12ca2b1d3de44ea50dda9b8bb5a36bb9e#commitcomment-18778229",
        "id": 18778229,
        "body": "Does this have the wrong issue tag?\n",
        "commit_id": "444315a12ca2b1d3de44ea50dda9b8bb5a36bb9e",
        "created_at": "2016-08-25T15:43:30Z",
        "updated_at": "2016-08-25T15:43:30Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/4810910431e01bf143ae77a6e93a86f2fafbccd0#commitcomment-18789532",
        "id": 18789532,
        "body": "There is some followup discussion on this in the JIRA issue: https://issues.apache.org/jira/browse/FLINK-3677\n",
        "commit_id": "4810910431e01bf143ae77a6e93a86f2fafbccd0",
        "created_at": "2016-08-26T09:05:11Z",
        "updated_at": "2016-08-26T09:05:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/abb4496781883937a935113c1e33ae1174aafa73#commitcomment-18789807",
        "id": 18789807,
        "body": "Can I re-iterate on this issue?\n\nDo we need tests here that fire up Kafka clusters? Those are very time intensive, they are tough to harden so that the build is reliable, and what do they really add here?\nAssuming the the Kafka connector works, this should test the \"add on\" by the TableSource. That can be done with a mock FlinkKafkaConsumer.\n\nI think it would be very good to update this.\n",
        "commit_id": "abb4496781883937a935113c1e33ae1174aafa73",
        "created_at": "2016-08-26T09:24:06Z",
        "updated_at": "2016-08-26T09:24:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7b574cf5b6e7549ae53ea0846022c4430a979a01#commitcomment-18811350",
        "id": 18811350,
        "body": "Does it make sense to mention that one can set the parallelism of the source independently to the number of Kinesis shards?\n\nThe original reporters of the issue thought they would have to set the parallelism of the entire program to the number of Kinesis shards.\n",
        "commit_id": "7b574cf5b6e7549ae53ea0846022c4430a979a01",
        "created_at": "2016-08-29T12:40:45Z",
        "updated_at": "2016-08-29T12:40:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7a539c05a4a7239801f4fa9bc7313e6f30ff85f5#r18811359",
        "id": 18811359,
        "body": "You could have just used `Arrays.asList(\"**/another_file.bin\", \"**/dataFile1.txt\")` here. The function takes varargs.\n",
        "commit_id": "7a539c05a4a7239801f4fa9bc7313e6f30ff85f5",
        "created_at": "2016-08-29T12:41:32Z",
        "updated_at": "2016-08-29T12:41:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b13db273c200efe12f03b2e1328fce595303223d#r18829377",
        "id": 18829377,
        "body": "Just FYI: For immutable lists without Guava (and without copying the elements), you can always use `Collections.unmodifiableList(list)`.\n",
        "commit_id": "b13db273c200efe12f03b2e1328fce595303223d",
        "created_at": "2016-08-30T13:27:07Z",
        "updated_at": "2016-08-30T13:27:07Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19375216",
        "id": 19375216,
        "body": "I am confused here. What does it help to make this \"serializable\", if the most important member (the KafkaTestEnvironment) is transient? Seems this cannot be serialized anyways...\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T10:13:49Z",
        "updated_at": "2016-10-11T10:13:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19375231",
        "id": 19375231,
        "body": "Is this a test for the Kafka producer? Otherwise, it seems that using directly the Kafka Producer rather than running a dedicated Flink program is simpler and more robust for a test.\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T10:15:48Z",
        "updated_at": "2016-10-11T10:15:48Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19375265",
        "id": 19375265,
        "body": "Can this commented-out code be removed?\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T10:19:19Z",
        "updated_at": "2016-10-11T10:19:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19376219",
        "id": 19376219,
        "body": "That seems like a hack that throws the next person looking into this code off. I think pulling the function out into a dedicated (static, non-anonymous) class is the clean way to go.\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T12:01:58Z",
        "updated_at": "2016-10-11T12:01:58Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19844923",
        "id": 19844923,
        "body": "That means that the thread numbering starts at `2`, right?",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T13:20:41Z",
        "updated_at": "2016-11-16T13:20:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19844935",
        "id": 19844935,
        "body": "Can new threads ever be daemons by default?",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T13:21:23Z",
        "updated_at": "2016-11-16T13:21:23Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19844939",
        "id": 19844939,
        "body": "Can a new thread ever have a different priority be default? Is that inherited from the parent thread or thread group?",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T13:21:54Z",
        "updated_at": "2016-11-16T13:21:54Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/016d90884cc6c6d3aa52d0b1634cc945ea0f2bf0#commitcomment-20372951",
        "id": 20372951,
        "body": "It would be nice to consistently use the `OperatingSystem` class in the code, rather than re-implement the OS name parsing.",
        "commit_id": "016d90884cc6c6d3aa52d0b1634cc945ea0f2bf0",
        "created_at": "2017-01-05T14:01:50Z",
        "updated_at": "2017-01-05T14:01:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6342d6db1de5f38a921732e35abd83e6c5b9305a#r20606338",
        "id": 20606338,
        "body": "It is not a problem, because for processing time, nothing is ever late, by definition. Allowing for late elements (even when nothing is late) is not a problem.\r\n\r\nThat way, it behaves even more consistently between event time and processing time.",
        "commit_id": "6342d6db1de5f38a921732e35abd83e6c5b9305a",
        "created_at": "2017-01-25T09:02:34Z",
        "updated_at": "2017-01-25T09:02:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/646490c4e93eca315e4bf41704f149390f8639cc#commitcomment-21003603",
        "id": 21003603,
        "body": "Should we make `flushOnCheckpoint` true by default?",
        "commit_id": "646490c4e93eca315e4bf41704f149390f8639cc",
        "created_at": "2017-02-22T20:49:40Z",
        "updated_at": "2017-02-22T20:49:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/30c9e2b683bf7f4776ffc23b6a860946a4429ae5#commitcomment-21018833",
        "id": 21018833,
        "body": "Great to have this in!\r\nI would suggest to mention in the JavaDocs of `MapState.size()` that this can be a potentially expensive operation, because it may entail iterating over many entries in some state backends (like RocksDB).",
        "commit_id": "30c9e2b683bf7f4776ffc23b6a860946a4429ae5",
        "created_at": "2017-02-23T16:41:10Z",
        "updated_at": "2017-02-23T16:41:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0a501e9f7f56baba2905002b74746998458db007#r21337504",
        "id": 21337504,
        "body": "I think this results in unnecessary boxing of `time`.",
        "commit_id": "0a501e9f7f56baba2905002b74746998458db007",
        "created_at": "2017-03-15T19:14:32Z",
        "updated_at": "2017-03-15T19:14:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0a501e9f7f56baba2905002b74746998458db007#r21347624",
        "id": 21347624,
        "body": "True, I just noticed it here and in the spirit of continuous improvement made a comment ;-)",
        "commit_id": "0a501e9f7f56baba2905002b74746998458db007",
        "created_at": "2017-03-16T09:26:13Z",
        "updated_at": "2017-03-16T09:26:13Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0da62e8d77dceca6f39e70fb6a313a8169364de0#commitcomment-22021616",
        "id": 22021616,
        "body": "Just saw that the default values used in the options here are different than those in the shell scripts.\r\nDoes it make sense to keep those in sync?",
        "commit_id": "0da62e8d77dceca6f39e70fb6a313a8169364de0",
        "created_at": "2017-05-04T19:20:49Z",
        "updated_at": "2017-05-04T19:20:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/9141379f6d2654886d48154b453170cc23b89a87#r22558742",
        "id": 22558742,
        "body": "What about negative seek values here?",
        "commit_id": "9141379f6d2654886d48154b453170cc23b89a87",
        "created_at": "2017-06-15T08:50:19Z",
        "updated_at": "2017-06-15T08:50:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/9141379f6d2654886d48154b453170cc23b89a87#commitcomment-22558746",
        "id": 22558746,
        "body": "Good change, but I think this could use a guarding unit test.",
        "commit_id": "9141379f6d2654886d48154b453170cc23b89a87",
        "created_at": "2017-06-15T08:50:47Z",
        "updated_at": "2017-06-15T08:50:47Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/435d9d320ba320b40eb328b59e32cda6cc2c531b#r26715452",
        "id": 26715452,
        "body": "I don't think this is needed. The thread status already tells you if it is finished...",
        "commit_id": "435d9d320ba320b40eb328b59e32cda6cc2c531b",
        "created_at": "2018-01-08T13:42:45Z",
        "updated_at": "2018-01-08T13:42:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/81d3e72eb8cd9eb591f6ea67bc904dd0ad200a17#r26715541",
        "id": 26715541,
        "body": "Let's factor this out to https://github.com/apache/flink/tree/master/flink-core/src/main/java/org/apache/flink/util/function\r\n\r\nThis class is probably helpful in other contexts as well...",
        "commit_id": "81d3e72eb8cd9eb591f6ea67bc904dd0ad200a17",
        "created_at": "2018-01-08T13:47:05Z",
        "updated_at": "2018-01-08T13:47:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1f60a1de563ccca4ea0309fbd5c6c3531090ddc9#r26715572",
        "id": 26715572,
        "body": "By common style, constructors use `this.` for all parameters. I would vote to uphold that style.",
        "commit_id": "1f60a1de563ccca4ea0309fbd5c6c3531090ddc9",
        "created_at": "2018-01-08T13:50:04Z",
        "updated_at": "2018-01-08T13:50:04Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/81d3e72eb8cd9eb591f6ea67bc904dd0ad200a17#r26715575",
        "id": 26715575,
        "body": "This method is probably better in https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/util/LambdaUtil.java\r\n\r\nAnother exception suppressing lambda method is already there...",
        "commit_id": "81d3e72eb8cd9eb591f6ea67bc904dd0ad200a17",
        "created_at": "2018-01-08T13:50:25Z",
        "updated_at": "2018-01-08T13:50:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a03cdfabe6eab48509b42a6831a21e488b9c3e80#r26740277",
        "id": 26740277,
        "body": "So far, each profile had a different cache identifier. That way profiles did not interfere with each other's caches. Not sure if this is more a theoretical danger, but this commit breaks with that assumption.",
        "commit_id": "a03cdfabe6eab48509b42a6831a21e488b9c3e80",
        "created_at": "2018-01-09T14:36:51Z",
        "updated_at": "2018-01-09T14:36:51Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5623ac66bd145d52f3488ac2fff9dbc762d0bda1#commitcomment-26867793",
        "id": 26867793,
        "body": "@zentol @rmetzger I think this is not correct. The RocksDB state backend is in `lib` by default. This is only relevant for \"running in the IDE\". The text suggests you need to add this to your user jar.",
        "commit_id": "5623ac66bd145d52f3488ac2fff9dbc762d0bda1",
        "created_at": "2018-01-15T16:01:45Z",
        "updated_at": "2018-01-15T16:01:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c8fa8d025684c2225824c54a7285bbfdec7cfddc#r29021995",
        "id": 29021995,
        "body": "true, did not see that, and checkstyle is off for that class.\r\nThe class is removed now in a follow-up commit anyways, so the problem is fixed now.",
        "commit_id": "c8fa8d025684c2225824c54a7285bbfdec7cfddc",
        "created_at": "2018-05-17T18:30:04Z",
        "updated_at": "2018-05-17T18:30:04Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8231b62ff42aae53ca3a7b552980838ccab824ab#r29792609",
        "id": 29792609,
        "body": "Looks redundant, I agree.",
        "commit_id": "8231b62ff42aae53ca3a7b552980838ccab824ab",
        "created_at": "2018-07-22T13:56:33Z",
        "updated_at": "2018-07-22T13:56:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/244d2db78307cd7dff1c60a664046adb6fe5c405#commitcomment-37282443",
        "id": 37282443,
        "body": "`org.javassist` is an optional \"booster\" for netty. We should make sure we always have it as a dependency in `flink-runtime` at least.",
        "commit_id": "244d2db78307cd7dff1c60a664046adb6fe5c405",
        "created_at": "2020-02-13T20:35:45Z",
        "updated_at": "2020-02-13T20:35:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/244d2db78307cd7dff1c60a664046adb6fe5c405#commitcomment-37293948",
        "id": 37293948,
        "body": "@zentol FYI",
        "commit_id": "244d2db78307cd7dff1c60a664046adb6fe5c405",
        "created_at": "2020-02-14T12:17:50Z",
        "updated_at": "2020-02-14T12:17:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3e66fcfd25f6a24e6d2b2da161683e1556242733#commitcomment-37655695",
        "id": 37655695,
        "body": "You can deprecate the class/enum `FileSystemKind` as well...",
        "commit_id": "3e66fcfd25f6a24e6d2b2da161683e1556242733",
        "created_at": "2020-03-05T14:25:15Z",
        "updated_at": "2020-03-05T14:25:15Z"
      }
    ]
  },
  "rmetzger": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/191dd1d2ec1759a9065ba76a700dfd32f0eb8137#r6757204",
        "id": 6757204,
        "body": "You are right. I'll change this with my next pull request.\n",
        "commit_id": "191dd1d2ec1759a9065ba76a700dfd32f0eb8137",
        "created_at": "2014-06-22T15:24:25Z",
        "updated_at": "2014-06-22T15:24:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/028fcf55c41f4b2a7677eb31d0ead3973e457efc#r8117401",
        "id": 8117401,
        "body": "@StephanEwen : Is there a reason why you removed this code-block?\nI think its a good idea to stop the web interface's Jetty-server?\n",
        "commit_id": "028fcf55c41f4b2a7677eb31d0ead3973e457efc",
        "created_at": "2014-10-10T15:52:54Z",
        "updated_at": "2014-10-10T15:52:54Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/028fcf55c41f4b2a7677eb31d0ead3973e457efc#r8118793",
        "id": 8118793,
        "body": "Ok. My latest push contains a fix for the accidential removal.\n\nThe shutdown hang is independent of this.\n\nSent from my iPhone\n\n> On 10.10.2014, at 19:31, Stephan Ewen notifications@github.com wrote:\n> \n> I agree. Must have been accidentally. Is that the reason for the shutdown hang?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n",
        "commit_id": "028fcf55c41f4b2a7677eb31d0ead3973e457efc",
        "created_at": "2014-10-10T17:36:26Z",
        "updated_at": "2014-10-10T17:36:26Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/9ee74f3cf7b04740d6b00edf45d9413ff40322cf#r9297423",
        "id": 9297423,
        "body": "Yes. But we can discuss it ;)\n",
        "commit_id": "9ee74f3cf7b04740d6b00edf45d9413ff40322cf",
        "created_at": "2015-01-15T14:13:22Z",
        "updated_at": "2015-01-15T14:13:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/554b77bcd9ed66d57d99d4990774a43f35f6a835#commitcomment-12965859",
        "id": 12965859,
        "body": "Currently, flink-runtime has a dependency on Hadoop, so I can assume its always available.\nEven for a binary Flink release without build in Hadoop dependencies, we would assume Hadoop to be present (from the classpath).\nFor a Flink release without any Hadoop, we can either remove this again or use some reflection / fake hadoop class magic (added via maven) if needed.\nBut for now, I would like to have this in the code base because it helps debugging user issues.\n",
        "commit_id": "554b77bcd9ed66d57d99d4990774a43f35f6a835",
        "created_at": "2015-08-30T15:15:25Z",
        "updated_at": "2015-08-30T15:15:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1bc48e0855df803c65344d836092dcf6393ad3f2#r15535103",
        "id": 15535103,
        "body": "I would call this `fs.default-scheme`.\n\nAlso, please add a Javadoc comment\n",
        "commit_id": "1bc48e0855df803c65344d836092dcf6393ad3f2",
        "created_at": "2016-01-19T16:47:20Z",
        "updated_at": "2016-01-19T16:47:20Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1bc48e0855df803c65344d836092dcf6393ad3f2#commitcomment-15535215",
        "id": 15535215,
        "body": "Did you IDE autoformat the code? That's something which makes reviewing the PRs much harder.\n\nYou didn't update the Flink documentation.\n\nI need to to further review of this :)\n",
        "commit_id": "1bc48e0855df803c65344d836092dcf6393ad3f2",
        "created_at": "2016-01-19T16:50:44Z",
        "updated_at": "2016-01-19T16:50:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7206b0ed2adb10c94e1ffd3dbe851250b44edcf4#r18116751",
        "id": 18116751,
        "body": "Thank you for the hint. I'll use it in the future.\n",
        "commit_id": "7206b0ed2adb10c94e1ffd3dbe851250b44edcf4",
        "created_at": "2016-07-04T17:47:26Z",
        "updated_at": "2016-07-04T17:47:26Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/444315a12ca2b1d3de44ea50dda9b8bb5a36bb9e#commitcomment-18778263",
        "id": 18778263,
        "body": "Mh, I stumbled across the broken log upload when I tried fixing that issue ... so I thought the commit is related to my efforts fixing the issue ;)\n",
        "commit_id": "444315a12ca2b1d3de44ea50dda9b8bb5a36bb9e",
        "created_at": "2016-08-25T15:45:20Z",
        "updated_at": "2016-08-25T15:45:20Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19376002",
        "id": 19376002,
        "body": "I marked the class Serializable to trick the ClosureCleaner to accept enclosed source (which is accessing a field of the outer class).\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T11:44:30Z",
        "updated_at": "2016-10-11T11:44:30Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19376443",
        "id": 19376443,
        "body": "I'll push a hotfix with a fix for this.\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T12:23:47Z",
        "updated_at": "2016-10-11T12:23:47Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19376450",
        "id": 19376450,
        "body": "I'll look into the issue again. If I recall correctly, there were some issues mocking everything needed for the producer.\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T12:24:28Z",
        "updated_at": "2016-10-11T12:24:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19376877",
        "id": 19376877,
        "body": "I'll probably have fix for this as well.\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T12:57:33Z",
        "updated_at": "2016-10-11T12:57:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6731ec1e48d0a0092dd2330adda73bcf37fda8d7#r19377574",
        "id": 19377574,
        "body": "Yes, I think these tests were never active. They are from the first pull request adding watermark support, but were commented out while merging.\n",
        "commit_id": "6731ec1e48d0a0092dd2330adda73bcf37fda8d7",
        "created_at": "2016-10-11T13:39:44Z",
        "updated_at": "2016-10-11T13:39:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8bddbc2a254d15675c6bdc8ecfabdc731b6b2f66#commitcomment-37889702",
        "id": 37889702,
        "body": "Sorry fellow committers :( \r\nThe PR had a perfect title: https://github.com/apache/flink/pull/11411 (`[hotfix] [docs] Fix typo in DataStream API walkthrough`). I didn't even consider that the commit is not named correctly. I should not commit stuff early in the morning.",
        "commit_id": "8bddbc2a254d15675c6bdc8ecfabdc731b6b2f66",
        "created_at": "2020-03-18T07:37:26Z",
        "updated_at": "2020-03-18T07:37:26Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b8b0331247fe6d023d4da44868cb1f3526b62c62#r38610181",
        "id": 38610181,
        "body": "I reverted the commit in fabeb9f5fd6e170a79aa7a43c492b049d384e509",
        "commit_id": "b8b0331247fe6d023d4da44868cb1f3526b62c62",
        "created_at": "2020-04-20T09:28:16Z",
        "updated_at": "2020-04-20T09:28:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/50253c6b89e3c92cac23edda6556770a63643c90#commitcomment-39411700",
        "id": 39411700,
        "body": "Sorry for the merge commit :(\r\nThe GitHub \"merge\" button hat an error and then produced this merge commit when I clicked \"try again\" :( ",
        "commit_id": "50253c6b89e3c92cac23edda6556770a63643c90",
        "created_at": "2020-05-25T06:24:33Z",
        "updated_at": "2020-05-25T06:24:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/50253c6b89e3c92cac23edda6556770a63643c90#commitcomment-39413046",
        "id": 39413046,
        "body": "Yeah :( I've learned this the hard way. But this is clearly a bug on GH's side.",
        "commit_id": "50253c6b89e3c92cac23edda6556770a63643c90",
        "created_at": "2020-05-25T07:43:57Z",
        "updated_at": "2020-05-25T07:43:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41660092",
        "id": 41660092,
        "body": "Mh, this renders like this:\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/89049/90878048-50a01980-e3a5-11ea-80df-5dd0720e0710.png)\r\n",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T09:56:17Z",
        "updated_at": "2020-08-21T09:56:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41660180",
        "id": 41660180,
        "body": "ah, I need to do `[nzDescription]=descriptionTemplateRef`",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T10:00:39Z",
        "updated_at": "2020-08-21T10:00:39Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41661878",
        "id": 41661878,
        "body": "Thanks :) ",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T11:14:50Z",
        "updated_at": "2020-08-21T11:14:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ea66e982b284d4ca044c94fbb1eb40c8fef7bf65#r44691786",
        "id": 44691786,
        "body": "I'm adressing this as part of this PR https://github.com/apache/flink/pull/14272",
        "commit_id": "ea66e982b284d4ca044c94fbb1eb40c8fef7bf65",
        "created_at": "2020-12-01T10:37:44Z",
        "updated_at": "2020-12-01T10:37:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/9ce6bf77f83f6c92c1edcc7ccffbaafedb0901d9#commitcomment-46649040",
        "id": 46649040,
        "body": "Fellow Flink committers, I'm sorry for pushing a commit with a poor commit message. I'll try to pay more attention during PR reviews.",
        "commit_id": "9ce6bf77f83f6c92c1edcc7ccffbaafedb0901d9",
        "created_at": "2021-02-02T12:30:22Z",
        "updated_at": "2021-02-02T12:30:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aba768193b3f7c417e2a0db06e949be8603d51f3#r47747562",
        "id": 47747562,
        "body": "What about the download in `test-scripts/docker-hadoop-secure-cluster/Dockerfile` ? \r\n(I use `git grep` for finding all archive.apache.org downloads)",
        "commit_id": "aba768193b3f7c417e2a0db06e949be8603d51f3",
        "created_at": "2021-03-02T15:38:34Z",
        "updated_at": "2021-03-02T15:38:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aba768193b3f7c417e2a0db06e949be8603d51f3#r47747643",
        "id": 47747643,
        "body": "given how awfully long it takes for the tests to run, I would recommend you (during development), to put some debugging code (print cache contents at the beginning and the end of the script)\r\n\r\nalso, you could consider commenting out the majority of the tests defined in this file, so that this thing finishes in less than an hour.",
        "commit_id": "aba768193b3f7c417e2a0db06e949be8603d51f3",
        "created_at": "2021-03-02T15:40:09Z",
        "updated_at": "2021-03-02T15:40:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aba768193b3f7c417e2a0db06e949be8603d51f3#r47747687",
        "id": 47747687,
        "body": "Why can't we use the `E2E_CACHE_FOLDER`? I don't think the java cache, which is using this folder as well will interfere.",
        "commit_id": "aba768193b3f7c417e2a0db06e949be8603d51f3",
        "created_at": "2021-03-02T15:41:03Z",
        "updated_at": "2021-03-02T15:41:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aba768193b3f7c417e2a0db06e949be8603d51f3#r47747770",
        "id": 47747770,
        "body": "I'm a bit confused by the use of `CACHE_FOLDER`. It's defined twice, and overwritten by the argparse.",
        "commit_id": "aba768193b3f7c417e2a0db06e949be8603d51f3",
        "created_at": "2021-03-02T15:42:45Z",
        "updated_at": "2021-03-02T15:42:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/27efcd2826cd2515f26da0b9b6bd527b4a09ff7a#commitcomment-49836271",
        "id": 49836271,
        "body": "Correction: The issue was not caused by 4be9aff, but by https://github.com/apache/flink/commit/4ad4e878606ae855e43e3f64e943885cafb9199a#diff-16222077b9d6d624c6b5571db9ca2e09b5862819c1d3142fad31d39e597ac8ce.",
        "commit_id": "27efcd2826cd2515f26da0b9b6bd527b4a09ff7a",
        "created_at": "2021-04-22T06:31:40Z",
        "updated_at": "2021-04-22T06:31:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8dca9fa852c72984ac873eae9a96bbd739e502f3#r49851344",
        "id": 49851344,
        "body": "No .. but it's a good point. I filed a ticket: https://issues.apache.org/jira/browse/FLINK-22413",
        "commit_id": "8dca9fa852c72984ac873eae9a96bbd739e502f3",
        "created_at": "2021-04-22T11:33:45Z",
        "updated_at": "2021-04-22T11:33:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b8d527166e095653ae3ff5c0431bf27297efe229#commitcomment-142759872",
        "id": 142759872,
        "body": "Sorry for pushing a commit with the wrong commit id!",
        "commit_id": "b8d527166e095653ae3ff5c0431bf27297efe229",
        "created_at": "2024-06-05T12:16:54Z",
        "updated_at": "2024-06-05T12:16:54Z"
      }
    ]
  },
  "physikerwelt": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/6278a6c3478d333231cd0a5adc688cbbc3a7dd94#r7689854",
        "id": 7689854,
        "body": "for DRIVERNAME = \"org.mariadb.jdbc.Driver\" it worked with FLOAT_TYPE_INFO instead of DOUBLE_TYPE_INFO\n",
        "commit_id": "6278a6c3478d333231cd0a5adc688cbbc3a7dd94",
        "created_at": "2014-09-07T14:39:22Z",
        "updated_at": "2014-09-07T14:39:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6278a6c3478d333231cd0a5adc688cbbc3a7dd94#commitcomment-7689856",
        "id": 7689856,
        "body": "test with org.mariadb.jdbc.Driver see inline comment\n",
        "commit_id": "6278a6c3478d333231cd0a5adc688cbbc3a7dd94",
        "created_at": "2014-09-07T14:40:01Z",
        "updated_at": "2014-09-07T14:40:01Z"
      }
    ]
  },
  "aljoscha": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/69ae3047797fa2ec8f249accc7e8de62ef9d8a66#commitcomment-8201320",
        "id": 8201320,
        "body": "Yes, they are not like Java Iterators. They allow all the usual collection operations. In addition, you can get a buffered iterator and access the first element, as in:\n\n```\nval it: Iterator = // ...\nval buffered = it.buffered\nval first = buffered.head\nfor (v <- buffered) {\n  // iterate over all element, including first\n}\n```\n",
        "commit_id": "69ae3047797fa2ec8f249accc7e8de62ef9d8a66",
        "created_at": "2014-10-17T11:13:59Z",
        "updated_at": "2014-10-17T11:13:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ae2537e8b672a7d73b3bb69bc32c9a17ae763783#commitcomment-10661408",
        "id": 10661408,
        "body": "Dammit, I fixed it in my janino PR\n",
        "commit_id": "ae2537e8b672a7d73b3bb69bc32c9a17ae763783",
        "created_at": "2015-04-10T08:21:04Z",
        "updated_at": "2015-04-10T08:21:04Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/76968c6360c17d5deb4e42727c16bc1b9a891b26#commitcomment-16956214",
        "id": 16956214,
        "body": "Done\n",
        "commit_id": "76968c6360c17d5deb4e42727c16bc1b9a891b26",
        "created_at": "2016-04-04T16:59:37Z",
        "updated_at": "2016-04-04T16:59:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/879bb1bb029ed37e33adc7a655328940135cfcb3#commitcomment-17254978",
        "id": 17254978,
        "body": "Could do, but it does not really impact performance very much.\n",
        "commit_id": "879bb1bb029ed37e33adc7a655328940135cfcb3",
        "created_at": "2016-04-26T14:26:01Z",
        "updated_at": "2016-04-26T14:26:01Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/19dae21b00cfbf68ee64af80672d25974a3cd346#commitcomment-18339338",
        "id": 18339338,
        "body": "That seems like a good idea, yes. Still not have the JMXReporter active by default or now have it active by default again?\n",
        "commit_id": "19dae21b00cfbf68ee64af80672d25974a3cd346",
        "created_at": "2016-07-21T13:48:07Z",
        "updated_at": "2016-07-21T13:48:07Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/da53953e5366185567515d209fcc85d4006f7e8a#r19948322",
        "id": 19948322,
        "body": "I think this won't work because now we don't have all the special serialisation logic that `SimpleStateDescriptor` has. What you could do is override `getDefaultValue()` and return `null` there. Then, in `getInitialValue()` you return the default value and you don't need the extra field.\r\n\r\nWhat do you think?",
        "commit_id": "da53953e5366185567515d209fcc85d4006f7e8a",
        "created_at": "2016-11-24T07:23:37Z",
        "updated_at": "2016-11-24T07:23:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6342d6db1de5f38a921732e35abd83e6c5b9305a#r20626829",
        "id": 20626829,
        "body": "That's a good point but the `WindowOperator` protects against this by only considering the allowed lateness when the `WindowAssigner` advertises itself as event-time aware: https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java#L615",
        "commit_id": "6342d6db1de5f38a921732e35abd83e6c5b9305a",
        "created_at": "2017-01-26T15:04:12Z",
        "updated_at": "2017-01-26T15:04:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0a501e9f7f56baba2905002b74746998458db007#r21347344",
        "id": 21347344,
        "body": "This commit didn't change that. But it's true, I'll push a commit that changes it to\r\n```\r\nif (fireTimestamp != null && fireTimestamp == time) {\r\n```\r\n",
        "commit_id": "0a501e9f7f56baba2905002b74746998458db007",
        "created_at": "2017-03-16T09:02:06Z",
        "updated_at": "2017-03-16T09:02:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0a501e9f7f56baba2905002b74746998458db007#r21351102",
        "id": 21351102,
        "body": "Of course \ud83d\ude03 ",
        "commit_id": "0a501e9f7f56baba2905002b74746998458db007",
        "created_at": "2017-03-16T13:11:03Z",
        "updated_at": "2017-03-16T13:11:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c940d5eff9897796625a696ed2989aed52c39ebd#r25902242",
        "id": 25902242,
        "body": "could, but that's not strictly necessary anymore because I also introduced the temporary `git clone`.",
        "commit_id": "c940d5eff9897796625a696ed2989aed52c39ebd",
        "created_at": "2017-11-28T16:55:28Z",
        "updated_at": "2017-11-28T16:55:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aa1f83333f31c01d8fd4ae5bdaaf48c44aadc221#r26036557",
        "id": 26036557,
        "body": "sorry about that, I pushed hot fixes",
        "commit_id": "aa1f83333f31c01d8fd4ae5bdaaf48c44aadc221",
        "created_at": "2017-12-04T16:07:57Z",
        "updated_at": "2017-12-04T16:07:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8c89f3c6b5ebd0334176d9e7e57b38b4d39a594a#commitcomment-29638369",
        "id": 29638369,
        "body": "Strange, it seems to be this one: https://issues.apache.org/jira/browse/FLINK-5363",
        "commit_id": "8c89f3c6b5ebd0334176d9e7e57b38b4d39a594a",
        "created_at": "2018-07-09T09:00:13Z",
        "updated_at": "2018-07-09T09:00:13Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/01811317d709ad54f1e0c105d5e3e6e36f85d24d#commitcomment-29903416",
        "id": 29903416,
        "body": "I think you might be right. This shouldn't have ended up here.\r\n\r\n@suez1224 Does Flink 1.5.x work for you in your Kerberos environment?",
        "commit_id": "01811317d709ad54f1e0c105d5e3e6e36f85d24d",
        "created_at": "2018-07-31T12:39:36Z",
        "updated_at": "2018-07-31T12:39:36Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/01811317d709ad54f1e0c105d5e3e6e36f85d24d#commitcomment-29923227",
        "id": 29923227,
        "body": "@link3280 For reference I created and resolved https://issues.apache.org/jira/browse/FLINK-10013",
        "commit_id": "01811317d709ad54f1e0c105d5e3e6e36f85d24d",
        "created_at": "2018-08-01T15:31:55Z",
        "updated_at": "2018-08-01T15:31:55Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2923a4e68da8f6cc2c6b8d770e5df18f971226f3#r31104411",
        "id": 31104411,
        "body": "Can do, but I think it also works like this. I'll change it.",
        "commit_id": "2923a4e68da8f6cc2c6b8d770e5df18f971226f3",
        "created_at": "2018-10-30T15:47:19Z",
        "updated_at": "2018-10-30T15:47:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/89634d7fb44de1c763271ef4c24aaaf048e5ae20#r36139242",
        "id": 36139242,
        "body": "I think the previous change of removing `-n` from the normal CLI already broke those user setups. But I think it's better to remove options that don't have any effect. At least then users will notice.",
        "commit_id": "89634d7fb44de1c763271ef4c24aaaf048e5ae20",
        "created_at": "2019-11-26T12:24:19Z",
        "updated_at": "2019-11-26T12:24:19Z"
      }
    ]
  },
  "mbalassi": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/ba44459f66f3a73b831da5ae807775faf4843b06#commitcomment-8215458",
        "id": 8215458,
        "body": "Thanks, @hsaputra. :)\n",
        "commit_id": "ba44459f66f3a73b831da5ae807775faf4843b06",
        "created_at": "2014-10-19T15:45:16Z",
        "updated_at": "2014-10-19T15:45:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/e23874cd886711d4a0c2812562e20719cc35ebb4#commitcomment-8599203",
        "id": 8599203,
        "body": "Thanks.\n",
        "commit_id": "e23874cd886711d4a0c2812562e20719cc35ebb4",
        "created_at": "2014-11-17T15:40:00Z",
        "updated_at": "2014-11-17T15:40:00Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/988602b031b63deb9640b115b798e9ae54fb7357#r9725249",
        "id": 9725249,
        "body": "This way you use the generate pom that is in the outside repo and might be from a different branch. Not a big difference, but might lead to unexpected results. :)\n",
        "commit_id": "988602b031b63deb9640b115b798e9ae54fb7357",
        "created_at": "2015-02-12T21:17:24Z",
        "updated_at": "2015-02-12T21:17:24Z"
      }
    ]
  },
  "aalexandrov": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/9ee74f3cf7b04740d6b00edf45d9413ff40322cf#r9297124",
        "id": 9297124,
        "body": "Is removing the .gitignore a standard procedure for the release branches?\n",
        "commit_id": "9ee74f3cf7b04740d6b00edf45d9413ff40322cf",
        "created_at": "2015-01-15T13:54:27Z",
        "updated_at": "2015-01-15T13:54:57Z"
      }
    ]
  },
  "uce": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/ae2537e8b672a7d73b3bb69bc32c9a17ae763783#commitcomment-10656403",
        "id": 10656403,
        "body": "Just skimmed over the scaladoc and found a typo in `join`: t**w**o is missing the w.\n",
        "commit_id": "ae2537e8b672a7d73b3bb69bc32c9a17ae763783",
        "created_at": "2015-04-09T22:29:17Z",
        "updated_at": "2015-04-09T22:29:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/16fb4e919f4a76b8fe4910435b2183fa172f6e24#r13328780",
        "id": 13328780,
        "body": "In case of an Exception, won't the client receive both a `JobResultFailure` and `JobResultSuccess` afterwards outside of the catch block?\n",
        "commit_id": "16fb4e919f4a76b8fe4910435b2183fa172f6e24",
        "created_at": "2015-09-20T09:18:19Z",
        "updated_at": "2015-09-20T09:18:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/008060f16d5a850be178557d5d0dbbc52864c187#r14621810",
        "id": 14621810,
        "body": "This will lead to having an error message at the end of each standalone job manager log, no? Maybe it's OK...\n",
        "commit_id": "008060f16d5a850be178557d5d0dbbc52864c187",
        "created_at": "2015-11-25T16:53:39Z",
        "updated_at": "2015-11-25T16:53:39Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aad99f25cd107a8eaa24a8d407680a8186ba6460#commitcomment-14621819",
        "id": 14621819,
        "body": "Should we merge this to 0.10.2 as well?\n",
        "commit_id": "aad99f25cd107a8eaa24a8d407680a8186ba6460",
        "created_at": "2015-11-25T16:54:14Z",
        "updated_at": "2015-11-25T16:54:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a7d4334f1843fd341be49605c2814e01bc786ccf#commitcomment-15678832",
        "id": 15678832,
        "body": "Should we add a checkstyle rule to not allow `junit.framework` imports?\n",
        "commit_id": "a7d4334f1843fd341be49605c2814e01bc786ccf",
        "created_at": "2016-01-26T14:54:12Z",
        "updated_at": "2016-01-26T14:54:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8b34d21e054bb1df3a86f975ff29a51807858a81#commitcomment-15702432",
        "id": 15702432,
        "body": "If you like, I can add a prominent note linking to a Wiki page, where we list all required changes. Would you like to add the Wiki page?\n",
        "commit_id": "8b34d21e054bb1df3a86f975ff29a51807858a81",
        "created_at": "2016-01-27T11:10:35Z",
        "updated_at": "2016-01-27T11:10:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8b34d21e054bb1df3a86f975ff29a51807858a81#commitcomment-15703496",
        "id": 15703496,
        "body": "OK, I've updated the docs.\n",
        "commit_id": "8b34d21e054bb1df3a86f975ff29a51807858a81",
        "created_at": "2016-01-27T11:58:14Z",
        "updated_at": "2016-01-27T11:58:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a7d4334f1843fd341be49605c2814e01bc786ccf#commitcomment-15707254",
        "id": 15707254,
        "body": "The thing is that this requires checkstyle to be enabled for the tests as well. I would like that. Let me ask on the mailing list what the others think...\n",
        "commit_id": "a7d4334f1843fd341be49605c2814e01bc786ccf",
        "created_at": "2016-01-27T14:42:19Z",
        "updated_at": "2016-01-27T14:42:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f8f747f2290ad623bd8a4f0d8ff4708fada6792a#commitcomment-15888699",
        "id": 15888699,
        "body": "Thanks for looking into it.\n\n`ZKPaths.deleteChildren` actually looks like it already handles this. The `KeeperException.NoNodeException` can only happen if the initial path does not exist. Therefore I think that we can skip the retry loop.\n\n``` java\npublic static void deleteChildren(ZooKeeper zookeeper, String path, boolean deleteSelf) throws InterruptedException, KeeperException\n{\n    PathUtils.validatePath(path);\n\n    List<String> children = zookeeper.getChildren(path, null);\n    for ( String child : children )\n    {\n        String fullPath = makePath(path, child);\n        deleteChildren(zookeeper, fullPath, true);\n    }\n\n    if ( deleteSelf )\n    {\n        try\n        {\n            zookeeper.delete(path, -1);\n        }\n        catch ( KeeperException.NotEmptyException e )\n        {\n            //someone has created a new child since we checked ... delete again.\n            deleteChildren(zookeeper, path, true);\n        }\n        catch ( KeeperException.NoNodeException e )\n        {\n            // ignore... someone else has deleted the node it since we checked\n        }\n    }\n}\n```\n",
        "commit_id": "f8f747f2290ad623bd8a4f0d8ff4708fada6792a",
        "created_at": "2016-02-04T15:20:34Z",
        "updated_at": "2016-02-04T15:20:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/21a715867d655bb61df9a9f7eef37e42b99e206a#commitcomment-15927499",
        "id": 15927499,
        "body": "Please consult this page and use the new Maven artifacts (with Scala suffixes): https://cwiki.apache.org/confluence/display/FLINK/Maven+artifact+names+suffixed+with+Scala+version\n\nDoes it resolve the issue?\n",
        "commit_id": "21a715867d655bb61df9a9f7eef37e42b99e206a",
        "created_at": "2016-02-05T23:02:38Z",
        "updated_at": "2016-02-05T23:02:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/138334a6d0181de153abd9bcfabba201ad512f34#commitcomment-16235140",
        "id": 16235140,
        "body": "I saw this one failing with the higher timeout last week. Is it OK with you to give it more time (like 60secs)?\n",
        "commit_id": "138334a6d0181de153abd9bcfabba201ad512f34",
        "created_at": "2016-02-22T09:34:32Z",
        "updated_at": "2016-02-22T09:34:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ce448cdbdd301585b0faea4fe4c920856ee37818#commitcomment-16897467",
        "id": 16897467,
        "body": "Did not add this to `master` yet as the ASF might support `rsync` for `home.apache.org` again until `1.1`...\n",
        "commit_id": "ce448cdbdd301585b0faea4fe4c920856ee37818",
        "created_at": "2016-03-30T15:20:28Z",
        "updated_at": "2016-03-30T15:20:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/76968c6360c17d5deb4e42727c16bc1b9a891b26#commitcomment-16955170",
        "id": 16955170,
        "body": "Can you please cherrypick this to `release-1.0` as well?\n",
        "commit_id": "76968c6360c17d5deb4e42727c16bc1b9a891b26",
        "created_at": "2016-04-04T16:02:35Z",
        "updated_at": "2016-04-04T16:02:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7462a5bfd7cb2dafbbc9eb02a43d3db9f6add30e#commitcomment-17165776",
        "id": 17165776,
        "body": "Can you push this to `release-1.0` as well to have it in 1.0.3 or the next 1.0.2 RC?\n",
        "commit_id": "7462a5bfd7cb2dafbbc9eb02a43d3db9f6add30e",
        "created_at": "2016-04-19T18:44:09Z",
        "updated_at": "2016-04-19T18:44:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/879bb1bb029ed37e33adc7a655328940135cfcb3#commitcomment-17254739",
        "id": 17254739,
        "body": "Should we add this to `release-1.0` as well?\n",
        "commit_id": "879bb1bb029ed37e33adc7a655328940135cfcb3",
        "created_at": "2016-04-26T14:18:53Z",
        "updated_at": "2016-04-26T14:18:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1ccc798914a2bd94157f2a86f7961bc1cc5de490#commitcomment-17256873",
        "id": 17256873,
        "body": "Can we add this to release-1.0 as well?\n",
        "commit_id": "1ccc798914a2bd94157f2a86f7961bc1cc5de490",
        "created_at": "2016-04-26T15:51:34Z",
        "updated_at": "2016-04-26T15:51:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0cf04108f70375d41ebb7c39629db3a081bd2876#commitcomment-17784955",
        "id": 17784955,
        "body": "Just noticed that `SubtaskState` cleanup only catches and logs exceptions (`TaskForState` before, too). Does anyone recall what the reasoning for this is? Is it OK to remove the catch or rethrow the Exception? When discarding a savepoint without the proper class loader for example, this will only show up in the logs, but the savepoint disposal will be marked as a success.\n",
        "commit_id": "0cf04108f70375d41ebb7c39629db3a081bd2876",
        "created_at": "2016-06-08T10:05:44Z",
        "updated_at": "2016-06-08T10:05:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/79d7e3017efe7c96e449e6f339fd7184ef3d1ba2#commitcomment-20198048",
        "id": 20198048,
        "body": "This commit accidentally removed the newly added docs about Externalized Checkpoints (in `setup/fault_tolerance.md`. @alpinegizmo @StephanEwen Where would you like to move that now?",
        "commit_id": "79d7e3017efe7c96e449e6f339fd7184ef3d1ba2",
        "created_at": "2016-12-15T10:22:16Z",
        "updated_at": "2016-12-15T10:22:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/79d7e3017efe7c96e449e6f339fd7184ef3d1ba2#commitcomment-20198072",
        "id": 20198072,
        "body": "OK, just found it in `setup/checkpoints.md`. Perfect place for it \ud83d\udc4d ",
        "commit_id": "79d7e3017efe7c96e449e6f339fd7184ef3d1ba2",
        "created_at": "2016-12-15T10:24:13Z",
        "updated_at": "2016-12-15T10:24:13Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8086e3bee8be4614359041c14786140edff19666#commitcomment-26179876",
        "id": 26179876,
        "body": "I know that the project historically did not consider the REST API as a public API, but I would vote to note down all of these breaking REST API changes for the upcoming 1.5 release notes in order to have a good migration path for users. I just ran into this when pointing a tool that was using the `jobsoverview` endpoint of 1.4 to the latest master and had to look into what happened when I got a 404.\r\n\r\nIt might also be worth to add redirects in 1.5. and only remove them in the release after that (cc @zentol).",
        "commit_id": "8086e3bee8be4614359041c14786140edff19666",
        "created_at": "2017-12-10T20:11:42Z",
        "updated_at": "2017-12-10T20:11:42Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3a61ea47922280e15f462ca3cdc0c367047bde24#commitcomment-28293221",
        "id": 28293221,
        "body": "@twalthr I think this broke the build. At least locally, I get a RAT license failure. \r\n\r\n```\r\n1 Unknown Licenses\r\n\r\n*****************************************************\r\n\r\nFiles with unapproved licenses:\r\n\r\n  docs/page/js/jquery.min.js\r\n\r\n*****************************************************\r\n```",
        "commit_id": "3a61ea47922280e15f462ca3cdc0c367047bde24",
        "created_at": "2018-03-27T15:41:31Z",
        "updated_at": "2018-03-27T15:41:31Z"
      }
    ]
  },
  "mjsax": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/35d7b5be823e3c4578b8d51f8d03f53018fb1066#r11303380",
        "id": 11303380,
        "body": "Sorry for the long diff. It's due to inconsistent line-breaks within the file... now all line-breaks are UNIX format.\n\nThe actuall change is from line 144 to 153. (144 to 147 is new; 153 is changed -> added programClass to response String)\n",
        "commit_id": "35d7b5be823e3c4578b8d51f8d03f53018fb1066",
        "created_at": "2015-05-21T11:10:00Z",
        "updated_at": "2015-05-21T11:24:06Z"
      }
    ]
  },
  "thvasilo": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/995f8f9693c4fe2e40efcf6a82c10ccab11c37ba#r11408683",
        "id": 11408683,
        "body": "Just noticed: The example still uses CoCoA() instead of SVM()\n",
        "commit_id": "995f8f9693c4fe2e40efcf6a82c10ccab11c37ba",
        "created_at": "2015-05-28T14:47:57Z",
        "updated_at": "2015-05-28T14:47:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/27487ec6089adbea77266f194582ae476e50e928#r11537562",
        "id": 11537562,
        "body": "Example should be program, cannot currently perform in the shell\n",
        "commit_id": "27487ec6089adbea77266f194582ae476e50e928",
        "created_at": "2015-06-05T09:16:56Z",
        "updated_at": "2015-06-05T09:16:56Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/27487ec6089adbea77266f194582ae476e50e928#r11537565",
        "id": 11537565,
        "body": "TODO: Need to transform the tuples to LabeledVector\n",
        "commit_id": "27487ec6089adbea77266f194582ae476e50e928",
        "created_at": "2015-06-05T09:17:22Z",
        "updated_at": "2015-06-05T09:17:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/27487ec6089adbea77266f194582ae476e50e928#r11537784",
        "id": 11537784,
        "body": "This way of reading in CSVs can get unwieldy fast. We need a more concise way to do this,\n",
        "commit_id": "27487ec6089adbea77266f194582ae476e50e928",
        "created_at": "2015-06-05T09:31:41Z",
        "updated_at": "2015-06-05T09:31:41Z"
      }
    ]
  },
  "mxm": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/a18994aabfba7c3775f6dc911bd9d59016216817#r12961579",
        "id": 12961579,
        "body": "Thanks for noticing. This requires some refactoring because the test depends on a method in `CommonTestUtils`. Is it desired to have a CommonTestUtils clases in each runtime and core? As far as I can see the methods are not runtime or core-specific, so the two can be combined into one class residing in core.\n",
        "commit_id": "a18994aabfba7c3775f6dc911bd9d59016216817",
        "created_at": "2015-08-29T15:15:50Z",
        "updated_at": "2015-08-29T15:15:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a18994aabfba7c3775f6dc911bd9d59016216817#r12974542",
        "id": 12974542,
        "body": "@StephanEwen Do you think #1081 is feasible?\n",
        "commit_id": "a18994aabfba7c3775f6dc911bd9d59016216817",
        "created_at": "2015-08-31T12:12:14Z",
        "updated_at": "2015-08-31T12:12:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14181408",
        "id": 14181408,
        "body": "HI Alexey, \n\nYes, these changes are in the newest SNAPSHOT. You might have to update your Maven cache.\n\nCheers,\nMax \n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-04T12:43:29Z",
        "updated_at": "2015-11-04T12:43:29Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14239173",
        "id": 14239173,
        "body": "Are you still having this problem? The newest flink-storm version as of today is from Nov 06.\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-06T11:54:53Z",
        "updated_at": "2015-11-06T11:54:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14240638",
        "id": 14240638,
        "body": "You're welcome.\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-06T13:06:44Z",
        "updated_at": "2015-11-06T13:06:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/976bacc65908cc35382ddbbcdc80249a700bc2d3#r14333154",
        "id": 14333154,
        "body": "\\n is not compatible with a non Unix environment.\n",
        "commit_id": "976bacc65908cc35382ddbbcdc80249a700bc2d3",
        "created_at": "2015-11-11T16:27:04Z",
        "updated_at": "2015-11-11T16:27:04Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/976bacc65908cc35382ddbbcdc80249a700bc2d3#r14385157",
        "id": 14385157,
        "body": "Adjusted in 9a911c88ec4b11300d72f41a7c51569e1d228a87.\n",
        "commit_id": "976bacc65908cc35382ddbbcdc80249a700bc2d3",
        "created_at": "2015-11-13T16:04:34Z",
        "updated_at": "2015-11-13T16:04:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14475546",
        "id": 14475546,
        "body": "@tillrohrmann @alexeyegorov Actually there are 1.0-SNAPSHOT binaries available. See http://flink.apache.org/contribute-code.html#snapshots-nightly-builds\n\nPlease keep in mind that these are targeted at developers and not officially released.\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-18T15:52:10Z",
        "updated_at": "2015-11-18T15:52:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14475824",
        "id": 14475824,
        "body": "Seems like the 1.0-SNAPSHOT binaries are missing. Looking into the problem right now.\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-18T15:59:54Z",
        "updated_at": "2015-11-18T15:59:54Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14559720",
        "id": 14559720,
        "body": "You can now get the latest nightly binaries here: http://flink.apache.org/contribute-code.html#snapshots-nightly-builds\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-23T13:13:14Z",
        "updated_at": "2015-11-23T13:13:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8b34d21e054bb1df3a86f975ff29a51807858a81#commitcomment-15702724",
        "id": 15702724,
        "body": "That would be great if you could do that. I just wrote an email to the user and dev mailing list.\n",
        "commit_id": "8b34d21e054bb1df3a86f975ff29a51807858a81",
        "created_at": "2016-01-27T11:21:40Z",
        "updated_at": "2016-01-27T11:21:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8b34d21e054bb1df3a86f975ff29a51807858a81#commitcomment-15704256",
        "id": 15704256,
        "body": "Thanks!\n",
        "commit_id": "8b34d21e054bb1df3a86f975ff29a51807858a81",
        "created_at": "2016-01-27T12:33:55Z",
        "updated_at": "2016-01-27T12:33:55Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5a7f4e3395bfb06da496584be88501c328f6ac1d#commitcomment-17643795",
        "id": 17643795,
        "body": "@StephanEwen I think this has been left there on purpose because the ExecutionConfig is declared Public and this would break the backwards-compatibility.\n",
        "commit_id": "5a7f4e3395bfb06da496584be88501c328f6ac1d",
        "created_at": "2016-05-27T09:42:02Z",
        "updated_at": "2016-05-27T09:42:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf256c7fbe05accdadc8470013879f567341d1aa#r17643812",
        "id": 17643812,
        "body": "@StephanEwen Why does this change touch critical parts of the system without a jira issue? Plus, the commit message is not even related to these changes.\n",
        "commit_id": "bf256c7fbe05accdadc8470013879f567341d1aa",
        "created_at": "2016-05-27T09:43:48Z",
        "updated_at": "2016-05-27T09:54:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf256c7fbe05accdadc8470013879f567341d1aa#r17643841",
        "id": 17643841,
        "body": "This breaks the master and ignores the PR #2037.\n",
        "commit_id": "bf256c7fbe05accdadc8470013879f567341d1aa",
        "created_at": "2016-05-27T09:47:37Z",
        "updated_at": "2016-05-27T09:47:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf256c7fbe05accdadc8470013879f567341d1aa#r17644775",
        "id": 17644775,
        "body": "No worries, that stuff can happen. Fixing this with #2037 (underlying issue why this bug could occur).\n",
        "commit_id": "bf256c7fbe05accdadc8470013879f567341d1aa",
        "created_at": "2016-05-27T11:38:01Z",
        "updated_at": "2016-05-27T11:38:01Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c8fed99e3e85a4d27c6134cfa3e07fb3a8e1da2a#r17936226",
        "id": 17936226,
        "body": "It does work fine for most cases. However, there are rare race conditions which render our CI useless.\n",
        "commit_id": "c8fed99e3e85a4d27c6134cfa3e07fb3a8e1da2a",
        "created_at": "2016-06-20T16:02:59Z",
        "updated_at": "2016-06-20T16:02:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b13db273c200efe12f03b2e1328fce595303223d#r18829963",
        "id": 18829963,
        "body": "Thanks. I've considered that option but I didn't want to change the semantic of the code which copies the values.\n",
        "commit_id": "b13db273c200efe12f03b2e1328fce595303223d",
        "created_at": "2016-08-30T14:06:47Z",
        "updated_at": "2016-08-30T14:06:47Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6d4dd75859aa5e78a20dc3a9492391f1c7f7ca7a#r19436429",
        "id": 19436429,
        "body": "Thanks for the notice! Fixed.\n",
        "commit_id": "6d4dd75859aa5e78a20dc3a9492391f1c7f7ca7a",
        "created_at": "2016-10-14T23:28:44Z",
        "updated_at": "2016-10-14T23:29:07Z"
      }
    ]
  },
  "MoeweX": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/9e20147c2089d29e3071addec19f0956f68b7321#commitcomment-12972151",
        "id": 12972151,
        "body": "Hi Till,\n\nas reported by me and @FelixNeutatz: the stop-script has the same error...\n",
        "commit_id": "9e20147c2089d29e3071addec19f0956f68b7321",
        "created_at": "2015-08-31T09:34:17Z",
        "updated_at": "2015-08-31T09:34:17Z"
      }
    ]
  },
  "tillrohrmann": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/9e20147c2089d29e3071addec19f0956f68b7321#commitcomment-12973040",
        "id": 12973040,
        "body": "I'll fix it. Thanks for the pointer @JonathanH5 :-)\n",
        "commit_id": "9e20147c2089d29e3071addec19f0956f68b7321",
        "created_at": "2015-08-31T10:28:42Z",
        "updated_at": "2015-08-31T10:28:42Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dd66e61ecc5da5b15a610f04b98c8386d141f910#commitcomment-14182335",
        "id": 14182335,
        "body": "Good point @smarthi. I think nobody so far considered it. Should take a look.\n",
        "commit_id": "dd66e61ecc5da5b15a610f04b98c8386d141f910",
        "created_at": "2015-11-04T13:21:37Z",
        "updated_at": "2015-11-04T13:21:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14470837",
        "id": 14470837,
        "body": "Hi @alexeyegorov, there are no binaries for 1.0-SNAPSHOT. But you can easily build it yourself by simply cloning the flink repository and then call `mvn clean package -DskipTests` in the root directory. If you then go to `build-target` you end up in the folder which contains the binary distribution of Flink. Thus, copying this folder to your cluster should do the job.\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-18T12:52:24Z",
        "updated_at": "2015-11-18T12:52:24Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a7d4334f1843fd341be49605c2814e01bc786ccf#commitcomment-15726940",
        "id": 15726940,
        "body": "I guess this will entail some work correcting the checkstyle violations in the tests, e.g. unused imports etc.\n",
        "commit_id": "a7d4334f1843fd341be49605c2814e01bc786ccf",
        "created_at": "2016-01-28T08:53:14Z",
        "updated_at": "2016-01-28T08:53:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7462a5bfd7cb2dafbbc9eb02a43d3db9f6add30e#commitcomment-17174247",
        "id": 17174247,
        "body": "Yes will do.\n\nOn Tue, Apr 19, 2016 at 8:44 PM, Ufuk Celebi notifications@github.com\nwrote:\n\n> Can you push this to release-1.0 as well to have it in 1.0.3 or the next\n> 1.0.2 RC?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/flink/commit/7462a5bfd7cb2dafbbc9eb02a43d3db9f6add30e#commitcomment-17165776\n",
        "commit_id": "7462a5bfd7cb2dafbbc9eb02a43d3db9f6add30e",
        "created_at": "2016-04-20T09:03:34Z",
        "updated_at": "2016-04-20T09:03:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1ccc798914a2bd94157f2a86f7961bc1cc5de490#commitcomment-17257298",
        "id": 17257298,
        "body": "Yes, will add it right away.\n",
        "commit_id": "1ccc798914a2bd94157f2a86f7961bc1cc5de490",
        "created_at": "2016-04-26T16:13:59Z",
        "updated_at": "2016-04-26T16:13:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/68addf39e0e5f9e1656818f923be362680ed93b0#commitcomment-18669730",
        "id": 18669730,
        "body": "Really nice abstraction @StephanEwen \ud83d\udc4d . I like it a lot :-)\n",
        "commit_id": "68addf39e0e5f9e1656818f923be362680ed93b0",
        "created_at": "2016-08-17T09:48:21Z",
        "updated_at": "2016-08-17T09:48:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/32e1675aa38eec4a15272d62977dfe3ddbe92401#commitcomment-20640052",
        "id": 20640052,
        "body": "Had also forgotten about this ;-)",
        "commit_id": "32e1675aa38eec4a15272d62977dfe3ddbe92401",
        "created_at": "2017-01-27T12:06:15Z",
        "updated_at": "2017-01-27T12:06:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3400a87dce9940ac8da95c89ff9791ca6a687776#r20662491",
        "id": 20662491,
        "body": "At the moment, there is no ack being sent back to the TM. What could however happen is that the message never receives the JM and the TM thinks that the checkpoint has been completed. In this case, we would have state lingering around.",
        "commit_id": "3400a87dce9940ac8da95c89ff9791ca6a687776",
        "created_at": "2017-01-30T14:10:38Z",
        "updated_at": "2017-01-30T14:10:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0da62e8d77dceca6f39e70fb6a313a8169364de0#commitcomment-22029297",
        "id": 22029297,
        "body": "I think this makes sense to do as long as we don't fall below the minimum memory requirements for Yarn (I think this should be 768 Mb).",
        "commit_id": "0da62e8d77dceca6f39e70fb6a313a8169364de0",
        "created_at": "2017-05-05T08:17:41Z",
        "updated_at": "2017-05-05T08:17:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/fca8caea70cb5b76d4d45bdac438d8e3c3fd3315#r23558079",
        "id": 23558079,
        "body": "Why did you exclude this dependency? I think that's the reason why Flink fails with the following exception when trying to start a Flink yarn session with Hadoop `2.7.1`:\r\n```\r\nException in thread \"main\" java.lang.NoClassDefFoundError: javax/servlet/Filter\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat org.apache.hadoop.hdfs.DFSConfigKeys.<clinit>(DFSConfigKeys.java:237)\r\n\tat org.apache.hadoop.hdfs.DFSClient$Conf.<init>(DFSClient.java:509)\r\n\tat org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:638)\r\n\tat org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:619)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149)\r\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653)\r\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:170)\r\n\tat org.apache.flink.yarn.AbstractYarnClusterDescriptor.startAppMaster(AbstractYarnClusterDescriptor.java:625)\r\n\tat org.apache.flink.yarn.AbstractYarnClusterDescriptor.deployInternal(AbstractYarnClusterDescriptor.java:456)\r\n\tat org.apache.flink.yarn.AbstractYarnClusterDescriptor.deploySessionCluster(AbstractYarnClusterDescriptor.java:362)\r\n\tat org.apache.flink.yarn.cli.FlinkYarnSessionCli.run(FlinkYarnSessionCli.java:677)\r\n\tat org.apache.flink.yarn.cli.FlinkYarnSessionCli$1.call(FlinkYarnSessionCli.java:512)\r\n\tat org.apache.flink.yarn.cli.FlinkYarnSessionCli$1.call(FlinkYarnSessionCli.java:509)\r\n\tat org.apache.flink.runtime.security.HadoopSecurityContext$1.run(HadoopSecurityContext.java:44)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\r\n\tat org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)\r\n\tat org.apache.flink.yarn.cli.FlinkYarnSessionCli.main(FlinkYarnSessionCli.java:509)\r\nCaused by: java.lang.ClassNotFoundException: javax.servlet.Filter\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 47 more\r\n```\r\n\r\nThe problem seems to be that `DFSConfigKeys` loads `o.a.h.hdfs.web.AuthFilter` which depends on `javax.servlet`.",
        "commit_id": "fca8caea70cb5b76d4d45bdac438d8e3c3fd3315",
        "created_at": "2017-08-09T14:02:49Z",
        "updated_at": "2017-08-09T14:02:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f2c3ff3ee3a5121665e32acebbaeee7bbb380e7f#commitcomment-25306076",
        "id": 25306076,
        "body": "Would be great to add an explanation why these tests are ignored.",
        "commit_id": "f2c3ff3ee3a5121665e32acebbaeee7bbb380e7f",
        "created_at": "2017-10-31T11:47:34Z",
        "updated_at": "2017-10-31T11:47:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dd48a40ab7b3a721c7c78a4b0d6efad5b50f947e#r26082263",
        "id": 26082263,
        "body": "yes",
        "commit_id": "dd48a40ab7b3a721c7c78a4b0d6efad5b50f947e",
        "created_at": "2017-12-06T08:23:11Z",
        "updated_at": "2017-12-06T08:23:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8086e3bee8be4614359041c14786140edff19666#commitcomment-26240373",
        "id": 26240373,
        "body": "Valid point. I'll add the release notes.",
        "commit_id": "8086e3bee8be4614359041c14786140edff19666",
        "created_at": "2017-12-13T13:29:37Z",
        "updated_at": "2017-12-13T13:29:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a03cdfabe6eab48509b42a6831a21e488b9c3e80#r26789565",
        "id": 26789565,
        "body": "You're right. I'll correct it.",
        "commit_id": "a03cdfabe6eab48509b42a6831a21e488b9c3e80",
        "created_at": "2018-01-11T13:14:50Z",
        "updated_at": "2018-01-11T13:14:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/17e8664aa6e2915c368e8eb75c6ae5e3b1942239#r27019488",
        "id": 27019488,
        "body": "Good point @zentol. Will add it.",
        "commit_id": "17e8664aa6e2915c368e8eb75c6ae5e3b1942239",
        "created_at": "2018-01-22T14:14:52Z",
        "updated_at": "2018-01-22T14:14:52Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8c89f3c6b5ebd0334176d9e7e57b38b4d39a594a#commitcomment-29555488",
        "id": 29555488,
        "body": "The Flink JIRA issue seems to be incorrect. @aljoscha could you please point me to the correct JIRA issue?",
        "commit_id": "8c89f3c6b5ebd0334176d9e7e57b38b4d39a594a",
        "created_at": "2018-06-30T20:55:04Z",
        "updated_at": "2018-06-30T20:55:04Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a95ec5acf259884347ae539913bcffcad5bfc340#r29919528",
        "id": 29919528,
        "body": "Hi @TisonKun, `runAsync` also runs in the main thread of the `RpcEndpoint`. Thus, this interleaving should not be possible to happen.",
        "commit_id": "a95ec5acf259884347ae539913bcffcad5bfc340",
        "created_at": "2018-08-01T10:39:42Z",
        "updated_at": "2018-08-01T10:39:42Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a2198b04712b8ec6105999414f33781c6efcf4a9#commitcomment-30050267",
        "id": 30050267,
        "body": "Could you do the back port and open a PR with it @xiaoguichao?",
        "commit_id": "a2198b04712b8ec6105999414f33781c6efcf4a9",
        "created_at": "2018-08-13T07:17:35Z",
        "updated_at": "2018-08-13T07:17:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c7eb6acaf95a6656ec6bd0a0b401c1944473e7f2#r30325774",
        "id": 30325774,
        "body": "The `AllocatedSlot` should only be used by the `SlotPool` and not outside of this class. Therefore, restricting the access to package private will prevent that his class is used somewhere else.",
        "commit_id": "c7eb6acaf95a6656ec6bd0a0b401c1944473e7f2",
        "created_at": "2018-08-29T09:46:59Z",
        "updated_at": "2018-08-29T09:46:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30330739",
        "id": 30330739,
        "body": "Hi @TisonKun, this test tests Flink's legacy mode. The community plans to remove the legacy mode altogether with the next release. Thus, I would not recommend spending too much effort into these tests. What would be helpful is to check what test should be ported to the Flip-6 code base and porting this test case then. There you don't need to worry about `TestingUtils.stopActorGracefully`. Did this answer your question?",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-08-29T16:05:18Z",
        "updated_at": "2018-08-29T16:05:18Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30511353",
        "id": 30511353,
        "body": "Would it help to create a special `HardFailingJobMaster` which extends from `JobMaster` and which simply skips the `postStop` method @TisonKun?",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-09-14T18:26:32Z",
        "updated_at": "2018-09-14T18:26:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0735b5b935b0c0757943e2d58047afcfb9949560#r30584257",
        "id": 30584257,
        "body": "This class seems only to be relevant for tests anymore. I couldn't find any other usage of it.",
        "commit_id": "0735b5b935b0c0757943e2d58047afcfb9949560",
        "created_at": "2018-09-20T21:49:03Z",
        "updated_at": "2018-09-20T21:49:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f90f5e5832425f999c5ce564c25284b912ebab18#commitcomment-30800853",
        "id": 30800853,
        "body": "I think `JobSubmitTest` has been removed with the previous commit.",
        "commit_id": "f90f5e5832425f999c5ce564c25284b912ebab18",
        "created_at": "2018-10-07T09:39:03Z",
        "updated_at": "2018-10-07T09:39:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/064379705f36aaea927c44bb303a867c0c66265d#r32518442",
        "id": 32518442,
        "body": "Continue discussion in https://issues.apache.org/jira/browse/FLINK-11749",
        "commit_id": "064379705f36aaea927c44bb303a867c0c66265d",
        "created_at": "2019-02-28T12:21:47Z",
        "updated_at": "2019-02-28T12:21:47Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a954ea113bc29a4480af579387c6e9b81bd76f85#r33276875",
        "id": 33276875,
        "body": "Yes, it looks like this.",
        "commit_id": "a954ea113bc29a4480af579387c6e9b81bd76f85",
        "created_at": "2019-04-23T14:15:52Z",
        "updated_at": "2019-04-23T14:15:52Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7838436fc3b3aa653ecb33fc965116110b1f835e#commitcomment-34616800",
        "id": 34616800,
        "body": "@wuchong if you tag a commit with a JIRA number then the JIRA should also reflect the change. FLINK-13509 is still open and has a fixVersion `1.10.0`. In the concrete case, I would suggest to create two separate issues which are related (one for the quick fix in 1.9 and the other for the proper fix).",
        "commit_id": "7838436fc3b3aa653ecb33fc965116110b1f835e",
        "created_at": "2019-08-08T08:19:23Z",
        "updated_at": "2019-08-08T08:19:23Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7838436fc3b3aa653ecb33fc965116110b1f835e#commitcomment-34620165",
        "id": 34620165,
        "body": "Thanks for the update @wuchong ",
        "commit_id": "7838436fc3b3aa653ecb33fc965116110b1f835e",
        "created_at": "2019-08-08T12:52:46Z",
        "updated_at": "2019-08-08T12:52:46Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c95e9f642288bb2816cf84868709ea2543a90ae5#r35132153",
        "id": 35132153,
        "body": "I think the check here is to make sure that all tasks are really running. If this were not required, then one could also use the `RestClusterClient.getJobStatus` method.",
        "commit_id": "c95e9f642288bb2816cf84868709ea2543a90ae5",
        "created_at": "2019-09-18T12:48:12Z",
        "updated_at": "2019-09-18T12:48:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c95e9f642288bb2816cf84868709ea2543a90ae5#r35208962",
        "id": 35208962,
        "body": "Theoretically it could also be `ClusterClient#listJobs` and `ClusterClient#getJobClient(JobID)` and then using `JobClient.getDetails()`. But this wasn't there at the time of writing.",
        "commit_id": "c95e9f642288bb2816cf84868709ea2543a90ae5",
        "created_at": "2019-09-24T09:32:01Z",
        "updated_at": "2019-09-24T09:32:01Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6134cbc7a2c63b6f0c602614000596818be13cdb#commitcomment-35713316",
        "id": 35713316,
        "body": "Nice catch @zentol \ud83d\udc4d ",
        "commit_id": "6134cbc7a2c63b6f0c602614000596818be13cdb",
        "created_at": "2019-10-29T15:53:29Z",
        "updated_at": "2019-10-29T15:53:29Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/45397fe974e1390cd39a34fc2eb216f3771ddf06#r36690096",
        "id": 36690096,
        "body": "The reason why this class exists is that not all Hadoop 2.x versions support `RegisterApplicationMasterResponse#getContainersFromPreviousAttempts`. Hence, I'm not sure that we can remove this class.",
        "commit_id": "45397fe974e1390cd39a34fc2eb216f3771ddf06",
        "created_at": "2020-01-07T11:17:08Z",
        "updated_at": "2020-01-07T11:17:08Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1f9c2d9740ffea2b59b8f5f3da287a0dc890ddbf#r36722778",
        "id": 36722778,
        "body": "@StephanEwen was there a specific reason why you've excluded `ConfigConstants` from the japicmp check? See https://issues.apache.org/jira/browse/FLINK-15523 for further discussion.",
        "commit_id": "1f9c2d9740ffea2b59b8f5f3da287a0dc890ddbf",
        "created_at": "2020-01-09T09:15:40Z",
        "updated_at": "2020-01-09T09:15:52Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dd6069fabf8a7ff65fbd9ff8dd7b0c47f492288f#r64352619",
        "id": 64352619,
        "body": "This is a good question. Currently, we do the same in the `ClusterEntrypoint`. That's why I've made it symmetric to the behaviour in this case.\r\n\r\nBut a `SIGTERM` which terminates the process properly should probably rather result in a 0 exit code. On the other hand, it is convention to terminate with a exit code `128 + signal`. But in both case, the current state is not correct.",
        "commit_id": "dd6069fabf8a7ff65fbd9ff8dd7b0c47f492288f",
        "created_at": "2022-01-21T18:23:03Z",
        "updated_at": "2022-01-21T18:23:03Z"
      }
    ]
  },
  "sachingoel0101": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/fc5c142fc95580f556e720839f8f8210bf049d27#r13848736",
        "id": 13848736,
        "body": "`a\\nb` isn't a very good test. It will fail on windows.\n",
        "commit_id": "fc5c142fc95580f556e720839f8f8210bf049d27",
        "created_at": "2015-10-19T13:33:50Z",
        "updated_at": "2015-10-19T13:33:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/4676a17309c8c502b158933b9bfb8c8060bd3458#r13855651",
        "id": 13855651,
        "body": "`a\\nb` isn't a very good way to verify existence of elements. It will fail on windows because the output will actually be `a\\r\\nb` there.\n",
        "commit_id": "4676a17309c8c502b158933b9bfb8c8060bd3458",
        "created_at": "2015-10-19T18:18:53Z",
        "updated_at": "2015-10-19T18:18:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dd66e61ecc5da5b15a610f04b98c8386d141f910#commitcomment-14352258",
        "id": 14352258,
        "body": "@gallenvara JMH is under GPL license which isn't compatible with Apache License. [FLINK-2973]\n",
        "commit_id": "dd66e61ecc5da5b15a610f04b98c8386d141f910",
        "created_at": "2015-11-12T10:55:30Z",
        "updated_at": "2015-11-12T10:55:30Z"
      }
    ]
  },
  "alexeyegorov": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14180954",
        "id": 14180954,
        "body": "Hey,\n\nare these changes already in the newest SNAPSHOT? As I'm getting an error locating in `FlinkLocalCluster.java`. I have the following line still in there:\n\n```\nJobGraph jobGraph = topology.getStreamGraph().getJobGraph(topologyName);\n```\n\nwhere `StreamGraph` API is already changed to `getJobGraph()`.\n\nCheers\nAlexey\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-04T12:22:06Z",
        "updated_at": "2015-11-04T12:22:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14182283",
        "id": 14182283,
        "body": "Hey,\n\nI have cleared my cache while I was waiting for your answer. Still getting this error. But after looking into the snapshots repo with a colleague we've found that [flink-storm](https://repository.apache.org/content/groups/snapshots/org/apache/flink/flink-storm/1.0-SNAPSHOT/) is from 23 October, while [flink-streaming-java](https://repository.apache.org/content/groups/snapshots/org/apache/flink/flink-streaming-java/1.0-SNAPSHOT/) package is more up to date (3 November) as I am getting right `StreamingGraph` version and wrong `FlinkLocalCluster` version.\n\nHope this is a the reason for my problem and you could fix it. ;) \n\nCheers\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-04T13:19:30Z",
        "updated_at": "2015-11-04T13:19:30Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14239582",
        "id": 14239582,
        "body": "Yesterday I saw that it was updated on Nov 04 in the evening and it worked. Thanks! ;) \n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-06T12:20:45Z",
        "updated_at": "2015-11-06T12:21:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14469239",
        "id": 14469239,
        "body": "Hey, as I get no answer on another question, maybe you can still help me: I would love to test 1.0-SNAPSHOT on my test cluster, but I am not able to find download link. I'm somehow not sure how to build right those sources or jars, that I need for the start!? If the scripts like start-cluster.sh or start-local.sh are still the same compared to 0.9.1, then how could I go further from what I have? \nI would really appreciate your help!\nThanks in advance!\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-18T11:33:21Z",
        "updated_at": "2015-11-18T11:33:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bf29de981c2bcd5cb5d33c68b158c95c8820f43d#commitcomment-14496327",
        "id": 14496327,
        "body": "@tillrohrmann @mxm thank you both. It's good know where I can find binaries I build on my own (was looking for them in my target folder). I was also trying to find some of them on the website, but it is somehow difficult, e.g. this [page](https://ci.apache.org/projects/flink/flink-docs-master/) states that pre-built snapshot can be downloaded there, but what you find is 0.9.1 stable version.\n",
        "commit_id": "bf29de981c2bcd5cb5d33c68b158c95c8820f43d",
        "created_at": "2015-11-19T10:58:06Z",
        "updated_at": "2015-11-19T10:58:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/21a715867d655bb61df9a9f7eef37e42b99e206a#commitcomment-15927084",
        "id": 15927084,
        "body": "has this commit been added to the current 1.0-SNAPSHOT? I become a problem while building my project and find that `org.apache.flink.streaming.api.datastream.DataStream` still imports `import org.apache.flink.api.java.operators.Keys;` while in this commit I see that it has been moved from package `...java.operators` to package `...common.operators`. I hope you can fix it asap.\n",
        "commit_id": "21a715867d655bb61df9a9f7eef37e42b99e206a",
        "created_at": "2016-02-05T22:43:50Z",
        "updated_at": "2016-02-05T22:43:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/21a715867d655bb61df9a9f7eef37e42b99e206a#commitcomment-15932065",
        "id": 15932065,
        "body": "@uce yes, I've already added _2.10 to my dependencies that are scala dependent... but I still get the build problem.\n",
        "commit_id": "21a715867d655bb61df9a9f7eef37e42b99e206a",
        "created_at": "2016-02-06T11:11:48Z",
        "updated_at": "2016-02-06T11:11:48Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/21a715867d655bb61df9a9f7eef37e42b99e206a#commitcomment-15941109",
        "id": 15941109,
        "body": "@StephanEwen ok, I'm sorry. I was able to build everything only after removing .m2/repository and clearing all caches. Seems to have been my own problem. ;) \n",
        "commit_id": "21a715867d655bb61df9a9f7eef37e42b99e206a",
        "created_at": "2016-02-07T22:04:32Z",
        "updated_at": "2016-02-07T22:04:32Z"
      }
    ]
  },
  "smarthi": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/dd66e61ecc5da5b15a610f04b98c8386d141f910#commitcomment-14182299",
        "id": 14182299,
        "body": "Consider using Google Calipers for micro benchmarking ?? - https://github.com/google/caliper  \n",
        "commit_id": "dd66e61ecc5da5b15a610f04b98c8386d141f910",
        "created_at": "2015-11-04T13:20:19Z",
        "updated_at": "2015-11-04T13:20:19Z"
      }
    ]
  },
  "gallenvara": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/dd66e61ecc5da5b15a610f04b98c8386d141f910#commitcomment-14352150",
        "id": 14352150,
        "body": "@tillrohrmann  @smarthi  I have done some work of `flink-benchmark` with JMH. Can you tell me why to remove the `flink-benchmark` module. Does JMH have some weakness?\n",
        "commit_id": "dd66e61ecc5da5b15a610f04b98c8386d141f910",
        "created_at": "2015-11-12T10:50:35Z",
        "updated_at": "2015-11-12T10:50:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dd66e61ecc5da5b15a610f04b98c8386d141f910#commitcomment-14373918",
        "id": 14373918,
        "body": "@chiwanpark  @sachingoel0101  Thanks for your explaination.\n",
        "commit_id": "dd66e61ecc5da5b15a610f04b98c8386d141f910",
        "created_at": "2015-11-13T04:55:19Z",
        "updated_at": "2015-11-13T04:55:19Z"
      }
    ]
  },
  "chiwanpark": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/dd66e61ecc5da5b15a610f04b98c8386d141f910#commitcomment-14352242",
        "id": 14352242,
        "body": "@gallenvara AFAIK JMH is licensed under GPL (http://hg.openjdk.java.net/code-tools/jmh/file/bcec9a03787f/LICENSE). GPL is not compatible with Apache License 2.0. So we had to remove `flink-benchmark` module.\n",
        "commit_id": "dd66e61ecc5da5b15a610f04b98c8386d141f910",
        "created_at": "2015-11-12T10:54:47Z",
        "updated_at": "2015-11-12T10:54:47Z"
      }
    ]
  },
  "hsaputra": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/aad99f25cd107a8eaa24a8d407680a8186ba6460#commitcomment-14623683",
        "id": 14623683,
        "body": "+1\nThis should be easy rebase to the branch.\n",
        "commit_id": "aad99f25cd107a8eaa24a8d407680a8186ba6460",
        "created_at": "2015-11-25T18:15:32Z",
        "updated_at": "2015-11-25T18:15:32Z"
      }
    ]
  },
  "hash-X": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/c923fb3c1c1d61462e1079198ae9fb735bb0acf2#r15155284",
        "id": 15155284,
        "body": "This line of code `while (input.hasNext()){` don't have a good style, it should be like this `while (input.hasNext()) {`\n",
        "commit_id": "c923fb3c1c1d61462e1079198ae9fb735bb0acf2",
        "created_at": "2015-12-24T16:14:44Z",
        "updated_at": "2015-12-24T16:14:44Z"
      }
    ]
  },
  "stefanobaghino": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/dd4e278545182f0d4cbf403911f550c1badde125#commitcomment-15677128",
        "id": 15677128,
        "body": "I can further improve the examples using `case classes` in the Scala example. Doing it while retaining the usage of inheritance would involve making a `trait` for both the `Point` and `Centroid` to inherit from.\n",
        "commit_id": "dd4e278545182f0d4cbf403911f550c1badde125",
        "created_at": "2016-01-26T13:48:01Z",
        "updated_at": "2016-01-26T13:48:01Z"
      }
    ]
  },
  "fhueske": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/629015fbff477f8a20d2142094e4015f4520e80b#r15909792",
        "id": 15909792,
        "body": "the number of keys is independent of the number of aggregation fields.\n",
        "commit_id": "629015fbff477f8a20d2142094e4015f4520e80b",
        "created_at": "2016-02-05T10:12:10Z",
        "updated_at": "2016-02-05T10:12:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/629015fbff477f8a20d2142094e4015f4520e80b#r15909835",
        "id": 15909835,
        "body": "You need two loops here\n1. to copy all grouping fields from the last input row into the out row\n2. to copy the results of all aggregate functions into the out row\n",
        "commit_id": "629015fbff477f8a20d2142094e4015f4520e80b",
        "created_at": "2016-02-05T10:13:57Z",
        "updated_at": "2016-02-05T10:13:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/629015fbff477f8a20d2142094e4015f4520e80b#r15909895",
        "id": 15909895,
        "body": "`groupingKeys` hold only the field indicies of the grouping keys, not the actual values. You need to do something like `outValue.setField(i, currentValue.getField(groupingKeys(i))`. For that you need to remember one input row (first or last doesn't matter, all have the same values in the grouping fields).\n",
        "commit_id": "629015fbff477f8a20d2142094e4015f4520e80b",
        "created_at": "2016-02-05T10:16:19Z",
        "updated_at": "2016-02-05T10:16:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/629015fbff477f8a20d2142094e4015f4520e80b#r15909932",
        "id": 15909932,
        "body": "This copies the field index of the aggregation fields. We only need the value of the aggregation.\n",
        "commit_id": "629015fbff477f8a20d2142094e4015f4520e80b",
        "created_at": "2016-02-05T10:17:31Z",
        "updated_at": "2016-02-05T10:17:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/629015fbff477f8a20d2142094e4015f4520e80b#r15909944",
        "id": 15909944,
        "body": "The row should be initialized with `new Row(groupingKeys.length + aggregates.length)`\n",
        "commit_id": "629015fbff477f8a20d2142094e4015f4520e80b",
        "created_at": "2016-02-05T10:18:11Z",
        "updated_at": "2016-02-05T10:18:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2a5d83221023176d2fffbe464aa29daab171e939#r15913051",
        "id": 15913051,
        "body": "should be `aggregates(i - groupingKeys.length)` or you iterate `for (i <- 0 to aggregates.length)` and add groupingKeys.length...\n",
        "commit_id": "2a5d83221023176d2fffbe464aa29daab171e939",
        "created_at": "2016-02-05T12:59:02Z",
        "updated_at": "2016-02-05T12:59:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2a5d83221023176d2fffbe464aa29daab171e939#commitcomment-15913064",
        "id": 15913064,
        "body": "Looks (mostly) good\n",
        "commit_id": "2a5d83221023176d2fffbe464aa29daab171e939",
        "created_at": "2016-02-05T12:59:45Z",
        "updated_at": "2016-02-05T12:59:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/eece0dd05bc38b88fcb6cbcef15add7f98eab456#r19307176",
        "id": 19307176,
        "body": "Outch, I should have been more careful with this :-( \nThanks for fixing it @tzulitai!\n",
        "commit_id": "eece0dd05bc38b88fcb6cbcef15add7f98eab456",
        "created_at": "2016-10-05T18:44:45Z",
        "updated_at": "2016-10-05T18:44:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6d4dd75859aa5e78a20dc3a9492391f1c7f7ca7a#r19435898",
        "id": 19435898,
        "body": "This change is breaking the build right now:\n`cannot find symbol:   variable HA_ZOOKEEPER_NAMESPACE_KEY`\n",
        "commit_id": "6d4dd75859aa5e78a20dc3a9492391f1c7f7ca7a",
        "created_at": "2016-10-14T22:25:17Z",
        "updated_at": "2016-10-14T22:25:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6d4dd75859aa5e78a20dc3a9492391f1c7f7ca7a#r19438191",
        "id": 19438191,
        "body": "Thanks for the quick fix!\n",
        "commit_id": "6d4dd75859aa5e78a20dc3a9492391f1c7f7ca7a",
        "created_at": "2016-10-15T05:14:52Z",
        "updated_at": "2016-10-15T05:14:52Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d4665a00a4262f89b166895f73a54daab2f25e1c#r21555986",
        "id": 21555986,
        "body": "Hi @rtudoran, \r\n\r\nthis PR added support for event-time OVER RANGE windows. Stefano and you are working on processing time OVER RANGE/ROWS windows which require a different implementation, no?\r\nI assume you are upset because the function was changed to support the row and range case. However, in the function the actual code for this part is still missing. This is where your code would go.\r\n\r\nI know working concurrently with others on the same code can mean a lot of rebasing and change merging. However, we merge PRs once they are ready to be merged. ",
        "commit_id": "d4665a00a4262f89b166895f73a54daab2f25e1c",
        "created_at": "2017-03-30T10:39:22Z",
        "updated_at": "2017-03-30T10:39:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/eb3a1741032795ab8db76b40c3614820a2529166#commitcomment-29983564",
        "id": 29983564,
        "body": "The `master` branch is protected. It is not possible to change commits once they've been added.",
        "commit_id": "eb3a1741032795ab8db76b40c3614820a2529166",
        "created_at": "2018-08-07T08:23:08Z",
        "updated_at": "2018-08-07T08:23:08Z"
      }
    ]
  },
  "zentol": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/707606ac40dbbbd497fcbbb5442870fec5468bf3#r17574494",
        "id": 17574494,
        "body": "this can produce wrong metrics for the Batch API. Metrics directly associated with a job will be reset if at any point a given TM has no tasks for a job.\n",
        "commit_id": "707606ac40dbbbd497fcbbb5442870fec5468bf3",
        "created_at": "2016-05-23T05:18:43Z",
        "updated_at": "2016-05-23T05:18:43Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7ad8375a89374bec80571029e9166f1336bdea8e#r17693130",
        "id": 17693130,
        "body": "this change has broken the scope formats.\n",
        "commit_id": "7ad8375a89374bec80571029e9166f1336bdea8e",
        "created_at": "2016-06-01T09:19:38Z",
        "updated_at": "2016-06-01T09:19:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7ad8375a89374bec80571029e9166f1336bdea8e#r17693170",
        "id": 17693170,
        "body": "where is this done now?\n",
        "commit_id": "7ad8375a89374bec80571029e9166f1336bdea8e",
        "created_at": "2016-06-01T09:23:11Z",
        "updated_at": "2016-06-01T09:23:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2477161352e12e75e2f0f85b5833ad04dc6d31f2#r18251972",
        "id": 18251972,
        "body": "will this condition never be true?\n",
        "commit_id": "2477161352e12e75e2f0f85b5833ad04dc6d31f2",
        "created_at": "2016-07-14T20:20:12Z",
        "updated_at": "2016-07-14T20:20:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2477161352e12e75e2f0f85b5833ad04dc6d31f2#r18257970",
        "id": 18257970,
        "body": "ok.\n",
        "commit_id": "2477161352e12e75e2f0f85b5833ad04dc6d31f2",
        "created_at": "2016-07-15T08:09:49Z",
        "updated_at": "2016-07-15T08:09:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a612b9966f3ee020a5721ac2f039a3633c40146c#r19427630",
        "id": 19427630,
        "body": "This error message is misleading, as it is also printed if the configured size is 0.\n",
        "commit_id": "a612b9966f3ee020a5721ac2f039a3633c40146c",
        "created_at": "2016-10-14T12:45:01Z",
        "updated_at": "2016-10-14T12:45:01Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19845479",
        "id": 19845479,
        "body": "yes it does.",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T14:01:33Z",
        "updated_at": "2016-11-16T14:01:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19845480",
        "id": 19845480,
        "body": "yes, if the parent thread is a daemon thread.",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T14:01:34Z",
        "updated_at": "2016-11-16T14:01:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19845484",
        "id": 19845484,
        "body": "it can have a different priority if the thread group to which it belongs has a different priority.",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T14:01:43Z",
        "updated_at": "2016-11-16T14:01:43Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/57208e650f94edece537ccdeb1a2c19b4f7ccca8#r19845489",
        "id": 19845489,
        "body": "will fix it.",
        "commit_id": "57208e650f94edece537ccdeb1a2c19b4f7ccca8",
        "created_at": "2016-11-16T14:02:02Z",
        "updated_at": "2016-11-16T14:02:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/016d90884cc6c6d3aa52d0b1634cc945ea0f2bf0#commitcomment-20373267",
        "id": 20373267,
        "body": "that's true, preparing a PR for that.",
        "commit_id": "016d90884cc6c6d3aa52d0b1634cc945ea0f2bf0",
        "created_at": "2017-01-05T14:26:32Z",
        "updated_at": "2017-01-05T14:26:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5f0d6769051be8db8ee12659e13d22e5c5fd2f2d#r21839439",
        "id": 21839439,
        "body": "This line shouldn't be removed.",
        "commit_id": "5f0d6769051be8db8ee12659e13d22e5c5fd2f2d",
        "created_at": "2017-04-20T15:13:02Z",
        "updated_at": "2017-04-20T15:13:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5f0d6769051be8db8ee12659e13d22e5c5fd2f2d#r21839446",
        "id": 21839446,
        "body": "This line shouldn't be removed.",
        "commit_id": "5f0d6769051be8db8ee12659e13d22e5c5fd2f2d",
        "created_at": "2017-04-20T15:13:29Z",
        "updated_at": "2017-04-20T15:13:29Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/423f4d65e3dd35482fdbc2fb7e34ec8f11243609#r22120213",
        "id": 22120213,
        "body": "isn't this breaking the checkstyle rules?",
        "commit_id": "423f4d65e3dd35482fdbc2fb7e34ec8f11243609",
        "created_at": "2017-05-12T14:57:22Z",
        "updated_at": "2017-05-12T14:57:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2437da6e54cb48c4e29116b8789fbe4782b17ea7#r24399898",
        "id": 24399898,
        "body": "Why do you think this is invalid? http://www.scala-lang.org/old/sites/default/files/linuxsoft_archives/docu/files/api/scala/throws.html",
        "commit_id": "2437da6e54cb48c4e29116b8789fbe4782b17ea7",
        "created_at": "2017-09-19T09:58:16Z",
        "updated_at": "2017-09-19T09:58:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c940d5eff9897796625a696ed2989aed52c39ebd#r25875079",
        "id": 25875079,
        "body": "maybe we should have a wildcard exclude for all files/directories starting with `.`.",
        "commit_id": "c940d5eff9897796625a696ed2989aed52c39ebd",
        "created_at": "2017-11-27T16:24:23Z",
        "updated_at": "2017-11-27T16:24:23Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aa1f83333f31c01d8fd4ae5bdaaf48c44aadc221#r26033587",
        "id": 26033587,
        "body": "remove empty line",
        "commit_id": "aa1f83333f31c01d8fd4ae5bdaaf48c44aadc221",
        "created_at": "2017-12-04T13:41:45Z",
        "updated_at": "2017-12-04T13:41:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dd48a40ab7b3a721c7c78a4b0d6efad5b50f947e#r26062390",
        "id": 26062390,
        "body": "did you intentionally place this import here?",
        "commit_id": "dd48a40ab7b3a721c7c78a4b0d6efad5b50f947e",
        "created_at": "2017-12-05T14:48:28Z",
        "updated_at": "2017-12-05T14:48:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/907361d862c77a70ff60d27e7fcc13647eac0e6d#r26885301",
        "id": 26885301,
        "body": "What benefit is there in referencing a module that doesn't exist?",
        "commit_id": "907361d862c77a70ff60d27e7fcc13647eac0e6d",
        "created_at": "2018-01-16T11:31:16Z",
        "updated_at": "2018-01-16T11:31:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/17e8664aa6e2915c368e8eb75c6ae5e3b1942239#r27018442",
        "id": 27018442,
        "body": "@tillrohrmann How about adding a null-check for the headers in `AbstractRestHandler`?",
        "commit_id": "17e8664aa6e2915c368e8eb75c6ae5e3b1942239",
        "created_at": "2018-01-22T13:19:26Z",
        "updated_at": "2018-01-22T13:19:26Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/547d19f9196512231661f427f3792f2e1f831339#r27178914",
        "id": 27178914,
        "body": "shouldn't we trigger this after `super.discoverNewShardstoSubscribe()`?\r\n\r\nAs in\r\n```\r\nList<StreamShardHandle> newShards = super.discoverNewShardsToSubscribe();\r\ninitialDiscoveryWaiter.trigger();\r\nreturn newShards;\r\n```\r\n```\r\n",
        "commit_id": "547d19f9196512231661f427f3792f2e1f831339",
        "created_at": "2018-01-29T11:15:33Z",
        "updated_at": "2018-01-29T11:15:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/30677772e29a8bbb667d098c43a0b225d5602049#r27650676",
        "id": 27650676,
        "body": "yes it's a typo. I've filed  a [JIRA](https://issues.apache.org/jira/browse/FLINK-8697).",
        "commit_id": "30677772e29a8bbb667d098c43a0b225d5602049",
        "created_at": "2018-02-19T10:53:56Z",
        "updated_at": "2018-02-19T10:53:56Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6c44d93d0a9da725ef8b1ad2a94889f79321db73#r27855304",
        "id": 27855304,
        "body": "As documented right above: `8388607`:\r\n\r\n> Long.MAX_VALUE in TB\r\n\r\nT is the unit, see the diff below that removes the existing unit.",
        "commit_id": "6c44d93d0a9da725ef8b1ad2a94889f79321db73",
        "created_at": "2018-03-01T05:33:48Z",
        "updated_at": "2018-03-01T05:34:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c8fa8d025684c2225824c54a7285bbfdec7cfddc#r28859963",
        "id": 28859963,
        "body": "you added spaces here",
        "commit_id": "c8fa8d025684c2225824c54a7285bbfdec7cfddc",
        "created_at": "2018-05-04T18:10:09Z",
        "updated_at": "2018-05-04T18:10:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ec28f92ffd042308494d9661a38ab462738611aa#r29761887",
        "id": 29761887,
        "body": "An option may be for the current and deprecated key(s) at the same time.",
        "commit_id": "ec28f92ffd042308494d9661a38ab462738611aa",
        "created_at": "2018-07-19T09:46:27Z",
        "updated_at": "2018-07-19T09:46:27Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/764da8183b6dfd0fe00eebe96fb619ca8d096047#r30029425",
        "id": 30029425,
        "body": "this doesn't look correct to me. If the problem is that all jars are put into the /lib folder, shouldn't we fix the test to only copy jars it that are actually required to run?",
        "commit_id": "764da8183b6dfd0fe00eebe96fb619ca8d096047",
        "created_at": "2018-08-10T05:20:02Z",
        "updated_at": "2018-08-10T05:20:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bbbd35c904e9e02d40fdac0ffe6f8d0b6cfaac85#r32542896",
        "id": 32542896,
        "body": "why is this not a test class in `flink-core`?",
        "commit_id": "bbbd35c904e9e02d40fdac0ffe6f8d0b6cfaac85",
        "created_at": "2019-03-01T14:51:14Z",
        "updated_at": "2019-03-01T14:51:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f421f321893c45a55d180dc8d7e18eb667d21f7b#r32795381",
        "id": 32795381,
        "body": "hmm, is the sort order still not deterministic?",
        "commit_id": "f421f321893c45a55d180dc8d7e18eb667d21f7b",
        "created_at": "2019-03-18T13:07:54Z",
        "updated_at": "2019-03-18T13:07:54Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33543545",
        "id": 33543545,
        "body": "This commit should not have been merged like this. It is addressing way too many different issues.\r\n\r\nWhat is this change in particular even doing? Why is it necessary?\r\n\r\nRenaming the script, while it does make sense on the face of it, provides little value, but can easily result in merge conflicts with concurrent efforts.\r\n\r\nThis profile only executes pure python tests from what I can tell, why do we care about scala 2.12 / java9 / hadoop 2.4.1?\r\n\r\nReworking the watchdog code to be agnostic of maven is fine, but I'd much rather had moved it into a separate `process_utils.sh`. `travis_mvn_watchdog.sh` is overloaded as is; we really shouldn't be adding more complexity.",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-15T09:27:18Z",
        "updated_at": "2019-05-15T09:27:18Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33543612",
        "id": 33543612,
        "body": "Looks like we've just added another 500mb of data to the Travis cache, i.e. 25% more data than before. This really shouldn't happen; the download/unpack & pack/upload of the cache _does_ take time.",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-15T09:30:37Z",
        "updated_at": "2019-05-15T09:30:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33546340",
        "id": 33546340,
        "body": ">In this commit, we only enabled the Python API test and I'm not sure what do you mean about `too many different issues`?\r\n\r\nSo here's what you actually did (which btw. should've totally been listed in the change log):\r\n* modified the cache to include flink-dist jars\r\n* renamed `travis_mvn_watchdog`\r\n* refactored the watchdog to be usable for arbitrary processes\r\n* added python logic to `travis_watchdog`\r\n* added python profiles to `.travis.yml`\r\n\r\nOnly the latter 2 should've been in this commit, everything else are refactorings that should be done in separate commits or even PRs.\r\n\r\n> Personally, I don't think the Travis will be updated very frequently and so I think it usually will not cause merge conflicts. Besides, code conflicts are very usual in open source project development which I don't think is such a problem. Anyway, I'm sorry if this change cause merges conflicts for you.\r\n\r\nYou did not cause problems for me; my point is for _any_ change you should consider the risk-value trade-off. Renaming the script improved _nothing_, but potentially affected other people.\r\n\r\nI'm sincerely urging you to rethink your stance on merge conflicts. Believing that we shouldn't worry about merge conflicts because they are common in opensource projects is a surefire way to, at some point, really step on someone's toe. They not only cause more work for the contributor but can also easily introduce subtle issue when resolving them.\r\nWe've been very conscious about reducing the number of merge conflicts; that's exactly why we are so picky about formatting changes and such.\r\n\r\n> [...] the Python test needs the dist jar. If we don't add the dist jar to the cache, we have to recompile the whole project for the Python tests which will take a longer time compared with the current approach. Do you have any suggestions on this? We can improve this if there are better solutions.\r\n\r\nIt is great that you considered the trade-off between caching vs rebuilding flink-dist. However you don't need all jars in flink-dist though. You need none of the example jars, nor reporters, nor filesystems, nor most libraries. The only jars you (should?) need are flink-dist and flink-table, which are only 100mb, which is quite a bit less than what we're caching right now.\r\n\r\n> As we have two ways to trigger the testing: one is PR and the other is the cron job. Regarding cron job, it's better to do complete testing which will not take too much time but can guarantee the functionality works well for scala 2.12 / java 9 / hadoop 2.4.1.\r\n\r\nThere's _no_ reason to worry about scala or hadoop. I'll give you java 9 due to py4j, but everything else should be covered on the java side. We're just running redundant tests otherwise.\r\n\r\n> Actually, I have pinged you on the PR page using the Flinkbot before merging this commit. \r\n\r\nYou pinged me [here](https://github.com/apache/flink/pull/8392#issuecomment-492027462) via githubs notification. You did not use the @flinkbot; if you did it would've requested a review from me, but I'm neither listed under reviewers nor in the [flinkbot comment](https://github.com/apache/flink/pull/8392#issuecomment-491125451).\r\nIn any case, if you feel the need to ping people, please give them some more time.",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-15T12:58:25Z",
        "updated_at": "2019-05-15T12:58:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33563437",
        "id": 33563437,
        "body": "that sounds good. In regards to 2) we will surely have to back in more jars at a later point, but excluding filesystems alone already saves us 100mb. We also don't have to cache flink-dist twice (once in /target, once in the distribution) so there's some potential here regardless.",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-16T13:38:02Z",
        "updated_at": "2019-05-16T13:38:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c52f14b55cfbec392db74fa894fd6131f268c21c#commitcomment-34354189",
        "id": 34354189,
        "body": "because it adds the chinese version of `catalog.md`",
        "commit_id": "c52f14b55cfbec392db74fa894fd6131f268c21c",
        "created_at": "2019-07-18T12:50:43Z",
        "updated_at": "2019-07-18T12:50:43Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c52f14b55cfbec392db74fa894fd6131f268c21c#commitcomment-34354203",
        "id": 34354203,
        "body": "Fair enough, I could've phrased it as `Add chinese placeholder`",
        "commit_id": "c52f14b55cfbec392db74fa894fd6131f268c21c",
        "created_at": "2019-07-18T12:51:27Z",
        "updated_at": "2019-07-18T12:51:27Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/4f0d6c170937c57934faa23141777f2304072ee4#r35854791",
        "id": 35854791,
        "body": "the name is inconsistent with literally every other metric name in this class, it would be good to adjust that. @GJL @zhuzhurk ",
        "commit_id": "4f0d6c170937c57934faa23141777f2304072ee4",
        "created_at": "2019-11-07T19:32:31Z",
        "updated_at": "2019-11-07T19:32:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/244d2db78307cd7dff1c60a664046adb6fe5c405#commitcomment-37372860",
        "id": 37372860,
        "body": "@StephanEwen I know, that's why I retained it in flink-runtime.",
        "commit_id": "244d2db78307cd7dff1c60a664046adb6fe5c405",
        "created_at": "2020-02-19T10:45:59Z",
        "updated_at": "2020-02-19T10:45:59Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1be88b13cfb14445aaf72635bc51072264f0c32d#r37946460",
        "id": 37946460,
        "body": "Doesn't this violate the code style guide regarding optionals as fields? @tillrohrmann ",
        "commit_id": "1be88b13cfb14445aaf72635bc51072264f0c32d",
        "created_at": "2020-03-20T17:16:18Z",
        "updated_at": "2020-03-20T17:16:18Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/50253c6b89e3c92cac23edda6556770a63643c90#commitcomment-39412362",
        "id": 39412362,
        "body": "Never click \"try again\"; it _always_ creates a merge commit for some reason.",
        "commit_id": "50253c6b89e3c92cac23edda6556770a63643c90",
        "created_at": "2020-05-25T07:02:29Z",
        "updated_at": "2020-05-25T07:02:29Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085#r47198384",
        "id": 47198384,
        "body": "Shouldn't this say flink-core? @sjwiesman ",
        "commit_id": "b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085",
        "created_at": "2021-02-16T20:32:06Z",
        "updated_at": "2021-02-16T20:32:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085#r47198423",
        "id": 47198423,
        "body": "this is missing the test classifier?",
        "commit_id": "b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085",
        "created_at": "2021-02-16T20:33:07Z",
        "updated_at": "2021-02-16T20:33:07Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085#r47198447",
        "id": 47198447,
        "body": "what about the `provided` scope?",
        "commit_id": "b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085",
        "created_at": "2021-02-16T20:33:47Z",
        "updated_at": "2021-02-16T20:33:47Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47757679",
        "id": 47757679,
        "body": "why was this version incremented? @rkhachatryan ",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T19:31:31Z",
        "updated_at": "2021-03-02T19:31:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47757685",
        "id": 47757685,
        "body": "Are we really doing hotfix commits now for extensions to the Public API? @rkhachatryan @AHeise ",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T19:31:36Z",
        "updated_at": "2021-03-02T19:31:36Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47765988",
        "id": 47765988,
        "body": "...so? With 1.13 not being released yet, what exactly does japicmp now compare the current API against? Isn't it now verifying that the current API is compatible with the current API, which is inherently the case?\r\nEven if it now would somehow work in that this method could no longer be removed until the release of 1.13, this doesn't sound like something we actually want to enforce (e.g, if we found a way before the release to get rid of the Optional which is rather annoying, then we should be free to do so).\r\n\r\nActually, how could this possibly be working without Flink 1.13.0 artifacts being accessible anywhere?\r\n\r\nThe addition of new methods to public API is, afaik, not a breaking change. I don't understand why we'd no longer want to compare the API against 1.12 .",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T23:26:38Z",
        "updated_at": "2021-03-02T23:27:51Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47766332",
        "id": 47766332,
        "body": "yep, we're indeed no longer checking API compatibility:\r\n\r\n```\r\n[INFO] --- japicmp-maven-plugin:0.11.0:cmp (default) @ flink-metrics-core ---\r\n[WARNING] Could not resolve org.apache.flink:flink-metrics-core:jar:1.13.0\r\n[WARNING] Could not resolve dependency with descriptor 'org.apache.flink:flink-metrics-core:1.13.0'.\r\n[WARNING] Please provide at least one resolvable old version using one of the configuration elements <oldVersion/> or <oldVersions/>.\r\n```\r\nI've filed FLINK-21571.",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T23:36:26Z",
        "updated_at": "2021-03-02T23:38:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8dca9fa852c72984ac873eae9a96bbd739e502f3#r49744255",
        "id": 49744255,
        "body": "@rmetzger Did we file a follow-up for hiding/disabling the checkpointing page in the UI for batch jobs?",
        "commit_id": "8dca9fa852c72984ac873eae9a96bbd739e502f3",
        "created_at": "2021-04-20T11:45:22Z",
        "updated_at": "2021-04-20T11:45:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61315217",
        "id": 61315217,
        "body": "why is this public?",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-03T15:50:48Z",
        "updated_at": "2021-12-03T15:50:48Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61315220",
        "id": 61315220,
        "body": "how can this be considered unused if it is referenced in the code?",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-03T15:50:51Z",
        "updated_at": "2021-12-03T15:50:51Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61315300",
        "id": 61315300,
        "body": "There's plenty of methods in here for which at this time we do not have corresponding assertj matches; why are we deprecating it then, producing over a hundred warnings for no reason?",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-03T15:52:14Z",
        "updated_at": "2021-12-03T15:52:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61315341",
        "id": 61315341,
        "body": "(and why not just migrate the existing usages that use the exception matchers)",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-03T15:52:50Z",
        "updated_at": "2021-12-03T15:52:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/34e666722a01173a6f82c7c26779111dbc4bbfae#r61773966",
        "id": 61773966,
        "body": "needs a note on whether this takes precedence over the TM/JM specific options.",
        "commit_id": "34e666722a01173a6f82c7c26779111dbc4bbfae",
        "created_at": "2021-12-12T11:52:25Z",
        "updated_at": "2021-12-12T11:52:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5c2fd493118d46ed4de5f58d3b3fee1a5306e05c#r63494752",
        "id": 63494752,
        "body": "yeah...this needs a separate ticket.",
        "commit_id": "5c2fd493118d46ed4de5f58d3b3fee1a5306e05c",
        "created_at": "2022-01-11T09:26:43Z",
        "updated_at": "2022-01-11T09:26:43Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d9d72ef142a2343f37b8b10ca6e04dc7f6ca086e#r65888896",
        "id": 65888896,
        "body": "@twalthr @matriv why is this still in the planner NOTICE?",
        "commit_id": "d9d72ef142a2343f37b8b10ca6e04dc7f6ca086e",
        "created_at": "2022-02-02T19:34:35Z",
        "updated_at": "2022-02-02T19:34:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f92548128543e07c0ad064b77b911c6049c7533f#r84482274",
        "id": 84482274,
        "body": "@rkhachatryan Could you explain why we don't need to check here whether the `changelogWriterAvailabilityProvider` is null?\r\nI have a test failure in a dev branch, failing right here with an NPE and I'm not sure what to make of it.",
        "commit_id": "f92548128543e07c0ad064b77b911c6049c7533f",
        "created_at": "2022-09-20T10:58:25Z",
        "updated_at": "2022-09-20T10:58:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb442936156583d6cf42550f3d9187da427b9c68#r88174935",
        "id": 88174935,
        "body": "The \"release branch\" term isn't mentioned before so this isn't helpful if you don't know the release guide.\r\nYou should also updated the \"create XXX branch\" step to mention release branches.\r\n\r\nIts not also inconsistent with the instructions for B).\r\n\r\n",
        "commit_id": "cb442936156583d6cf42550f3d9187da427b9c68",
        "created_at": "2022-10-28T10:32:07Z",
        "updated_at": "2022-10-28T10:32:07Z"
      }
    ]
  },
  "vijikarthi": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/c8fed99e3e85a4d27c6134cfa3e07fb3a8e1da2a#r17935989",
        "id": 17935989,
        "body": "This version (2.18.1) has some issues running scoped test case. For example it does not run, \"mvn verify -pl flink-yarn-tests -Pinclude-yarn-tests -Dtest=YARNSessionFIFOITCase#testJavaAPI\". I have reverted the version 2.19.1 and it was working fine.\n",
        "commit_id": "c8fed99e3e85a4d27c6134cfa3e07fb3a8e1da2a",
        "created_at": "2016-06-20T15:48:05Z",
        "updated_at": "2016-06-20T15:48:05Z"
      }
    ]
  },
  "mushketyk": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/abb4496781883937a935113c1e33ae1174aafa73#commitcomment-18789946",
        "id": 18789946,
        "body": "Hi Stephan.\n\nI think you are right.\nI'll update the testing as soon as possible and create a different PR to address your comment.\n",
        "commit_id": "abb4496781883937a935113c1e33ae1174aafa73",
        "created_at": "2016-08-26T09:33:57Z",
        "updated_at": "2016-08-26T09:33:57Z"
      }
    ]
  },
  "tzulitai": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/7b574cf5b6e7549ae53ea0846022c4430a979a01#commitcomment-18811598",
        "id": 18811598,
        "body": "From the original Kinesis consumer documentation, I don't think it's necessary to mention this, because there's already this in the first paragraph: \"Each subtask of the consumer is responsible for fetching data records from multiple Kinesis shards. The number of shards fetched by each subtask will change as shards are closed and created by Kinesis.\"\n\nPerhaps its because the new warning notice is a bit confusing? Especially this: \"Currently, resharding can not be handled transparently (i.e., without failing and restarting jobs) if there are idle consumer\n subtasks, which occur when the total number of shards is lower than the configured consumer parallelism.\"\n",
        "commit_id": "7b574cf5b6e7549ae53ea0846022c4430a979a01",
        "created_at": "2016-08-29T13:05:17Z",
        "updated_at": "2016-08-29T13:05:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7b574cf5b6e7549ae53ea0846022c4430a979a01#commitcomment-18811645",
        "id": 18811645,
        "body": "AFAIK, the original issue reporters set the parallelism to the number of Kinesis shards because they realized only then will the checkpoint state size not unboundly grow. They did not seem to have this misunderstanding in the beginning.\n",
        "commit_id": "7b574cf5b6e7549ae53ea0846022c4430a979a01",
        "created_at": "2016-08-29T13:08:06Z",
        "updated_at": "2016-08-29T13:08:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c#r19258651",
        "id": 19258651,
        "body": "This doesn't seem right to me. `getPartitionableState` is only called 4 times throughout this test, so I think this should be `thenReturn(listState1, listState1, listState2, listState3)`.\n",
        "commit_id": "53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c",
        "created_at": "2016-10-02T07:29:23Z",
        "updated_at": "2016-10-02T07:29:23Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c#r19258652",
        "id": 19258652,
        "body": "This should be `listState3.get`?\n",
        "commit_id": "53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c",
        "created_at": "2016-10-02T07:29:29Z",
        "updated_at": "2016-10-02T07:29:29Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c#r19258653",
        "id": 19258653,
        "body": "Should be `snapshot3`\n",
        "commit_id": "53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c",
        "created_at": "2016-10-02T07:29:33Z",
        "updated_at": "2016-10-02T07:29:33Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c#r19258654",
        "id": 19258654,
        "body": "This is actually passing only because `state3` wasn't correctly initialized, so actually `state3` and `snapshot3` are both empty.\n",
        "commit_id": "53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c",
        "created_at": "2016-10-02T07:29:40Z",
        "updated_at": "2016-10-02T07:29:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c#commitcomment-19258663",
        "id": 19258663,
        "body": "@StefanRRichter Found some bugs in `KafkaConsumerBaseTest#testSnapshotState()` here, the code happened to workaround and bypass the bugs and asserts :P \nI'll fix this test as part of [FLINK-4723](https://issues.apache.org/jira/browse/FLINK-4723) since I'll need to change this test over there.\n",
        "commit_id": "53ed6adac8cbe6b5dcb692dc9b94970f3ec5887c",
        "created_at": "2016-10-02T07:33:26Z",
        "updated_at": "2016-10-02T07:33:55Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/eece0dd05bc38b88fcb6cbcef15add7f98eab456#commitcomment-19297476",
        "id": 19297476,
        "body": "Thanks for the fix! Seems like I wasn't quite concentrated on the review :/ \n",
        "commit_id": "eece0dd05bc38b88fcb6cbcef15add7f98eab456",
        "created_at": "2016-10-05T04:15:44Z",
        "updated_at": "2016-10-05T04:16:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/eece0dd05bc38b88fcb6cbcef15add7f98eab456#r19300270",
        "id": 19300270,
        "body": "@fhueske Just realized, the setted committed offset to `partition` needs to be incremented by 1 also. This hotfix broke that. I'll hotfix this now ...\n",
        "commit_id": "eece0dd05bc38b88fcb6cbcef15add7f98eab456",
        "created_at": "2016-10-05T10:07:57Z",
        "updated_at": "2016-10-05T10:07:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/646490c4e93eca315e4bf41704f149390f8639cc#commitcomment-21009882",
        "id": 21009882,
        "body": "@StephanEwen Yes. We discussed that in https://issues.apache.org/jira/browse/FLINK-5728 with some other aspects regarding the `setFlushOnCheckpoint` and `setLogFailuresOnly` methods, so it was kept as a separate issue.",
        "commit_id": "646490c4e93eca315e4bf41704f149390f8639cc",
        "created_at": "2017-02-23T06:31:06Z",
        "updated_at": "2017-02-23T06:31:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/547d19f9196512231661f427f3792f2e1f831339#r27231640",
        "id": 27231640,
        "body": "Yes, that is correct. Will fix.",
        "commit_id": "547d19f9196512231661f427f3792f2e1f831339",
        "created_at": "2018-01-31T11:29:25Z",
        "updated_at": "2018-01-31T11:29:25Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a2533f406d46b1c5acb5f70c263f9afad839dffe#r27262148",
        "id": 27262148,
        "body": "Question regarding this change:\r\nWhy do we already test for `v1_5`? I think we should / can only add that variant once we cut the `release-1.5` branch. Otherwise, strictly speaking, any savepoints taken with the current `master` snapshot is not a proper 1.5 savepoint.",
        "commit_id": "a2533f406d46b1c5acb5f70c263f9afad839dffe",
        "created_at": "2018-02-01T13:28:15Z",
        "updated_at": "2018-02-01T13:28:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32022489",
        "id": 32022489,
        "body": "That makes sense!",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T14:26:10Z",
        "updated_at": "2019-01-22T14:26:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32022506",
        "id": 32022506,
        "body": "We can actually. It's just that it has been more or less a \"convention\" that we return -1 for serializers that are used solely for state serialization.\r\n\r\nFor the actual length, it would be `Integer.BYTES + Long.BYTES`, correct?",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T14:27:15Z",
        "updated_at": "2019-01-22T14:27:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32022512",
        "id": 32022512,
        "body": "Good idea, will add the comment.",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T14:27:41Z",
        "updated_at": "2019-01-22T14:27:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/898f6c54035206a97cfbb04bdad4f7568264dab2#r32022527",
        "id": 32022527,
        "body": "Hmm, this file shouldn't have been added here, instead should have been added in a later commit.\r\nSomething might have went wrong while I was cherry-picking the changes.\r\nI'll remove this file from this commit.",
        "commit_id": "898f6c54035206a97cfbb04bdad4f7568264dab2",
        "created_at": "2019-01-22T14:29:05Z",
        "updated_at": "2019-01-22T14:29:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/62dd050ba1566c169f29f83ed6289812f8b83688#r34048243",
        "id": 34048243,
        "body": "Add `@Internal`",
        "commit_id": "62dd050ba1566c169f29f83ed6289812f8b83688",
        "created_at": "2019-06-24T03:42:45Z",
        "updated_at": "2019-06-24T03:42:45Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/38eaa6611befd0ab769d9190dfe74f6271935e48#r34048256",
        "id": 34048256,
        "body": "nit: this could use a better naming, e.g. `ERROR_MSG` or the like.",
        "commit_id": "38eaa6611befd0ab769d9190dfe74f6271935e48",
        "created_at": "2019-06-24T03:46:31Z",
        "updated_at": "2019-06-24T03:46:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/38eaa6611befd0ab769d9190dfe74f6271935e48#r34048262",
        "id": 34048262,
        "body": "Public constructors should have appropriate argument checks.",
        "commit_id": "38eaa6611befd0ab769d9190dfe74f6271935e48",
        "created_at": "2019-06-24T03:48:07Z",
        "updated_at": "2019-06-24T03:48:07Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/38eaa6611befd0ab769d9190dfe74f6271935e48#r34048268",
        "id": 34048268,
        "body": "nit: extra words - `may`, `by`",
        "commit_id": "38eaa6611befd0ab769d9190dfe74f6271935e48",
        "created_at": "2019-06-24T03:49:35Z",
        "updated_at": "2019-06-24T03:57:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/38eaa6611befd0ab769d9190dfe74f6271935e48#r34048425",
        "id": 34048425,
        "body": "I find making this an `AutoClosable` quite confusing, just for the functionality of closing of state registration after open. On the call site, users would wrap this within a try-with-resource clause, which just doesn't directly imply anything about state registration.\r\n\r\nAs an alternative, simply having a `disableStateRegistration()` method that should be called on the call site after `open()` returns is much more explicit and easily understandable.",
        "commit_id": "38eaa6611befd0ab769d9190dfe74f6271935e48",
        "created_at": "2019-06-24T04:21:26Z",
        "updated_at": "2019-06-24T04:22:47Z"
      }
    ]
  },
  "NicoK": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/79d7e3017efe7c96e449e6f339fd7184ef3d1ba2#r20200802",
        "id": 20200802,
        "body": "was it necessary to increase this dependency?",
        "commit_id": "79d7e3017efe7c96e449e6f339fd7184ef3d1ba2",
        "created_at": "2016-12-15T14:38:40Z",
        "updated_at": "2016-12-15T14:38:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/79d7e3017efe7c96e449e6f339fd7184ef3d1ba2#r20200919",
        "id": 20200919,
        "body": "seems that `./build_docs -p` is broken, i.e. it does neither enable auto-regeneration nor serve the docs locally",
        "commit_id": "79d7e3017efe7c96e449e6f339fd7184ef3d1ba2",
        "created_at": "2016-12-15T14:46:41Z",
        "updated_at": "2016-12-15T14:46:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/39345e0863357e90cf7ddc66a5ffc6b20e5ac2ef#r40401122",
        "id": 40401122,
        "body": "@Myasuka can you add a follow-up PR to `master` and `release-1.11` that fixes the typos here? Thanks",
        "commit_id": "39345e0863357e90cf7ddc66a5ffc6b20e5ac2ef",
        "created_at": "2020-07-06T15:50:09Z",
        "updated_at": "2020-07-06T15:50:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ad0d5c8e256e6db5f6a51e6374cdc262283c912d#r46647022",
        "id": 46647022,
        "body": "There's no strict need for that, it just creates a localized context for variable declarations and groups the lines together.",
        "commit_id": "ad0d5c8e256e6db5f6a51e6374cdc262283c912d",
        "created_at": "2021-02-02T11:22:07Z",
        "updated_at": "2021-02-02T11:22:07Z"
      }
    ]
  },
  "rohitagarwal003": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/6342d6db1de5f38a921732e35abd83e6c5b9305a#r20600038",
        "id": 20600038,
        "body": "@StephanEwen This would set allowedLateness for Processing time windows as well. Do we want that?",
        "commit_id": "6342d6db1de5f38a921732e35abd83e6c5b9305a",
        "created_at": "2017-01-24T21:28:35Z",
        "updated_at": "2017-01-24T21:28:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6342d6db1de5f38a921732e35abd83e6c5b9305a#r20615018",
        "id": 20615018,
        "body": "I thought `allowedLateness` affected when we purged windows. Wouldn't this result in keeping processing time windows around for longer than we should?",
        "commit_id": "6342d6db1de5f38a921732e35abd83e6c5b9305a",
        "created_at": "2017-01-25T19:13:59Z",
        "updated_at": "2017-01-25T19:13:59Z"
      }
    ]
  },
  "Fokko": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/32e1675aa38eec4a15272d62977dfe3ddbe92401#commitcomment-20632930",
        "id": 20632930,
        "body": "Did not know this, thanks.",
        "commit_id": "32e1675aa38eec4a15272d62977dfe3ddbe92401",
        "created_at": "2017-01-26T21:29:57Z",
        "updated_at": "2017-01-26T21:29:57Z"
      }
    ]
  },
  "TwitRco": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/036f9d9d8fee095165e999e19c395fab45c7d9cd#r20650607",
        "id": 20650607,
        "body": "\r\n\r\n![avatar](https://cloud.githubusercontent.com/assets/1036668/22395721/3932e6a8-e546-11e6-8c56-ab878d8b3773.png)\r\n",
        "commit_id": "036f9d9d8fee095165e999e19c395fab45c7d9cd",
        "created_at": "2017-01-28T09:40:50Z",
        "updated_at": "2017-01-28T09:40:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/bd2fd1ae40ef2f34a2a3a050df865c5e04cee89f#commitcomment-33571044",
        "id": 33571044,
        "body": "Join list ",
        "commit_id": "bd2fd1ae40ef2f34a2a3a050df865c5e04cee89f",
        "created_at": "2019-05-16T22:43:06Z",
        "updated_at": "2019-05-16T22:43:06Z"
      }
    ]
  },
  "StefanRRichter": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/3400a87dce9940ac8da95c89ff9791ca6a687776#r20654494",
        "id": 20654494,
        "body": "I am not sure about the guarantees we have in Akka and the underlying acknowledgement chain, but depending on how this works, is there a possibility that TM acknowledges a checkpoint, the JM receives the acknowledgment, marks the checkpoint as complete but the JM's message to the TM to acknowledge back is lost / timeout, leading to an exception in the TM's call. Would we have a data loss or does it work differently?",
        "commit_id": "3400a87dce9940ac8da95c89ff9791ca6a687776",
        "created_at": "2017-01-29T14:39:48Z",
        "updated_at": "2017-01-29T14:39:48Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/9141379f6d2654886d48154b453170cc23b89a87#r22558757",
        "id": 22558757,
        "body": "They will trigger `forceSeek`, as they should.",
        "commit_id": "9141379f6d2654886d48154b453170cc23b89a87",
        "created_at": "2017-06-15T08:51:28Z",
        "updated_at": "2017-06-15T08:51:34Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b609ede4b4060bcc94b7e936726369983f3b6bfe#commitcomment-31219217",
        "id": 31219217,
        "body": "Thanks @xccui, the problem comes from the cherrypick to the 1.6 branch. I commit a fix.",
        "commit_id": "b609ede4b4060bcc94b7e936726369983f3b6bfe",
        "created_at": "2018-11-08T08:33:10Z",
        "updated_at": "2018-11-08T08:33:10Z"
      }
    ]
  },
  "EronWright": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/e2f01b81e801a5ae6610d06fb9e2e3f54bbf34d9#r21361837",
        "id": 21361837,
        "body": "You took the wrong shortcut here to access the Flink configuration.   This code erroneously says, \"get the configured framework name *from the JM's dynamic configuration only*\".  This code would fail if the `mesos.rm.framework.name` property were instead set in the JM's static configuration.\r\n\r\nIt is undesirable to use the raw configuration at this stage anyway.   You probably notice that Flink 'eagerly' processes its configuration into typed objects like `MesosConfiguration`   Let's use that here too.   Please change `LaunchableMesosWorker` constructor to take `MesosConfiguration` as a parameter.   Use `mesosConfig.frameworkInfo().getName()` when setting `ENV_FRAMEWORK_NAME`.   Change `MesosFlinkResourceManager::createLaunchableMesosWorker` to pass the `mesosConfig` that it has.\r\n\r\n\r\nPlease adjust the handling of `TASK_MANAGER_HOSTNAME_KEY` in the same way.\r\n\r\nThanks!",
        "commit_id": "e2f01b81e801a5ae6610d06fb9e2e3f54bbf34d9",
        "created_at": "2017-03-16T22:06:10Z",
        "updated_at": "2017-03-16T22:06:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/601a94802ceb81eb17aa6977eb7a35baef929c02#r21361863",
        "id": 21361863,
        "body": "I would be happy to see this renamed to `mesos.resourcemanager.tasks.hostname` for simplicity.",
        "commit_id": "601a94802ceb81eb17aa6977eb7a35baef929c02",
        "created_at": "2017-03-16T22:07:41Z",
        "updated_at": "2017-03-16T22:07:41Z"
      }
    ]
  },
  "rtudoran": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/d4665a00a4262f89b166895f73a54daab2f25e1c#r21554770",
        "id": 21554770,
        "body": "@fhueske @sunjincheng121 This is not ok or fair to create this.  Me and @stefanobortoli  already created this and this creates conflict over our branches without bringing anything. And in fact it is exactly the code we created. \r\n...i think it only creates additional work and delays our merging...",
        "commit_id": "d4665a00a4262f89b166895f73a54daab2f25e1c",
        "created_at": "2017-03-30T09:11:03Z",
        "updated_at": "2017-03-30T09:11:03Z"
      }
    ]
  },
  "taizilongxu": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/2437da6e54cb48c4e29116b8789fbe4782b17ea7#r24300072",
        "id": 24300072,
        "body": "I thinks the code is wrong in scala, it's not work, is there any one to fix it?",
        "commit_id": "2437da6e54cb48c4e29116b8789fbe4782b17ea7",
        "created_at": "2017-09-14T11:18:15Z",
        "updated_at": "2017-09-14T11:18:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c93205b4abe643d6dd798c3180d68ab8d02eded5#r43167743",
        "id": 43167743,
        "body": "Hi, want to know why not comma separated just like kafka broker...",
        "commit_id": "c93205b4abe643d6dd798c3180d68ab8d02eded5",
        "created_at": "2020-10-12T10:52:22Z",
        "updated_at": "2020-10-12T10:52:22Z"
      }
    ]
  },
  "p16i": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/cce40c5cd4aaff446bb4bec8918d2fda37649e0a#r24528598",
        "id": 24528598,
        "body": "Is it possible that the class will be disappear after the first `get()` from if's condition?",
        "commit_id": "cce40c5cd4aaff446bb4bec8918d2fda37649e0a",
        "created_at": "2017-09-24T18:41:35Z",
        "updated_at": "2017-09-24T18:41:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/9016cce503b4d471b5a49f0abccc196945ada97e#r24529391",
        "id": 24529391,
        "body": "Can we simplify it to the code below?\r\n```\r\nClass generatedClass = null\r\nWeakReference<Class> fromCache = generatedClassCache.getOrDefault(cacheKey, null);\r\n\r\ngeneratedClass = fromCache != null ? fromCache.get() : null;\r\n\r\nif ( genenetedClass == null ) {\r\n// cache miss\r\n...\r\n}\r\n```\r\n\r\nSo, we don't need to introduce `cacheHit` variable.",
        "commit_id": "9016cce503b4d471b5a49f0abccc196945ada97e",
        "created_at": "2017-09-24T20:00:09Z",
        "updated_at": "2017-09-24T20:00:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ff3a35e93e858e30debcb1e85cc056045c1fe2a0#commitcomment-24687576",
        "id": 24687576,
        "body": "\ud83d\udc4d ",
        "commit_id": "ff3a35e93e858e30debcb1e85cc056045c1fe2a0",
        "created_at": "2017-10-01T19:27:25Z",
        "updated_at": "2017-10-01T19:27:25Z"
      }
    ]
  },
  "kl0u": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/f2c3ff3ee3a5121665e32acebbaeee7bbb380e7f#commitcomment-25306091",
        "id": 25306091,
        "body": "@zentol  reported instabilities so for now I ignored them until I fix them.",
        "commit_id": "f2c3ff3ee3a5121665e32acebbaeee7bbb380e7f",
        "created_at": "2017-10-31T11:48:56Z",
        "updated_at": "2017-10-31T11:48:56Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dc9e4494dddfed36432e6bbf6cd3231530bc2e01#commitcomment-34980173",
        "id": 34980173,
        "body": "I agree @TisonKun but @zentol pointed out that some users are programming directly again the `ClusterClient` and this would be a breaking change for them.",
        "commit_id": "dc9e4494dddfed36432e6bbf6cd3231530bc2e01",
        "created_at": "2019-09-06T13:58:50Z",
        "updated_at": "2019-09-06T13:58:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dc9e4494dddfed36432e6bbf6cd3231530bc2e01#commitcomment-34980751",
        "id": 34980751,
        "body": "I agree, I was also confused. This is why I removed the `shutdown()` in the first place. I agree that we should discuss about our interface stability guarantees for some parts of the codebase.",
        "commit_id": "dc9e4494dddfed36432e6bbf6cd3231530bc2e01",
        "created_at": "2019-09-06T14:35:15Z",
        "updated_at": "2019-09-06T14:35:15Z"
      }
    ]
  },
  "fpompermaier": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/b5caaef82add4a6f424094d526700c77b011724e#r27100256",
        "id": 27100256,
        "body": "Why these settings here...? I've drafted a connector for es 5.6.5 and I removed these 2 lines..but then I have to set es.set.netty.runtime.available.processors=false otherwise there's an Exception related to a concurrent call to NettyRuntime$AvailableProcessorsHolder.setAvailableProcessors()...Moreover, this exception cannot be reproduced in a Local cluster (i.e. while debugging from the IDE) but it happens only on the cluster when a TaskManager use multiple slots simultaneoulsy",
        "commit_id": "b5caaef82add4a6f424094d526700c77b011724e",
        "created_at": "2018-01-25T13:57:18Z",
        "updated_at": "2018-01-25T13:57:18Z"
      }
    ]
  },
  "jimmec": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/30677772e29a8bbb667d098c43a0b225d5602049#r27642949",
        "id": 27642949,
        "body": "Is DummyFlink`Kafka`Consumer a typo?? It's at the least inconsistent with the comment above this line.",
        "commit_id": "30677772e29a8bbb667d098c43a0b225d5602049",
        "created_at": "2018-02-18T23:59:23Z",
        "updated_at": "2018-02-18T23:59:23Z"
      }
    ]
  },
  "kbialek": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/13bb32ef891428fe9e0e14b6ecc525f15c52c40a#commitcomment-27763936",
        "id": 27763936,
        "body": "This change broke my flink-consul implementation. That is not a big deal, however I wonder if it wouldn't break ZK recovery. As far as I understood the code in ZooKeeperCompletedCheckpointStore.recover() it compares two Lists of CompletedCheckpoints (line 201). When there is no equals() defined in CompletedCheckpoint class those comparision will never succeed.\r\n\r\n",
        "commit_id": "13bb32ef891428fe9e0e14b6ecc525f15c52c40a",
        "created_at": "2018-02-24T16:43:26Z",
        "updated_at": "2018-02-24T16:43:26Z"
      }
    ]
  },
  "yuqi1129": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/6c44d93d0a9da725ef8b1ad2a94889f79321db73#r27853406",
        "id": 27853406,
        "body": "Why the value `TM_MAX_OFFHEAP_SIZE` ends with `T`, this is not consistent with before that it's a number. I think you can't add `T` in line 92\r\nAddition, this specific number of `8388607` has a real meaning that you choose this number?",
        "commit_id": "6c44d93d0a9da725ef8b1ad2a94889f79321db73",
        "created_at": "2018-03-01T02:14:36Z",
        "updated_at": "2018-03-01T02:14:36Z"
      }
    ]
  },
  "Aitozi": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/8c89f3c6b5ebd0334176d9e7e57b38b4d39a594a#commitcomment-29640344",
        "id": 29640344,
        "body": "Hi, do you discuss about the logic change of Trigger in  the PR: https://github.com/apache/flink/pull/6224",
        "commit_id": "8c89f3c6b5ebd0334176d9e7e57b38b4d39a594a",
        "created_at": "2018-07-09T11:42:32Z",
        "updated_at": "2018-07-09T11:42:32Z"
      }
    ]
  },
  "tisonkun": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/8231b62ff42aae53ca3a7b552980838ccab824ab#r29765803",
        "id": 29765803,
        "body": "here is a question from 4 years later.\r\n\r\nwhy this method call `ensureCapacity` twice. it seems to solve some issue about concurrency but as the change made in #6353 , this method throws a out of index exception. so i try to add a synchronized block to make sure it is thread-safe #6370 . definitely i think my code is not that perfect. so i come to here, wonder the original purpose of this code and ask advice about the two PRs mentioned above\r\n\r\n@StephanEwen looking forward to your advice. thanks in advance!",
        "commit_id": "8231b62ff42aae53ca3a7b552980838ccab824ab",
        "created_at": "2018-07-19T14:45:09Z",
        "updated_at": "2018-07-19T14:45:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a95ec5acf259884347ae539913bcffcad5bfc340#r29915663",
        "id": 29915663,
        "body": "What if the situation below?\r\n\r\n1. `rmLeaderRetrievalService.notifyListener(firstResourceManagerAddress, resourceManagerId.toUUID());`\r\n2. before registration success, what exactly, `resourceManagerConnection != null && establishedResourceManagerConnection == null`, now runs `rmLeaderRetrievalService.notifyListener(null, null);`, which cause `closeResourceManagerConnection` execute.\r\n3. then in `closeResourceManagerConnection`, it jumps\r\n```\r\nif (establishedResourceManagerConnection != null) {\r\n    dissolveResourceManagerConnection(establishedResourceManagerConnection, cause);\r\n    establishedResourceManagerConnection = null;\r\n}\r\n```\r\nand now in method `establishResourceManagerConnection`, `establishedResourceManagerConnection = new ...`,\r\nand then `closeResourceManagerConnection` continues,\r\n```\r\n        if (resourceManagerConnection != null) {\r\n\t\t\t// stop a potentially ongoing registration process\r\n\t\t\tresourceManagerConnection.close();\r\n\t\t\tresourceManagerConnection = null;\r\n\t\t}\r\n```\r\nso we arrive where `resourceManagerConnection == null && establishedResourceManagerConnection != null`",
        "commit_id": "a95ec5acf259884347ae539913bcffcad5bfc340",
        "created_at": "2018-08-01T03:40:17Z",
        "updated_at": "2018-08-01T03:40:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a95ec5acf259884347ae539913bcffcad5bfc340#r29915704",
        "id": 29915704,
        "body": "To be short, since `establishedResourceManagerConnection` build in async, is it possible that we meet a bug when disconnect while establishing?\r\nPlease note that although we check `resourceManagerConnection != null` before establish `establishedResourceManagerConnection`, `resourceManagerConnection` is still possibly changed.",
        "commit_id": "a95ec5acf259884347ae539913bcffcad5bfc340",
        "created_at": "2018-08-01T03:44:46Z",
        "updated_at": "2018-08-01T03:44:46Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a95ec5acf259884347ae539913bcffcad5bfc340#r29931969",
        "id": 29931969,
        "body": "Yes, you're right. Its name `runAsync` misleads me :P",
        "commit_id": "a95ec5acf259884347ae539913bcffcad5bfc340",
        "created_at": "2018-08-02T06:38:10Z",
        "updated_at": "2018-08-02T06:38:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/8ed85fe49b7595546a8f968e0faa1fa7d4da47ec#r29966522",
        "id": 29966522,
        "body": "what is the design here, passing `execution`, and no use it or remain the function body `// nothing to do`? I check their use in master(ce96c409148d1a9bc40f581e13900818b5f11f6a) code base and get confused.",
        "commit_id": "8ed85fe49b7595546a8f968e0faa1fa7d4da47ec",
        "created_at": "2018-08-06T04:15:32Z",
        "updated_at": "2018-08-06T04:16:24Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/eb3a1741032795ab8db76b40c3614820a2529166#commitcomment-29981268",
        "id": 29981268,
        "body": "@suez1224 amend commit message?",
        "commit_id": "eb3a1741032795ab8db76b40c3614820a2529166",
        "created_at": "2018-08-07T03:25:13Z",
        "updated_at": "2018-08-07T03:25:13Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c7eb6acaf95a6656ec6bd0a0b401c1944473e7f2#r30308364",
        "id": 30308364,
        "body": "@tillrohrmann What is the purpose to change access level here?",
        "commit_id": "c7eb6acaf95a6656ec6bd0a0b401c1944473e7f2",
        "created_at": "2018-08-28T06:45:22Z",
        "updated_at": "2018-08-28T06:45:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30330617",
        "id": 30330617,
        "body": "Hi @tillrohrmann , I am planning to rework `JobManagerFailsITCase` and `JobManagerTest` into `JobMasterITCase` and `JobMasterHAITCase`. That is, reorganize the legacy tests, make them neat and cover cases explicitly. The JIRA and PR would follow before this weekend.\r\n\r\nHere comes a problem. I wonder if the statement, `TestingUtils.stopActorGracefully(jmGateway)`, cause a jm failover. For \"jm failover\", I mean a real world failover, without calling Flink internal `postStop` logic or something like it. I'd like to add more jm failover test cases list below, for the further implement of jm failover with `RECONCILING` state.\r\n\r\n1. Streaming task with jm failover.\r\n2. Streaming task with jm failover concurrent to task fail.\r\n3. Batch task with jm failover.\r\n4. Batch task with jm failover concurrent to task fail.\r\n5. Batch task with jm failover when some vertex has already been FINISHED.",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-08-29T15:52:03Z",
        "updated_at": "2018-08-29T15:52:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30330887",
        "id": 30330887,
        "body": "Yes. First thanks for your explain about akka underneath. And by naming \"rework\", I'd like more to do what you say, \"ported to the Filp-6 code base\". It is no goal to \"harden\" this legacy code, but aim to porting same/similar test cases in new code base.",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-08-29T16:18:21Z",
        "updated_at": "2018-08-29T16:18:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30330904",
        "id": 30330904,
        "body": "FYI, here is the [JIRA](https://issues.apache.org/jira/browse/FLINK-10256) associated.",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-08-29T16:19:12Z",
        "updated_at": "2018-08-29T16:19:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30371761",
        "id": 30371761,
        "body": "Hi @tillrohrmann , I met a problem when porting JM failover case to FLIP-6 codebase.\r\n\r\nOn legacy codebase, we build a MiniCluster directly on actor system, while on FLIP-6 codebase, Flink use a wrapped `RpcService` to communicate with. In such case, if we call `stopService`, it acts a `poststop` for the `RpcEndpoint`. But for jm failover, we would prefer a \"force shutdown\" like process killed or actor poisonpilled.\r\n\r\nI think it cases on JobMaster failover are important since they are common failures, and it is good to port them to FILP-6 codebase. Thus I wonder how could I simulate such a case with FILP-6 MiniCluster?",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-09-03T07:26:19Z",
        "updated_at": "2018-09-03T07:26:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6356128865bff7463bf03185d18b129ed3633bc2#commitcomment-30432097",
        "id": 30432097,
        "body": "Hi @tillrohrmann, how about the replacements? we still have DetachedMode right? I see our current codebase still depend on these methods.",
        "commit_id": "6356128865bff7463bf03185d18b129ed3633bc2",
        "created_at": "2018-09-07T15:32:14Z",
        "updated_at": "2018-09-07T15:32:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/6356128865bff7463bf03185d18b129ed3633bc2#commitcomment-30432454",
        "id": 30432454,
        "body": "The main usages of it are\r\n\r\n1. `FlinkYarnSessionCli#run`, this can be resolved by checking whether `allOptions` has DETACHED options locally.\r\n\r\n2. when `AbstractYarnClusterDescriptor` start a AM, it sets `appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached));`. At this point it seems that YarnClusterDescriptor should know whether or not it is in detached mode.\r\n\r\nIf usage 2 is irrelevant now, we can get rid of deprecated method in FLIP-6 codebase.",
        "commit_id": "6356128865bff7463bf03185d18b129ed3633bc2",
        "created_at": "2018-09-07T16:03:55Z",
        "updated_at": "2018-09-07T16:03:55Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ddd6a99a95b56c52ea5b5153b7270b578f5479bc#r30515610",
        "id": 30515610,
        "body": "Yes, that works for me. I response at the corresponding [JIRA](https://issues.apache.org/jira/browse/FLINK-10256). Let's move the further discussion there ( if there is :-)",
        "commit_id": "ddd6a99a95b56c52ea5b5153b7270b578f5479bc",
        "created_at": "2018-09-15T05:57:07Z",
        "updated_at": "2018-09-15T05:57:07Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0735b5b935b0c0757943e2d58047afcfb9949560#r30525400",
        "id": 30525400,
        "body": "Hi @tillrohrmann ! I find this class use in `Task` but it looks do nothing. Is it part of legacy code now?",
        "commit_id": "0735b5b935b0c0757943e2d58047afcfb9949560",
        "created_at": "2018-09-17T07:25:18Z",
        "updated_at": "2018-09-17T07:25:18Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f90f5e5832425f999c5ce564c25284b912ebab18#commitcomment-30789889",
        "id": 30789889,
        "body": "Thus we can remove `JobSubmitTest.java`?",
        "commit_id": "f90f5e5832425f999c5ce564c25284b912ebab18",
        "created_at": "2018-10-05T16:21:38Z",
        "updated_at": "2018-10-05T16:21:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/09d1c33c9016748ee971a1a906b1e2549eb3f3ee#r30898826",
        "id": 30898826,
        "body": "Hi @StephanEwen ! Sorry for bothering.\r\nI want to question that why we set `allowQueuedScheduling` to `false` here? I think FLIP-6 always enable it  because we need to request from the ResourceManager.\r\nSee also [lines of this commit](https://github.com/apache/flink/commit/722274519fbf258531707ef85df4e1846f2fa4d4#diff-a0ab8aace3d6bf96f223d57b532b8418R631).",
        "commit_id": "09d1c33c9016748ee971a1a906b1e2549eb3f3ee",
        "created_at": "2018-10-15T05:42:49Z",
        "updated_at": "2018-10-15T05:42:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/700377a86155061679122ad33e595eb079bb1ca6#commitcomment-30957357",
        "id": 30957357,
        "body": "nice speed up :-) learn it",
        "commit_id": "700377a86155061679122ad33e595eb079bb1ca6",
        "created_at": "2018-10-18T15:28:57Z",
        "updated_at": "2018-10-18T15:28:57Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a1ba9f1126270d53168394211a99e354aa2cf20d#r32146767",
        "id": 32146767,
        "body": "Hi @StephanEwen now `SlotPool#start` itself is marked `throws Exception`, so I'm wonder if this TODO is still valid. If it is, how?",
        "commit_id": "a1ba9f1126270d53168394211a99e354aa2cf20d",
        "created_at": "2019-02-01T13:22:21Z",
        "updated_at": "2019-02-01T13:22:21Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/064379705f36aaea927c44bb303a867c0c66265d#r32471762",
        "id": 32471762,
        "body": "@tillrohrmann I'm not quite sure why the reconnection could cause NodeCache flush. Otherwise, why we add this statement.",
        "commit_id": "064379705f36aaea927c44bb303a867c0c66265d",
        "created_at": "2019-02-26T03:08:34Z",
        "updated_at": "2019-02-26T03:09:41Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/a954ea113bc29a4480af579387c6e9b81bd76f85#r33263279",
        "id": 33263279,
        "body": "Is it possible that `userJarFiles` now become a local variable? Checking out the nightly code I see no usage of it outside here. Seems like `userJarFiles` now contains only user code jars from the provided JobGraph\r\n\r\ncc @tillrohrmann ",
        "commit_id": "a954ea113bc29a4480af579387c6e9b81bd76f85",
        "created_at": "2019-04-22T15:27:15Z",
        "updated_at": "2019-04-22T15:27:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/e7ac74087e7309ad049f67fde8326c77518044f8#r33884835",
        "id": 33884835,
        "body": "Why we do another serialization here? Akka has already serialized message in its scope. I see the doc above says\r\n\r\n>In order to fail fast and report an appropriate error message to the user, the method name, the parameter types and the arguments are eagerly serialized.\r\n\r\nIs it all the reason we do this?",
        "commit_id": "e7ac74087e7309ad049f67fde8326c77518044f8",
        "created_at": "2019-06-11T02:04:05Z",
        "updated_at": "2019-06-11T02:04:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/e7ac74087e7309ad049f67fde8326c77518044f8#r33958649",
        "id": 33958649,
        "body": "Checkout the commit msg and it seems that we exactly serialized for a customized error handling.",
        "commit_id": "e7ac74087e7309ad049f67fde8326c77518044f8",
        "created_at": "2019-06-17T03:54:15Z",
        "updated_at": "2019-06-17T03:54:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c52f14b55cfbec392db74fa894fd6131f268c21c#commitcomment-34352464",
        "id": 34352464,
        "body": "Why is the commit message written as \"Add chinese version\"?",
        "commit_id": "c52f14b55cfbec392db74fa894fd6131f268c21c",
        "created_at": "2019-07-18T10:39:36Z",
        "updated_at": "2019-07-18T10:39:36Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dc9e4494dddfed36432e6bbf6cd3231530bc2e01#commitcomment-34980116",
        "id": 34980116,
        "body": "Hi @kl0u! I wonder what the backwards compatibility concerns here? I cannot find any usage and don't know how backwards compatibility breaks here.",
        "commit_id": "dc9e4494dddfed36432e6bbf6cd3231530bc2e01",
        "created_at": "2019-09-06T13:54:04Z",
        "updated_at": "2019-09-06T13:54:04Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dc9e4494dddfed36432e6bbf6cd3231530bc2e01#commitcomment-34980406",
        "id": 34980406,
        "body": "Thanks for your explanation @kl0u. In fact my colleagues develop a platform based on Flink and they also program directly against `ClusterClient` for what we propose to be changed in client apis side. However, when we bump to a new version, it is planned we make some corresponding adaptations.\r\n\r\nAlso I'd like to point out that `ClusterClient` is not an interface marked as `@Public` or `@PublicEvolving`. Given that we are blocked by some legacy code accidentally marked as `@Public(Evolving)` while some interfaces we want to provide backward compatibility are not marked. I think it could be the time or so to discuss our InterfaceAudience policy. At least it would be a pity if we don't address this InterfaceAudience issue towards 2.0. ",
        "commit_id": "dc9e4494dddfed36432e6bbf6cd3231530bc2e01",
        "created_at": "2019-09-06T14:12:31Z",
        "updated_at": "2019-09-06T14:12:31Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c95e9f642288bb2816cf84868709ea2543a90ae5#r35115341",
        "id": 35115341,
        "body": "Is there any other approach we verify that job is running except add a method `RestClusterClient#getJobDetails`?",
        "commit_id": "c95e9f642288bb2816cf84868709ea2543a90ae5",
        "created_at": "2019-09-17T13:10:14Z",
        "updated_at": "2019-09-17T13:10:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c95e9f642288bb2816cf84868709ea2543a90ae5#r35204170",
        "id": 35204170,
        "body": "I'm hesitated whether `RestClusterClient.getJobDetails` should be a `ClusterClient` level method.. ",
        "commit_id": "c95e9f642288bb2816cf84868709ea2543a90ae5",
        "created_at": "2019-09-24T01:40:32Z",
        "updated_at": "2019-09-24T01:40:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/89634d7fb44de1c763271ef4c24aaaf048e5ae20#r36132530",
        "id": 36132530,
        "body": "@aljoscha I'd like to know whether or not this change makes user previous setup broken due to we also set `stopAtNonOptions` as `true`. Or if we say we should remove options with no power I think `-yst` can be removed also.",
        "commit_id": "89634d7fb44de1c763271ef4c24aaaf048e5ae20",
        "created_at": "2019-11-26T05:16:50Z",
        "updated_at": "2019-11-26T05:16:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/89634d7fb44de1c763271ef4c24aaaf048e5ae20#r36150795",
        "id": 36150795,
        "body": "Make sense. Then we should remove \"-yst\" i.e. \"streaming\" option also.",
        "commit_id": "89634d7fb44de1c763271ef4c24aaaf048e5ae20",
        "created_at": "2019-11-27T01:40:37Z",
        "updated_at": "2019-11-27T01:40:37Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/89634d7fb44de1c763271ef4c24aaaf048e5ae20#r36150809",
        "id": 36150809,
        "body": "FYI [FLINK-14957](https://issues.apache.org/jira/browse/FLINK-14957)",
        "commit_id": "89634d7fb44de1c763271ef4c24aaaf048e5ae20",
        "created_at": "2019-11-27T01:44:11Z",
        "updated_at": "2019-11-27T01:44:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c910d71c358ab55763e77fdd2be2811dcdec6c41#r36214308",
        "id": 36214308,
        "body": "if we don't specific `-skip.npm` here, is `npm` required?",
        "commit_id": "c910d71c358ab55763e77fdd2be2811dcdec6c41",
        "created_at": "2019-12-02T02:14:38Z",
        "updated_at": "2019-12-02T02:14:38Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/45397fe974e1390cd39a34fc2eb216f3771ddf06#r36685668",
        "id": 36685668,
        "body": "I just notice that `RegisterApplicationMasterResponse#getContainersFromPreviousAttempts` is a public method. So I'm confused why we have to use reflect for a method call. Shall we directly call `RegisterApplicationMasterResponse#getContainersFromPreviousAttempts` in `YarnResourceManager`?\r\n\r\ncc @GJL @tillrohrmann ",
        "commit_id": "45397fe974e1390cd39a34fc2eb216f3771ddf06",
        "created_at": "2020-01-07T03:36:14Z",
        "updated_at": "2020-01-07T03:36:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/45397fe974e1390cd39a34fc2eb216f3771ddf06#r36685671",
        "id": 36685671,
        "body": "From the document it says \"This saves computation time on subsequent calls.\" but why? I guess from a previous version of YARN the method is not `public`?",
        "commit_id": "45397fe974e1390cd39a34fc2eb216f3771ddf06",
        "created_at": "2020-01-07T03:37:17Z",
        "updated_at": "2020-01-07T03:37:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/45397fe974e1390cd39a34fc2eb216f3771ddf06#r36686777",
        "id": 36686777,
        "body": "FYI I created a JIRA for tracking the removal of this https://issues.apache.org/jira/browse/FLINK-15496 .",
        "commit_id": "45397fe974e1390cd39a34fc2eb216f3771ddf06",
        "created_at": "2020-01-07T06:30:40Z",
        "updated_at": "2020-01-07T06:30:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/aaba4e82d4e7fb7060cb9d3254046dc00b68099a#commitcomment-37207787",
        "id": 37207787,
        "body": "It is not dead code since we call `cgroup.resetConstraints();`. Though tests pass without the statements(which possibly infers it has no power), it deserves more investigation.\r\n\r\nSorry for the noise.",
        "commit_id": "aaba4e82d4e7fb7060cb9d3254046dc00b68099a",
        "created_at": "2020-02-10T11:38:57Z",
        "updated_at": "2020-02-10T11:39:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/eb814e861c89488b63572350cc1db880ab40213a#r37638131",
        "id": 37638131,
        "body": "Recently e2e cases often fail on this case \r\n\r\n```\r\njava.lang.NoClassDefFoundError: org/apache/flink/runtime/rest/messages/RequestBody\r\n\r\n\tat org.apache.flink.tests.util.flink.LocalStandaloneFlinkResourceFactory.create(LocalStandaloneFlinkResourceFactory.java:35)\r\n\tat org.apache.flink.metrics.prometheus.tests.PrometheusReporterEndToEndITCase.<init>(PrometheusReporterEndToEndITCase.java:119)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\r\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\r\n\tat com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)\r\n\tat com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230)\r\n\tat com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58)\r\nCaused by: java.lang.ClassNotFoundException: org.apache.flink.runtime.rest.messages.RequestBody\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 24 more\r\n```\r\n\r\neven it fails locally. Is it a known issue? Otherwise we should file one.",
        "commit_id": "eb814e861c89488b63572350cc1db880ab40213a",
        "created_at": "2020-03-04T18:18:26Z",
        "updated_at": "2020-03-04T18:18:39Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/809eb2ab292ad2916d74f4f761b45ec4aa2f5404#commitcomment-37677452",
        "id": 37677452,
        "body": "I create a duplicate JIRA FLINK-16458 and when I work on this issue, there is a thought that we might have a check when bump our SNAPSHOT version as well as the `japicmp.referenceVersion` should always be `x.y.0`. Possibly we update scripts in tools/, IIRC named `update_branch_version.sh`. WDTY?",
        "commit_id": "809eb2ab292ad2916d74f4f761b45ec4aa2f5404",
        "created_at": "2020-03-06T15:22:58Z",
        "updated_at": "2020-03-06T15:22:58Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/809eb2ab292ad2916d74f4f761b45ec4aa2f5404#commitcomment-37677790",
        "id": 37677790,
        "body": "Either assertion or if we can implement correctly, update `japicmp.referenceVersion` according to `OLD_VERSION`(or `NEW_VERSION`, depends on how we implement it). I just notice that there is no precondition we verify the input format of the script but it should work with proper usage...",
        "commit_id": "809eb2ab292ad2916d74f4f761b45ec4aa2f5404",
        "created_at": "2020-03-06T15:40:48Z",
        "updated_at": "2020-03-06T15:40:48Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c1e9aefc2449a4ea0ff3fa590cf1eb6c1cb484a2#r37738470",
        "id": 37738470,
        "body": "@guoweiM is this method introduced intermediately and finally not into used? I see a JIRA [FLINK-16521](https://issues.apache.org/jira/browse/FLINK-16521) created by @zhengcanbin says this method is unused.\r\n\r\nThus I come here for the original motivation introduce it.",
        "commit_id": "c1e9aefc2449a4ea0ff3fa590cf1eb6c1cb484a2",
        "created_at": "2020-03-10T08:27:18Z",
        "updated_at": "2020-03-10T08:27:18Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/4f5b2fb5736f5a1c098a7dc1d448a879f36f801b#r121578995",
        "id": 121578995,
        "body": "These are breaking changes for downstream projects especially connectors - https://github.com/apache/flink-connector-pulsar/actions/runs/5549154786/jobs/10132925640\r\n\r\nAlthough the interface is `PublicEvolving` that can be changed, perhaps we can try to maintain the compatibility with a default implementation?",
        "commit_id": "4f5b2fb5736f5a1c098a7dc1d448a879f36f801b",
        "created_at": "2023-07-14T05:19:05Z",
        "updated_at": "2023-07-14T05:19:05Z"
      }
    ]
  },
  "link3280": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/01811317d709ad54f1e0c105d5e3e6e36f85d24d#commitcomment-29901548",
        "id": 29901548,
        "body": "Why is this commit reverted? I think it fixes the TM keytab problem.",
        "commit_id": "01811317d709ad54f1e0c105d5e3e6e36f85d24d",
        "created_at": "2018-07-31T10:17:58Z",
        "updated_at": "2018-07-31T10:17:58Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/01811317d709ad54f1e0c105d5e3e6e36f85d24d#commitcomment-29930138",
        "id": 29930138,
        "body": "That's great. Thanks a lot.",
        "commit_id": "01811317d709ad54f1e0c105d5e3e6e36f85d24d",
        "created_at": "2018-08-02T01:34:22Z",
        "updated_at": "2018-08-02T01:34:22Z"
      }
    ]
  },
  "xiaoguichao": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/a2198b04712b8ec6105999414f33781c6efcf4a9#commitcomment-30046767",
        "id": 30046767,
        "body": "WHY do not pick this to 1.3",
        "commit_id": "a2198b04712b8ec6105999414f33781c6efcf4a9",
        "created_at": "2018-08-12T13:44:48Z",
        "updated_at": "2018-08-12T13:44:48Z"
      }
    ]
  },
  "xccui": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/b609ede4b4060bcc94b7e936726369983f3b6bfe#commitcomment-31217883",
        "id": 31217883,
        "body": "Hi @StefanRRichter, the changes for `KafkaTestBase` in this commit seem to cause a build exception. I wonder if you could help check and make a hotfix.\r\n\r\nThanks, Xingcan",
        "commit_id": "b609ede4b4060bcc94b7e936726369983f3b6bfe",
        "created_at": "2018-11-08T05:39:41Z",
        "updated_at": "2018-11-08T05:39:41Z"
      }
    ]
  },
  "Clarkkkkk": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/96684058d4a209d39d7fb1667beb7f083d215b58#commitcomment-31324896",
        "id": 31324896,
        "body": "How can I pull this commit?",
        "commit_id": "96684058d4a209d39d7fb1667beb7f083d215b58",
        "created_at": "2018-11-16T09:39:54Z",
        "updated_at": "2018-11-16T09:39:54Z"
      }
    ]
  },
  "hongtao12310": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/71828fc8540c6693110a1a13850be9bd6e15fab3#commitcomment-31378680",
        "id": 31378680,
        "body": "does the `MATCH_RECOGNIZE` clause for SQL will be released on 1.7.0 branch ? if not which branch is recommend to use the feature ?",
        "commit_id": "71828fc8540c6693110a1a13850be9bd6e15fab3",
        "created_at": "2018-11-21T08:57:31Z",
        "updated_at": "2018-11-21T08:57:31Z"
      }
    ]
  },
  "0x26res": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/93176e5e889d0d51c4d06145a261ed89b06a8381#r31579455",
        "id": 31579455,
        "body": "@tzulitai, I have batch jobs that are writing to kafka. My understanding is that for batch jobs, there isn't a notion of checkpoint. \r\n\r\nI stumble into an issue because the default has now been set to true. The problem is on line 245:\r\n``` if (flushOnCheckpoint && !((StreamingRuntimeContext) this.getRuntimeContext()).isCheckpointingEnabled()) {```\r\n\r\nIn my case, the runtime context isn't a StreamingRuntimeContext but a DistributedRuntimeUDFContext, which causes this code to crash. \r\n\r\nThere is a work around, which is to explicitly set flushOnCheckpoint to false. But maybe we should be more careful when casting the runtime context nwo that the default value for flushOnCheckpoint true;\r\n\r\nHere's the stack trace:\r\n```\r\nCaused by: java.lang.ClassCastException: org.apache.flink.runtime.operators.util.DistributedRuntimeUDFContext cannot be cast to org.apache.flink.streaming.api.operators.StreamingRuntimeContext\r\n        at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.open(FlinkKafkaProducerBase.java:245)\r\n        at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:36)\r\n```\r\n",
        "commit_id": "93176e5e889d0d51c4d06145a261ed89b06a8381",
        "created_at": "2018-12-06T09:41:32Z",
        "updated_at": "2018-12-06T09:41:32Z"
      }
    ]
  },
  "igalshilman": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/9b32f0cab2d9b11e7a22cafdff8043090b7d3a72#commitcomment-31985451",
        "id": 31985451,
        "body": "@tzulitai LGTM \ud83d\udc4d ",
        "commit_id": "9b32f0cab2d9b11e7a22cafdff8043090b7d3a72",
        "created_at": "2019-01-18T07:53:15Z",
        "updated_at": "2019-01-18T07:53:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/68c0b9e94a99daa447b62d77483e5ed5e478b901#r32460353",
        "id": 32460353,
        "body": "@tzulitai Can this be called directly from user's old serializer via CompatibilityUtil#resolveCompatibilityResult ?\r\nWhat would happen in that case?\r\nMaybe we should add a check at CompatibilityUtil for these new interfaces?",
        "commit_id": "68c0b9e94a99daa447b62d77483e5ed5e478b901",
        "created_at": "2019-02-25T14:29:02Z",
        "updated_at": "2019-02-25T14:29:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/46835caaefc206abe11219913eee20f28840eea6#r32460529",
        "id": 32460529,
        "body": "why is this needed?\r\nI think we've implemented `EitherSerializerConfigSnapshot#resolveSchemaCompat`",
        "commit_id": "46835caaefc206abe11219913eee20f28840eea6",
        "created_at": "2019-02-25T14:40:13Z",
        "updated_at": "2019-02-25T14:40:13Z"
      }
    ]
  },
  "kaelzhang": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/185d7304d7883864c25b61bb79095e12c63e3b4a#commitcomment-32085406",
        "id": 32085406,
        "body": "What a huge commit!",
        "commit_id": "185d7304d7883864c25b61bb79095e12c63e3b4a",
        "created_at": "2019-01-28T09:15:48Z",
        "updated_at": "2019-01-28T09:15:48Z"
      }
    ]
  },
  "Kiddinglife": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/185d7304d7883864c25b61bb79095e12c63e3b4a#commitcomment-32097975",
        "id": 32097975,
        "body": "what a huge commit! \r\nWill this branch merge to flink eventually?\r\nThanks.",
        "commit_id": "185d7304d7883864c25b61bb79095e12c63e3b4a",
        "created_at": "2019-01-29T03:57:56Z",
        "updated_at": "2019-01-29T03:57:56Z"
      }
    ]
  },
  "ap0406736": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/2be5f47fb62126fa3a35e44459e660c39e9e0a39#commitcomment-32318826",
        "id": 32318826,
        "body": "org.apache.flink.sql.parser.impl.FlinkSqlParserImpl  \u8fd9\u4e2a\u7c7b\u5e76\u6ca1\u6709\u770b\u5230\uff0c\u662f\u5426\u6ca1\u6709\u63d0\u4ea4\u5b8c\u6574\uff1f",
        "commit_id": "2be5f47fb62126fa3a35e44459e660c39e9e0a39",
        "created_at": "2019-02-14T13:59:03Z",
        "updated_at": "2019-02-14T13:59:03Z"
      }
    ]
  },
  "Hacky-DH": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/55ae0a14a80fb16c25b61dca66fe5ce9e7b2d506#commitcomment-32497858",
        "id": 32497858,
        "body": "Is there a script to change all versions?",
        "commit_id": "55ae0a14a80fb16c25b61dca66fe5ce9e7b2d506",
        "created_at": "2019-02-27T10:29:06Z",
        "updated_at": "2019-02-27T10:29:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/55ae0a14a80fb16c25b61dca66fe5ce9e7b2d506#commitcomment-32514732",
        "id": 32514732,
        "body": "Thanks",
        "commit_id": "55ae0a14a80fb16c25b61dca66fe5ce9e7b2d506",
        "created_at": "2019-02-28T08:14:07Z",
        "updated_at": "2019-02-28T08:14:07Z"
      }
    ]
  },
  "panguoqing": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/55ae0a14a80fb16c25b61dca66fe5ce9e7b2d506#commitcomment-32513923",
        "id": 32513923,
        "body": "> Is there a script to change all versions?\r\n\r\nmvn versions:set -DnewVersion=1.9-SNAPSHOT -DgenerateBackupPoms=false",
        "commit_id": "55ae0a14a80fb16c25b61dca66fe5ce9e7b2d506",
        "created_at": "2019-02-28T07:27:12Z",
        "updated_at": "2019-02-28T07:27:12Z"
      }
    ]
  },
  "lvhuyen": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/d015ce7a3b86a529f4db79ed8ac8dbe28c62d6b8#r32741750",
        "id": 32741750,
        "body": "this private method seems to be redundant - should it get removed? (in the past it was used when calling the ParquetInputFormat constructor)",
        "commit_id": "d015ce7a3b86a529f4db79ed8ac8dbe28c62d6b8",
        "created_at": "2019-03-14T11:01:29Z",
        "updated_at": "2019-03-14T11:01:29Z"
      }
    ]
  },
  "mpoulizos": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/494f5be09d165c5adca092ef1bdcfec1a238c316#r33214199",
        "id": 33214199,
        "body": "You can also use [Objects.nonNull](https://docs.oracle.com/javase/8/docs/api/java/util/Objects.html#nonNull-java.lang.Object-) instead of ne ",
        "commit_id": "494f5be09d165c5adca092ef1bdcfec1a238c316",
        "created_at": "2019-04-17T13:54:56Z",
        "updated_at": "2019-04-17T13:54:56Z"
      }
    ]
  },
  "KurtYoung": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/c05fe9622dae776df25d44964eaab1e63911466f#r33259141",
        "id": 33259141,
        "body": "why set parallelism to 1?",
        "commit_id": "c05fe9622dae776df25d44964eaab1e63911466f",
        "created_at": "2019-04-22T06:55:55Z",
        "updated_at": "2019-04-22T06:55:55Z"
      }
    ]
  },
  "JingsongLi": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/c05fe9622dae776df25d44964eaab1e63911466f#r33259188",
        "id": 33259188,
        "body": "The plan is too complex and the memory of the MemoryManager is not enough.\r\n(This test error is not related to this PR)\r\n(I think we should increase the memory of MemoryManager for testing Cluster later)",
        "commit_id": "c05fe9622dae776df25d44964eaab1e63911466f",
        "created_at": "2019-04-22T07:01:56Z",
        "updated_at": "2019-04-22T07:01:56Z"
      }
    ]
  },
  "hequn8128": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/62c2a7bda33e17d39d400f0ee40db7d78c6f8484#commitcomment-33292710",
        "id": 33292710,
        "body": "Thanks for fixing this. LGTM.",
        "commit_id": "62c2a7bda33e17d39d400f0ee40db7d78c6f8484",
        "created_at": "2019-04-24T13:53:16Z",
        "updated_at": "2019-04-24T13:53:16Z"
      }
    ]
  },
  "benlamonica": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/e0efabe8884f22b4a1c7ab9df3274b3fca03dcfb#r33534793",
        "id": 33534793,
        "body": "You should probably put what developers should use now instead of just putting a @Deprecated.",
        "commit_id": "e0efabe8884f22b4a1c7ab9df3274b3fca03dcfb",
        "created_at": "2019-05-14T18:40:35Z",
        "updated_at": "2019-05-14T18:40:35Z"
      }
    ]
  },
  "sunjincheng121": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33545062",
        "id": 33545062,
        "body": "Hi Chesnay,\n\nThank you very much for sharing these thoughts in the mail thread. And I am\nglad to share my thoughts here:\n\nThis commit should not have been merged like this. It is addressing way too\n> many different issues.\n\n\n In this commit, we only enabled the Python API test and I'm not sure what\ndo you mean about `too many different issues`?\n\nWhat is this change in particular even doing? Why is it necessary?\n\n\nYes, the only goal is to integrate the Travis for Python API.\nThat's already mentioned in the JIRA page, the description section of the\nPR and also described in the commit message.\n\nRenaming the script, while it does make sense on the face of it, provides\n> little value, but can easily result in merge conflicts with concurrent\n> efforts.\n\n\nI'm not fully understanding what is the problem? Are you also changing the\nTravis script? Personally, I don't think the Travis will be\nupdated very frequently and so I think it usually will not cause merge\nconflicts. Besides, code conflicts are very usual in open source project\ndevelopment which\nI don't think is such a problem. Anyway, I'm sorry if this change cause\nmerges conflicts for you.\n\nThis profile only executes pure python tests from what I can tell, why do\n> we care about scala 2.12 / java9 / hadoop 2.4.1?\n\n\nAs we have two ways to trigger the testing: one is PR and the other is the\ncron job. Regarding cron job, it's better to do complete testing\nwhich will not take too much time but can guarantee the functionality works\nwell for scala 2.12 / java 9 / hadoop 2.4.1.\n\nReworking the watchdog code to be agnostic of maven is fine, but I'd much\n> rather had moved it into a separate process_utils.sh. travis_mvn_watchdog.sh\n\nis overloaded as is; we really shouldn't be adding more complexity.\n\n\nI really think about adding utilities for the watchdog code. But we found\nthat the changes are not so big and so we haven't done that in this commit.\nWe can create a follow-up issue to improve this if you think it's necessary.\n\nLooks like we've just added another 500mb of data to the Travis cache, i.e.\n> 25% more data than before. This really shouldn't happen;\n\nthe download/unpack & pack/upload of the cache does take time.\n\n\nWe have already noticed that but we found that it's unavoidable as the\nPython test needs the dist jar. If we don't add the dist\njar to the cache, we have to recompile the whole project for the Python\ntests which will take a longer time compared with the current approach.\nDo you have any suggestions on this? We can improve this if there are\nbetter solutions.\n\nActually, I have pinged you on the PR page using the Flinkbot before\nmerging this commit. But I'm still very grateful that you can share\nyour concerns and experience with us here.\n\nTo be honest, you really give us much help offline for many things and feel\nfree to let me know if there is any misunderstanding.\nI appreciate if you can give us better solutions for this issue and we can\nimprove it in the follow-up PRs.\n\nBest,\nJincheng\n\nChesnay Schepler <notifications@github.com> \u4e8e2019\u5e745\u670815\u65e5\u5468\u4e09 \u4e0b\u53485:31\u5199\u9053\uff1a\n\n> Looks like we've just added another 500mb of data to the Travis cache,\n> i.e. 25% more data than before. This really shouldn't happen; the\n> download/unpack & pack/upload of the cache *does* take time.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5?email_source=notifications&email_token=AFLSIFARR3ZTA7A2JGVF5CLPVPJ6FA5CNFSM4HNBLQZKYY3PNVWWK3TUL52HS4DFVVBW63LNNF2EG33NNVSW45FKMNXW23LFNZ2F62LEZYA77VN4#commitcomment-33543612>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFLSIFDTLRGO2MZXRNZHO3TPVPJ6FANCNFSM4HNBLQZA>\n> .\n>\n",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-15T11:28:05Z",
        "updated_at": "2019-05-15T11:28:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33547116",
        "id": 33547116,
        "body": "Hi Chesnay,\n\nThanks for your explanation, what we can do in the follow-up are:\n\n1. Pay more attention:\n    - We need to write more detail in the changelog, I should pay more\nattention to myself and have the responsibility for maintaining\ncontributors to pay attention to this issue.\n    - Ping someone for the help, and wait at the last 2~3 days.\n\n2. Open the PR contains the following changes:\n   - Remove the test for `scala 2.12` and  `hadoop 2.4.1`\n   - Reduce the JARs, i.e remove the opt JARs except for flink-table. (But\nIMO. anyway we will add them back in future, e.g.: Python API will add ML,\nCEP support, etc.)\n\nDoes that make sense to you?  Feel free to tell me if there is anything I\nmissing?\n\nBest,\nJincheng\n\nChesnay Schepler <notifications@github.com> \u4e8e2019\u5e745\u670815\u65e5\u5468\u4e09 \u4e0b\u53488:59\u5199\u9053\uff1a\n\n> In this commit, we only enabled the Python API test and I'm not sure what\n> do you mean about too many different issues?\n>\n> So here's what you actually did (which btw. should've totally been listed\n> in the change log):\n>\n>    - modified the cache to include flink-dist jars\n>    - renamed travis_mvn_watchdog\n>    - refactored the watchdog to be usable for arbitrary processes\n>    - added python logic to travis_watchdog\n>    - added python profiles to .travis.yml\n>\n> Only the latter 2 should've been in this commit, everything else are\n> refactorings that should be done in separate commits or even PRs.\n>\n> Personally, I don't think the Travis will be updated very frequently and\n> so I think it usually will not cause merge conflicts. Besides, code\n> conflicts are very usual in open source project development which I don't\n> think is such a problem. Anyway, I'm sorry if this change cause merges\n> conflicts for you.\n>\n> You did not cause problems for me; my point is for *any* change you\n> should consider the risk-value trade-off. Renaming the script improved\n> *nothing*, but potentially affected other people.\n>\n> I'm sincerely urging you to rethink your stance on merge conflicts.\n> Believing that we shouldn't worry about merge conflicts because they are\n> common in opensource projects is a surefire way to, at some point, really\n> step on someone's toe. They not only cause more work for the contributor\n> but can also easily introduce subtle issue when resolving them.\n> We've been very conscious about reducing the number of merge conflicts;\n> that's exactly why we are so picky about formatting changes and such.\n>\n> [...] the Python test needs the dist jar. If we don't add the dist jar to\n> the cache, we have to recompile the whole project for the Python tests\n> which will take a longer time compared with the current approach. Do you\n> have any suggestions on this? We can improve this if there are better\n> solutions.\n>\n> It is great that you considered the trade-off between caching vs\n> rebuilding flink-dist. However you don't need all jars in flink-dist\n> though. You need none of the example jars, nor reporters, nor filesystems,\n> nor most libraries. The only jars you (should?) need are flink-dist and\n> flink-table, which are only 100mb, which is quite a bit less than what\n> we're caching right now.\n>\n> As we have two ways to trigger the testing: one is PR and the other is the\n> cron job. Regarding cron job, it's better to do complete testing which will\n> not take too much time but can guarantee the functionality works well for\n> scala 2.12 / java 9 / hadoop 2.4.1.\n>\n> There's *no* reason to worry about scala or hadoop. I'll give you java 9\n> due to py4j, but everything else should be covered on the java side. We're\n> just running redundant tests otherwise.\n>\n> Actually, I have pinged you on the PR page using the Flinkbot before\n> merging this commit.\n>\n> You pinged me here\n> <https://github.com/apache/flink/pull/8392#issuecomment-492027462> via\n> githubs notification. You did not use the @flinkbot\n> <https://github.com/flinkbot>; if you did it would've requested a review\n> from me, but I'm neither listed under reviewers nor in the flinkbot\n> comment <https://github.com/apache/flink/pull/8392#issuecomment-491125451>\n> .\n> In any case, if you feel the need to ping people, please give them some\n> more time.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5?email_source=notifications&email_token=AFLSIFGL5LCHCXH7SN5SPK3PVQCJRA5CNFSM4HNBLQZKYY3PNVWWK3TUL52HS4DFVVBW63LNNF2EG33NNVSW45FKMNXW23LFNZ2F62LEZYA77YDE#commitcomment-33546340>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFLSIFCHNX5IHRMQQHLQRJLPVQCJRANCNFSM4HNBLQZA>\n> .\n>\n",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-15T13:48:44Z",
        "updated_at": "2019-05-15T13:48:44Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5#r33571719",
        "id": 33571719,
        "body": "Hi Chesnay,\nthanks for your reply,  the PR is opened, please have a look!\nhttps://github.com/apache/flink/pull/8465\nBest,\nJincheng\n\n\nChesnay Schepler <notifications@github.com> \u4e8e2019\u5e745\u670816\u65e5\u5468\u56db \u4e0b\u53489:38\u5199\u9053\uff1a\n\n> that sounds good. In regards to 2) we will surely have to back in more\n> jars at a later point, but excluding filesystems alone already saves us\n> 100mb. We also don't have to cache flink-dist twice (once in /target, once\n> in the distribution) so there's some potential here regardless.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/flink/commit/d95d395d92acca210e107663ed0e96c3285f0cf5?email_source=notifications&email_token=AFLSIFAQWR3HUWTAI4B7AITPVVPWBA5CNFSM4HNBLQZKYY3PNVWWK3TUL52HS4DFVVBW63LNNF2EG33NNVSW45FKMNXW23LFNZ2F62LEZYBAAIZN#commitcomment-33563437>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFLSIFEO4PZ2L6WANPROVQLPVVPWBANCNFSM4HNBLQZA>\n> .\n>\n",
        "commit_id": "d95d395d92acca210e107663ed0e96c3285f0cf5",
        "created_at": "2019-05-17T00:09:02Z",
        "updated_at": "2019-05-17T00:09:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/65ebd07c3d9140e2c2e75464999da5d599c3bc6b#r33802621",
        "id": 33802621,
        "body": "Thanks for the PR. @aloyszhang!\r\nJust reminder: This change is already contained in https://github.com/apache/flink/pull/8225/files",
        "commit_id": "65ebd07c3d9140e2c2e75464999da5d599c3bc6b",
        "created_at": "2019-06-04T10:11:35Z",
        "updated_at": "2019-06-04T10:14:24Z"
      }
    ]
  },
  "zhijiangW": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/c7193dc3de5ded777a30ed35a7b261d0a17a3ff9#r33991235",
        "id": 33991235,
        "body": "checkNotNull(partitionTable)",
        "commit_id": "c7193dc3de5ded777a30ed35a7b261d0a17a3ff9",
        "created_at": "2019-06-19T07:29:10Z",
        "updated_at": "2019-06-19T07:29:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c7193dc3de5ded777a30ed35a7b261d0a17a3ff9#r33991286",
        "id": 33991286,
        "body": "checkNotNull(partitionTable)",
        "commit_id": "c7193dc3de5ded777a30ed35a7b261d0a17a3ff9",
        "created_at": "2019-06-19T07:34:02Z",
        "updated_at": "2019-06-19T07:34:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ea418da37803a0352b292b2f7a9aeedd3a691c2c#r33991385",
        "id": 33991385,
        "body": "Maybe better to put the following logics in a separate method to make `markFinished` shorter",
        "commit_id": "ea418da37803a0352b292b2f7a9aeedd3a691c2c",
        "created_at": "2019-06-19T07:42:46Z",
        "updated_at": "2019-06-19T07:42:46Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ea418da37803a0352b292b2f7a9aeedd3a691c2c#r33991497",
        "id": 33991497,
        "body": "The execution was already finished then it must have a assigned slot before, so I think it is not necessary here. Otherwise we should make this check in the beginning of `markFinished`, not in the process of starting tracking partitions.",
        "commit_id": "ea418da37803a0352b292b2f7a9aeedd3a691c2c",
        "created_at": "2019-06-19T07:51:12Z",
        "updated_at": "2019-06-19T07:51:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d5a9f3c94e33211885d0089a91f2bb6236db8e76#r33991689",
        "id": 33991689,
        "body": "nit: if we put the `if (!partitionTable.hasTrackedPartitions(taskManagerId))` inside the method of `releaseEmptyTaskManager`, we could reuse it if release might be reused in other parts future.",
        "commit_id": "d5a9f3c94e33211885d0089a91f2bb6236db8e76",
        "created_at": "2019-06-19T08:04:58Z",
        "updated_at": "2019-06-19T08:04:58Z"
      }
    ]
  },
  "zjffdu": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/1c03cda548b639af999e5ea3d6fc6dde483ef8c8#r34246204",
        "id": 34246204,
        "body": "`expected` is not verified ?",
        "commit_id": "1c03cda548b639af999e5ea3d6fc6dde483ef8c8",
        "created_at": "2019-07-10T05:11:27Z",
        "updated_at": "2019-07-10T05:11:27Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1c03cda548b639af999e5ea3d6fc6dde483ef8c8#r34246221",
        "id": 34246221,
        "body": "Is it possible for infer the schema info ? To me, it is redundant to declare it here. ",
        "commit_id": "1c03cda548b639af999e5ea3d6fc6dde483ef8c8",
        "created_at": "2019-07-10T05:13:36Z",
        "updated_at": "2019-07-10T05:13:36Z"
      }
    ]
  },
  "hehuiyuan": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/1c03cda548b639af999e5ea3d6fc6dde483ef8c8#r34246792",
        "id": 34246792,
        "body": "Hi, I took a look at CsvTableSink.  Exception  will be throw If it is not configured, ",
        "commit_id": "1c03cda548b639af999e5ea3d6fc6dde483ef8c8",
        "created_at": "2019-07-10T06:23:50Z",
        "updated_at": "2019-07-10T06:24:08Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/1c03cda548b639af999e5ea3d6fc6dde483ef8c8#r34246953",
        "id": 34246953,
        "body": "Now , I do not have a good method  to verify between the valued of `expected` and the value of `print` ",
        "commit_id": "1c03cda548b639af999e5ea3d6fc6dde483ef8c8",
        "created_at": "2019-07-10T06:41:45Z",
        "updated_at": "2019-07-10T06:41:45Z"
      }
    ]
  },
  "RockyRunning": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/5c9caa7d2cc4d917898879ad9518c07e5cca5b49#commitcomment-34567390",
        "id": 34567390,
        "body": "cool~",
        "commit_id": "5c9caa7d2cc4d917898879ad9518c07e5cca5b49",
        "created_at": "2019-08-05T07:24:59Z",
        "updated_at": "2019-08-05T07:24:59Z"
      }
    ]
  },
  "wuchong": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/7838436fc3b3aa653ecb33fc965116110b1f835e#commitcomment-34617270",
        "id": 34617270,
        "body": "Thanks for pointing out. The JIRA id of this commit should be FLINK-13433. I'm sorry I missed to check it when merging commits. \r\n\r\nI think we can modify the title and description of FLINK-13509 issue to align with this commit and close it. And create another issue for proper fix. \r\n\r\nWhat do you think @tillrohrmann ? ",
        "commit_id": "7838436fc3b3aa653ecb33fc965116110b1f835e",
        "created_at": "2019-08-08T08:58:58Z",
        "updated_at": "2019-08-08T08:59:08Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7838436fc3b3aa653ecb33fc965116110b1f835e#commitcomment-34617375",
        "id": 34617375,
        "body": "I have create a separate issue [FLINK-13648](https://issues.apache.org/jira/browse/FLINK-13648) for proper support in 1.10. And closed [FLINK-13509](https://issues.apache.org/jira/browse/FLINK-13509) with this commit id.",
        "commit_id": "7838436fc3b3aa653ecb33fc965116110b1f835e",
        "created_at": "2019-08-08T09:07:00Z",
        "updated_at": "2019-08-08T09:07:00Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/810321d988a8284eb54c2963f22a049dc06ac8aa#r40872636",
        "id": 40872636,
        "body": "If we use the `avro-confluent` as identifier, I perfer to have the `schema-registry` to make it clear what is the url for. For example: `avro-confluent.schema-registry.url` is more self-explanatory than `avro-confluent.url` that the url is the schema registry url. ",
        "commit_id": "810321d988a8284eb54c2963f22a049dc06ac8aa",
        "created_at": "2020-07-24T10:10:53Z",
        "updated_at": "2020-07-24T10:10:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/810321d988a8284eb54c2963f22a049dc06ac8aa#r40872683",
        "id": 40872683,
        "body": "I'm not sure about this, actually, we don't distinguish source/sink in format for now. For example, `csv` has `ignore-parse-errors`, `allow-comments` which are only avaiable in deserialization. ",
        "commit_id": "810321d988a8284eb54c2963f22a049dc06ac8aa",
        "created_at": "2020-07-24T10:12:42Z",
        "updated_at": "2020-07-24T10:12:42Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/c93205b4abe643d6dd798c3180d68ab8d02eded5#r43170054",
        "id": 43170054,
        "body": "Flink uses comma as a separator for POJO members, so lists use semicolon. Otherwise, it's hard to expression `List<POJO>` in plain string. \r\n\r\nSee more: https://cwiki.apache.org/confluence/display/FLINK/FLIP-54%3A+Evolve+ConfigOption+and+Configuration#FLIP54:EvolveConfigOptionandConfiguration-Example:.2",
        "commit_id": "c93205b4abe643d6dd798c3180d68ab8d02eded5",
        "created_at": "2020-10-12T12:32:19Z",
        "updated_at": "2020-10-12T12:32:19Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d067629d4d200f940d0b58759459d7ff5832b292#r79346901",
        "id": 79346901,
        "body": "Would be better to use `executor.shutdownNow()` instead of `executor.shutdown()`? The purpose of `stop()` is to exit the gateway without waiting for all the pending requests. @fsk119 ",
        "commit_id": "d067629d4d200f940d0b58759459d7ff5832b292",
        "created_at": "2022-07-25T12:28:53Z",
        "updated_at": "2022-07-25T12:29:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d067629d4d200f940d0b58759459d7ff5832b292#r79346988",
        "id": 79346988,
        "body": "Is it missed to call `System.exit(-1);` at the end? Otherwise, the gateway won't exit even if the endpoint doesn't start successfully.",
        "commit_id": "d067629d4d200f940d0b58759459d7ff5832b292",
        "created_at": "2022-07-25T12:29:35Z",
        "updated_at": "2022-07-25T12:29:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d067629d4d200f940d0b58759459d7ff5832b292#r79347255",
        "id": 79347255,
        "body": "Is it possible to reuse the executor in `SqlGatewayService`?  Otherwise, users need to configure the threads twice/thrice. The flooded threads are overhead to the gateway as well. ",
        "commit_id": "d067629d4d200f940d0b58759459d7ff5832b292",
        "created_at": "2022-07-25T12:32:14Z",
        "updated_at": "2022-07-25T12:32:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d067629d4d200f940d0b58759459d7ff5832b292#r79347579",
        "id": 79347579,
        "body": "For hiveserver, we should not only register hive module, but also reorder the module to use hive module before core module. Otherwise, the hive functions won't be discovered. See https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/hive/hive_dialect/",
        "commit_id": "d067629d4d200f940d0b58759459d7ff5832b292",
        "created_at": "2022-07-25T12:36:23Z",
        "updated_at": "2022-07-25T12:36:23Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d067629d4d200f940d0b58759459d7ff5832b292#r79348771",
        "id": 79348771,
        "body": "Also `table.dml-sync=true` and exeuction mode set to batch. ",
        "commit_id": "d067629d4d200f940d0b58759459d7ff5832b292",
        "created_at": "2022-07-25T12:49:11Z",
        "updated_at": "2022-07-25T12:49:11Z"
      }
    ]
  },
  "ramthottempudi12": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/e2728c0dddafcfe7fac0652084be6c7fd9714d85#commitcomment-35151890",
        "id": 35151890,
        "body": "Respected Sir,\r\nI want to run pagerank using flink gelly for full data. How i have to give the value for maxIterations.\r\nHow to change the parameter value for number of iterations in pagerank.",
        "commit_id": "e2728c0dddafcfe7fac0652084be6c7fd9714d85",
        "created_at": "2019-09-19T14:03:14Z",
        "updated_at": "2019-09-19T14:03:14Z"
      }
    ]
  },
  "GJL": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/4f0d6c170937c57934faa23141777f2304072ee4#r35854845",
        "id": 35854845,
        "body": "Then what about the metrics here? https://ci.apache.org/projects/flink/flink-docs-release-1.9/monitoring/metrics.html#checkpointing\r\n\r\n",
        "commit_id": "4f0d6c170937c57934faa23141777f2304072ee4",
        "created_at": "2019-11-07T19:36:29Z",
        "updated_at": "2019-11-07T19:36:29Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/809eb2ab292ad2916d74f4f761b45ec4aa2f5404#commitcomment-37677624",
        "id": 37677624,
        "body": "Not sure if I understood you right. In `update_branch_version.sh`, do you want to assert that `japicmp.referenceVersion` points to the previous release?",
        "commit_id": "809eb2ab292ad2916d74f4f761b45ec4aa2f5404",
        "created_at": "2020-03-06T15:31:28Z",
        "updated_at": "2020-03-06T15:31:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/809eb2ab292ad2916d74f4f761b45ec4aa2f5404#commitcomment-37677979",
        "id": 37677979,
        "body": "You can open a ticket and we can take the discussion there. I currently have these concerns:\r\n1. We should point to the latest patch release of the previous minor release. How can we ensure that?\r\n1. If we raise the version to 2.x.x, the script shouldn't break. Dropping binary compatibility should be allowed if it is intentional.\r\n1. Raising the version in `update_branch_version.sh` to `OLD_VERSION` is too late. The release branch is taken after feature freeze. However, the version should be raised as soon as the release is out.",
        "commit_id": "809eb2ab292ad2916d74f4f761b45ec4aa2f5404",
        "created_at": "2020-03-06T15:51:28Z",
        "updated_at": "2020-03-06T15:53:33Z"
      }
    ]
  },
  "qinjunjerry": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/bcc315f76bccbc0be72b5007fc87809980ce99ca#r36707346",
        "id": 36707346,
        "body": "I believe the line should be the following instead:\r\n`.load(bEnv, oldPath, new MemoryStateBackend())`\r\nAnd for Scala:\r\n`.load(bEnv, oldPath, new MemoryStateBackend)`",
        "commit_id": "bcc315f76bccbc0be72b5007fc87809980ce99ca",
        "created_at": "2020-01-08T11:50:01Z",
        "updated_at": "2020-01-08T11:50:01Z"
      }
    ]
  },
  "walterddr": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/efef8be86f2fc6976ef3bd53314593e7e9099fd5#r37771844",
        "id": 37771844,
        "body": "I would refactor this part with the ones in `YarnClusterEntrypointUtils` and put them in `yarn.Utils` class. ",
        "commit_id": "efef8be86f2fc6976ef3bd53314593e7e9099fd5",
        "created_at": "2020-03-11T16:30:40Z",
        "updated_at": "2020-03-11T16:30:40Z"
      }
    ]
  },
  "wanglijie95": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/6a42bf6e72ddd86b88554c2342f0696b7c9af12b#commitcomment-38312526",
        "id": 38312526,
        "body": "why revert\uff1f",
        "commit_id": "6a42bf6e72ddd86b88554c2342f0696b7c9af12b",
        "created_at": "2020-04-06T08:43:16Z",
        "updated_at": "2020-04-06T08:43:16Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/01d1e1cb153411c74ff15bd9253bf04ea3f947b7#r137685003",
        "id": 137685003,
        "body": "\u8fd9\u4e2a\u5730\u65b9\u7ed9\u6f0f\u4e86\u3002\u6211\u4eec\u4e4b\u524d\u6253\u7b97 jm failover \u540e\uff0c\u6062\u590d ExecutionGraphID \u7684\u3002\u73b0\u5728\u8fd9\u4e2a\u7248\u672c\u4e2d\uff0cjm \u91cd\u542f\u524d\u540e\uff0cExecutionGraphID \u662f\u4e0d\u4e00\u6837\u7684",
        "commit_id": "01d1e1cb153411c74ff15bd9253bf04ea3f947b7",
        "created_at": "2024-01-24T02:09:09Z",
        "updated_at": "2024-01-24T02:09:09Z"
      }
    ]
  },
  "pnowojski": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/6a42bf6e72ddd86b88554c2342f0696b7c9af12b#commitcomment-38312939",
        "id": 38312939,
        "body": "As described in the ticket it caused https://issues.apache.org/jira/browse/FLINK-16959",
        "commit_id": "6a42bf6e72ddd86b88554c2342f0696b7c9af12b",
        "created_at": "2020-04-06T09:04:26Z",
        "updated_at": "2020-04-06T09:04:51Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f92548128543e07c0ad064b77b911c6049c7533f#r84618612",
        "id": 84618612,
        "body": "It looks like a bug/race condition. If we are not using changelog (`changelogWriterAvailabilityProvider == null`),  `recordWriter` or `inputProcessor` were not available in the switch/case above, but became available before we reached this if/else if/else block, we might end up in this else condition by accident.\r\n\r\nProbably a fix would be to change `else` to `else if (changelogWriterAvailabilityProvider != null)` and add a fall through:\r\n```\r\nelse {\r\n  return;\r\n}\r\n```\r\n?\r\n\r\nWouldn't a simple unit test where `inputProcessor#processInput` returns always `NOTHING_AVAILABLE` , but `recordWriter` and `inputProcessor` are always available reliably hit this bug all the time?\r\n\r\nIf I'm correct it's really strange that it wasn't discovered before.",
        "commit_id": "f92548128543e07c0ad064b77b911c6049c7533f",
        "created_at": "2022-09-21T15:10:35Z",
        "updated_at": "2022-09-21T15:10:35Z"
      }
    ]
  },
  "cooniur": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/4a5e8c083969cad215819ad6a3a0d2919e8c2d5e#r38473073",
        "id": 38473073,
        "body": "Hi @xintongsong, @azagrebin: \r\n\r\nI understand the need of code deduplication. However, this change seems to break backward compatibility where in the old logic `ExecutionConfig.PARALLELISM_DEFAULT` (`-1`) is a valid value, while the new logic only allows values greater than 0.\r\n\r\nEven if the intention is to make `-1` is no longer valid for DataStreamSource's parallelism, there also seems to be a confusion caused in the exception message talking about \"max parallelism\" when a user is actually setting the parallelism: \r\n\r\n```\r\nCaused by: java.lang.IllegalArgumentException: The maximum parallelism must be greater than 0.\r\n                                                   ^^^^^^^^^^^^^^^^^^^                                                                \r\n    at org.apache.flink.util.Preconditions.checkArgument(Preconditions.java:139)\r\n    at org.apache.flink.api.common.operators.util.OperatorValidationUtils.validateMaxParallelism(OperatorValidationUtils.java:57)\r\n    at org.apache.flink.api.common.operators.util.OperatorValidationUtils.validateMaxParallelism(OperatorValidationUtils.java:53)\r\n    at org.apache.flink.streaming.api.datastream.DataStreamSource.setParallelism(DataStreamSource.java:55)\r\n    at org.apache.flink.streaming.api.datastream.DataStreamSource.setParallelism(DataStreamSource.java:32)\r\n```\r\n\r\nMaybe I miss something here, but otherwise, I hope this logic can be fixed to maintain backward compatibility, and the exception error message can be improved to reduce the confusion.  Thanks!",
        "commit_id": "4a5e8c083969cad215819ad6a3a0d2919e8c2d5e",
        "created_at": "2020-04-14T00:57:04Z",
        "updated_at": "2020-04-14T01:03:09Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/4a5e8c083969cad215819ad6a3a0d2919e8c2d5e#r38474194",
        "id": 38474194,
        "body": "@xintongsong Thanks for letting me know! That's great! Will follow on the ticket. \ud83d\udc4d ",
        "commit_id": "4a5e8c083969cad215819ad6a3a0d2919e8c2d5e",
        "created_at": "2020-04-14T02:25:42Z",
        "updated_at": "2020-04-14T02:25:42Z"
      }
    ]
  },
  "xintongsong": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/4a5e8c083969cad215819ad6a3a0d2919e8c2d5e#r38474093",
        "id": 38474093,
        "body": "Thanks for reporting this issues, @cooniur. This is indeed a bug.\r\nActually, the community is already aware of this issue, and has fixed it in FLINK-16664. This bug-fix will be available in release 1.10.1 & 1.11.0.",
        "commit_id": "4a5e8c083969cad215819ad6a3a0d2919e8c2d5e",
        "created_at": "2020-04-14T02:19:40Z",
        "updated_at": "2020-04-14T02:19:40Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b9e576fb845b817d804da3d68471ff8a4723dcf3#commitcomment-49683569",
        "id": 49683569,
        "body": "Hi @jiamo,\r\n\r\nThanks for reporting this. I think you're right. Concurrent access to `ThresholdMeter` could potentially cause the NPE. I've opened FLINK-22340 to tack this issue. It would be nice if you can post the complete error stack on the jira ticket.\r\n\r\nMoreover, please be aware that `ThresholdMeter` is a Flink runtime internal class. It should not be used in a user defined function. There's no compatibility guarantee for this class.",
        "commit_id": "b9e576fb845b817d804da3d68471ff8a4723dcf3",
        "created_at": "2021-04-19T05:38:05Z",
        "updated_at": "2021-04-19T05:38:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/06435cec2e510d0592e8ad868a1d0ea3e83c1b35#r96593526",
        "id": 96593526,
        "body": "My bad. I thought WASB is also supported, which turns out is not. Fixed in 2a8ea19894f087598792346bc9a9617b669b4527.",
        "commit_id": "06435cec2e510d0592e8ad868a1d0ea3e83c1b35",
        "created_at": "2023-01-18T08:55:40Z",
        "updated_at": "2023-01-18T08:55:40Z"
      }
    ]
  },
  "dianfu": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/b8b0331247fe6d023d4da44868cb1f3526b62c62#r38609800",
        "id": 38609800,
        "body": "Why removed the license header? This failure may be caused by this change: https://dev.azure.com/rmetzger/5bd3ef0a-4359-41af-abca-811b04098d2e/_apis/build/builds/7761/logs/13",
        "commit_id": "b8b0331247fe6d023d4da44868cb1f3526b62c62",
        "created_at": "2020-04-20T09:06:20Z",
        "updated_at": "2020-04-20T09:06:20Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b8b0331247fe6d023d4da44868cb1f3526b62c62#r38610286",
        "id": 38610286,
        "body": "Thanks a lot! Just noticed that I'm commenting on the commit instead of the PR.",
        "commit_id": "b8b0331247fe6d023d4da44868cb1f3526b62c62",
        "created_at": "2020-04-20T09:34:02Z",
        "updated_at": "2020-04-20T09:34:02Z"
      }
    ]
  },
  "sjwiesman": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/9a9ae4d5447c18f4cd593e7f0ea115698026db4f#r39145490",
        "id": 39145490,
        "body": "I\u2019m not qualified to review this code but could you please expand the comment that it prints to std out. ",
        "commit_id": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f",
        "created_at": "2020-05-13T13:28:08Z",
        "updated_at": "2020-05-13T13:28:08Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085#r47203720",
        "id": 47203720,
        "body": "yes it should. ",
        "commit_id": "b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085",
        "created_at": "2021-02-16T23:34:58Z",
        "updated_at": "2021-02-16T23:34:58Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085#r47203804",
        "id": 47203804,
        "body": "that was wrong, state proc is not in lib. ",
        "commit_id": "b6a0bb2eb9747e7e511fd1afb6593e2d60fb3085",
        "created_at": "2021-02-16T23:38:12Z",
        "updated_at": "2021-02-16T23:38:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/dc4e35c39130f4229364fb3677f6983fcb9a39c9#r56373397",
        "id": 56373397,
        "body": "@twalthr do we still need this `LegacyTypeInfoDataTypeConverter` restriction or can it be dropped? I see the class still exists but I can't tell if it's still used. ",
        "commit_id": "dc4e35c39130f4229364fb3677f6983fcb9a39c9",
        "created_at": "2021-09-13T13:38:14Z",
        "updated_at": "2021-09-13T13:38:14Z"
      }
    ]
  },
  "danny0405": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/11f71d1b13e2b6456722b5ce5f1081a6f9d1cef9#r39931313",
        "id": 39931313,
        "body": "About the nullability, here is the issue and discussion [1], and the conclusion:\r\n\r\n> If someone declares a column r ROW(x INT NOT NULL, y INT NOT NULL) should we implicitly add NOT NULL to r?\r\n\r\n>if someone declares r ROW(x INT, y INT) NOT NULL should be implicitly add NOT NULL to x and y?\r\n\r\nBoth answers are no ~\r\n\r\nSo the fix here is invalid, we should respect the nullability of the record attributes. That means we should make the nullability right when we create the record type not fix it in all kinds of operators.\r\n\r\n[1] https://issues.apache.org/jira/browse/CALCITE-2464",
        "commit_id": "11f71d1b13e2b6456722b5ce5f1081a6f9d1cef9",
        "created_at": "2020-06-16T02:58:55Z",
        "updated_at": "2020-06-16T02:58:55Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/efc12ca13743c2562d297a511d82cbdccc718cd0#r45842983",
        "id": 45842983,
        "body": "Why move the `SchemaBuilder.builder().nullType()` to be the first element of `Union`, we actually have no idea whether user's avro schema Union type has form `null, other type` or form `other type, null`, should we support both ?",
        "commit_id": "efc12ca13743c2562d297a511d82cbdccc718cd0",
        "created_at": "2021-01-11T12:56:49Z",
        "updated_at": "2021-01-11T12:56:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/efc12ca13743c2562d297a511d82cbdccc718cd0#r45866577",
        "id": 45866577,
        "body": "> that's the suggested way by Avro\r\n\r\nIf `Schema.createUnion(schema, SchemaBuilder.builder().nullType())` is valid, we should also support that.\r\nBecause the avro schema is already there and the only way of current code base to declare the schema is from the DDL. User can not specify a Avro schema string anymore.",
        "commit_id": "efc12ca13743c2562d297a511d82cbdccc718cd0",
        "created_at": "2021-01-12T02:38:06Z",
        "updated_at": "2021-01-12T02:38:15Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/efc12ca13743c2562d297a511d82cbdccc718cd0#r45878739",
        "id": 45878739,
        "body": "Support both seems more reasonable.",
        "commit_id": "efc12ca13743c2562d297a511d82cbdccc718cd0",
        "created_at": "2021-01-12T11:36:02Z",
        "updated_at": "2021-01-12T11:36:02Z"
      }
    ]
  },
  "billyrrr": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/959ca5495fe57ca5b116a47504ecbd19819b65e5#r41361004",
        "id": 41361004,
        "body": "\u62b1\u6b49\uff0c\u9017\u53f7\u65e0\u610f\u4e2d\u4f7f\u7528\u4e86\u4e2d\u6587\u683c\u5f0f",
        "commit_id": "959ca5495fe57ca5b116a47504ecbd19819b65e5",
        "created_at": "2020-08-11T08:00:10Z",
        "updated_at": "2020-08-11T08:00:10Z"
      }
    ]
  },
  "vthinkxie": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41659001",
        "id": 41659001,
        "body": "```html\r\n<nz-alert *ngIf=\"isError\" nzShowIcon nzType=\"warning\" nzMessage=\"Job failed during initialization of JobManager\" nzDescription=\"descriptionTemplateRef\"></nz-alert>\r\n<ng-template #descriptionTemplateRef>\r\n  <pre>{{errorDetails}}</pre>\r\n</ng-template>\r\n```",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T09:05:06Z",
        "updated_at": "2020-08-21T09:05:17Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41659013",
        "id": 41659013,
        "body": "errorDetails: string;",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T09:05:28Z",
        "updated_at": "2020-08-21T09:05:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41659028",
        "id": 41659028,
        "body": "```typescript\r\nthis.jobService.loadExceptions(this.activatedRoute.snapshot.params.jid, 10).subscribe(data => {\r\n  this.errorDetails = data['root-exception'];\r\n  this.cdr.markForCheck();\r\n});\r\n```",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T09:06:32Z",
        "updated_at": "2020-08-21T09:06:32Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41659039",
        "id": 41659039,
        "body": "no tap needed here",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T09:07:02Z",
        "updated_at": "2020-08-21T09:07:02Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/5b5dcb0d5045f3390fc65defe5904650e8957124#r41661744",
        "id": 41661744,
        "body": "my mistake, you are right",
        "commit_id": "5b5dcb0d5045f3390fc65defe5904650e8957124",
        "created_at": "2020-08-21T11:08:09Z",
        "updated_at": "2020-08-21T11:08:09Z"
      }
    ]
  },
  "SteNicholas": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/411b4c1e4ad88a7468343efa04dd87c12d0dc5f8#r43616961",
        "id": 43616961,
        "body": "fromSequence(String, long, long) -> fromSequence(long, long)",
        "commit_id": "411b4c1e4ad88a7468343efa04dd87c12d0dc5f8",
        "created_at": "2020-10-27T11:55:25Z",
        "updated_at": "2020-10-27T11:55:25Z"
      }
    ]
  },
  "AHeise": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/ee558374ffcc0271332e40e82ad20813f680d0d6#r43823521",
        "id": 43823521,
        "body": "nit: typo commit message",
        "commit_id": "ee558374ffcc0271332e40e82ad20813f680d0d6",
        "created_at": "2020-11-03T07:41:10Z",
        "updated_at": "2020-11-03T07:41:10Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47760782",
        "id": 47760782,
        "body": "Hm no, this is definitively not good in hindsight. \r\nThe ticket would have not added more information for now, but it would be at least a reference point.\r\nI'd propose to amend it by adding a ticket and at least at it to the PR title. There is probably nothing that we can do to amend the commit itself.",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T20:49:50Z",
        "updated_at": "2021-03-02T20:49:50Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/37c2e23f30151879abfe66c52fb56b5ce5c82050#r55588879",
        "id": 55588879,
        "body": "@PatrickRen FYI, please re-enable once stabilized.",
        "commit_id": "37c2e23f30151879abfe66c52fb56b5ce5c82050",
        "created_at": "2021-08-28T21:32:00Z",
        "updated_at": "2021-08-28T21:32:00Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/37c2e23f30151879abfe66c52fb56b5ce5c82050#r55588882",
        "id": 55588882,
        "body": "@syhily  FYI, please re-enable once stabilized.",
        "commit_id": "37c2e23f30151879abfe66c52fb56b5ce5c82050",
        "created_at": "2021-08-28T21:32:10Z",
        "updated_at": "2021-08-28T21:32:10Z"
      }
    ]
  },
  "KarmaGYZ": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/ea66e982b284d4ca044c94fbb1eb40c8fef7bf65#r44691209",
        "id": 44691209,
        "body": "I think this should be `{% link dev/table/streaming/temporal_tables.zh.md %}#\u65f6\u6001\u8868\u51fd\u6570)`. cc @tillrohrmann ",
        "commit_id": "ea66e982b284d4ca044c94fbb1eb40c8fef7bf65",
        "created_at": "2020-12-01T10:16:06Z",
        "updated_at": "2020-12-01T10:17:50Z"
      }
    ]
  },
  "atris": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/2aa667f8ce48b0ad606063c7a6328c65f4713421#r45128306",
        "id": 45128306,
        "body": "Noted",
        "commit_id": "2aa667f8ce48b0ad606063c7a6328c65f4713421",
        "created_at": "2020-12-15T08:34:12Z",
        "updated_at": "2020-12-15T08:34:12Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/2aa667f8ce48b0ad606063c7a6328c65f4713421#r45128413",
        "id": 45128413,
        "body": "So should I not push here at all and just create a cast and return it?",
        "commit_id": "2aa667f8ce48b0ad606063c7a6328c65f4713421",
        "created_at": "2020-12-15T08:38:29Z",
        "updated_at": "2020-12-15T08:38:29Z"
      }
    ]
  },
  "zeahoo": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/ad0d5c8e256e6db5f6a51e6374cdc262283c912d#r46595758",
        "id": 46595758,
        "body": "May I ask why It need brace to nest following codes? It's weird from I can see...",
        "commit_id": "ad0d5c8e256e6db5f6a51e6374cdc262283c912d",
        "created_at": "2021-02-01T08:45:06Z",
        "updated_at": "2021-02-01T08:45:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/ad0d5c8e256e6db5f6a51e6374cdc262283c912d#r46724138",
        "id": 46724138,
        "body": "Many thanks",
        "commit_id": "ad0d5c8e256e6db5f6a51e6374cdc262283c912d",
        "created_at": "2021-02-04T01:36:48Z",
        "updated_at": "2021-02-04T01:36:48Z"
      }
    ]
  },
  "rkhachatryan": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47758212",
        "id": 47758212,
        "body": "Because the new method was added to the public API.",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T19:44:42Z",
        "updated_at": "2021-03-02T19:44:42Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/cb8a8c6925d8fbf34c64bea417606cac05e5b5d1#r47762115",
        "id": 47762115,
        "body": "Thanks for raising this @zentol.\r\n\r\nI've created https://issues.apache.org/jira/browse/FLINK-21570 for reference as @AHeise suggested.",
        "commit_id": "cb8a8c6925d8fbf34c64bea417606cac05e5b5d1",
        "created_at": "2021-03-02T21:26:07Z",
        "updated_at": "2021-03-02T21:26:07Z"
      }
    ]
  },
  "jhuchuan-chen": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/814fe0eb06f1941247742de27e8150b7c9274b43#commitcomment-48684045",
        "id": 48684045,
        "body": "how can i use op or type in table ddl\uff1f",
        "commit_id": "814fe0eb06f1941247742de27e8150b7c9274b43",
        "created_at": "2021-03-25T05:07:41Z",
        "updated_at": "2021-03-25T05:07:41Z"
      }
    ]
  },
  "jiamo": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/b9e576fb845b817d804da3d68471ff8a4723dcf3#commitcomment-49681105",
        "id": 49681105,
        "body": "I got every strange NPE in this \r\n\r\n```\r\n    private int getEventCountsRecentInterval() {\r\n        Long currentTimeStamp = System.currentTimeMillis();\r\n        while (!eventTimestamps.isEmpty()\r\n                && currentTimeStamp - eventTimestamps.peek() > interval.toMillis()) {   # this line  got NPE\r\n            eventTimestamps.remove();\r\n        }\r\n```\r\n\r\nThe only way I can thought is:\r\nWhen in while:  `eventTimestamps.remove();`  and Another thread do `eventTimestamps.add()` which may cause \r\n\r\n```\r\n    private void doubleCapacity() {\r\n        assert head == tail;\r\n        int p = head;\r\n        int n = elements.length;\r\n        int r = n - p; // number of elements to the right of p\r\n        int newCapacity = n << 1;\r\n        if (newCapacity < 0)\r\n            throw new IllegalStateException(\"Sorry, deque too big\");\r\n        Object[] a = new Object[newCapacity];\r\n        System.arraycopy(elements, p, a, 0, r);\r\n        System.arraycopy(elements, 0, a, r, p);\r\n        elements = a;\r\n        head = 0;\r\n        tail = n;\r\n    }\r\n```\r\n\r\nAnd the `elements = a;`  make the old  eventTimestamps  to be GC collect. and got NPE.\r\n\r\nIs it possible?  So such like\r\n\r\n```\r\n\t\tpublic void open(org.apache.flink.configuration.Configuration parameters) throws Exception {\r\n\t\t\tgroup = getRuntimeContext()\r\n\t\t\t\t\t.getMetricGroup().addGroup(\"Click\");\r\n\t\t\tmeter = group.meter(\"1seconds\", new ThresholdMeter(30000, Duration.ofSeconds(1)));\r\n\t\t\tcounter = group.counter(\"totalCount\", new SimpleCounter());\r\n\t\t}\r\n```\r\nIn `RichFlatMapFunction`  is it possible there is  two threads operate the same meter to cause this NPE?\r\n\r\nThe real NPE is \r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat com.papayamobile.streaming.ThresholdMeter.getEventCountsRecentInterval(ThresholdMeter.java:67)\r\n\tat com.papayamobile.streaming.ThresholdMeter.checkAgainstThreshold(ThresholdMeter.java:56)\r\n\tat com.papayamobile.streaming.StreamingClickJob$ToClick.flatMap(StreamingClickJob.java:66)\r\n\tat com.papayamobile.streaming.StreamingClickJob$ToClick.flatMap(StreamingClickJob.java:42)\r\n\tat org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)\r\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71)\r\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)\r\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)\r\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50)\r\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28)\r\n\tat org.apache.flink.streaming.api.operators.StreamSourceContexts$ManualWatermarkContext.processAndCollectWithTimestamp(StreamSourceContexts.java:322)\r\n\tat org.apache.flink.streaming.api.operators.StreamSourceContexts$WatermarkContext.collectWithTimestamp(StreamSourceContexts.java:426)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher.emitRecordAndUpdateState(KinesisDataFetcher.java:986)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher.access$000(KinesisDataFetcher.java:111)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher$AsyncKinesisRecordEmitter.emit(KinesisDataFetcher.java:314)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher$SyncKinesisRecordEmitter$1.put(KinesisDataFetcher.java:331)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher$SyncKinesisRecordEmitter$1.put(KinesisDataFetcher.java:328)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher.emitRecordAndUpdateState(KinesisDataFetcher.java:970)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumer.deserializeRecordForCollectionAndUpdateState(ShardConsumer.java:209)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumer.lambda$run$0(ShardConsumer.java:125)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.publisher.polling.AdaptivePollingRecordPublisher.lambda$run$0(AdaptivePollingRecordPublisher.java:77)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.publisher.polling.PollingRecordPublisher.run(PollingRecordPublisher.java:117)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.publisher.polling.AdaptivePollingRecordPublisher.run(AdaptivePollingRecordPublisher.java:75)\r\n\tat org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumer.run(ShardConsumer.java:113)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\n```",
        "commit_id": "b9e576fb845b817d804da3d68471ff8a4723dcf3",
        "created_at": "2021-04-19T03:47:20Z",
        "updated_at": "2021-04-19T03:50:51Z"
      }
    ]
  },
  "tao-xiao-sn": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/f7d0de611af7c167b261dfc8bfb7f039660b54d7#r51714439",
        "id": 51714439,
        "body": "according to the [implementation](https://github.com/confluentinc/schema-registry/blob/master/client/src/main/java/io/confluent/kafka/schemaregistry/client/CachedSchemaRegistryClient.java#L91)\r\n\r\ncalling below is good enough\r\n```\r\nnew CachedSchemaRegistryClient(url, identityMapCapacity, registryConfigs)\r\n```",
        "commit_id": "f7d0de611af7c167b261dfc8bfb7f039660b54d7",
        "created_at": "2021-06-04T08:28:35Z",
        "updated_at": "2021-06-04T08:28:35Z"
      }
    ]
  },
  "liygzting": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/289e147c489c3d0c28d5ea55c95d2d08b2d781b0#commitcomment-54826311",
        "id": 54826311,
        "body": "hi  @zjuwangg  sbt how to add?",
        "commit_id": "289e147c489c3d0c28d5ea55c95d2d08b2d781b0",
        "created_at": "2021-08-13T05:16:07Z",
        "updated_at": "2021-08-13T05:47:49Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/289e147c489c3d0c28d5ea55c95d2d08b2d781b0#commitcomment-55744950",
        "id": 55744950,
        "body": "thanks @zjuwangg \r\nI add this code in my build.sbt ,that works\r\n`scalacOptions in ThisBuild += \"-target:jvm-1.8\"`",
        "commit_id": "289e147c489c3d0c28d5ea55c95d2d08b2d781b0",
        "created_at": "2021-09-01T02:35:13Z",
        "updated_at": "2021-09-01T02:35:13Z"
      }
    ]
  },
  "zjuwangg": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/289e147c489c3d0c28d5ea55c95d2d08b2d781b0#commitcomment-55637518",
        "id": 55637518,
        "body": "> hi @zjuwangg sbt how to add?\r\n\r\nI haven't digged in it. You can ask questions related to your case in user or dev mailing list.",
        "commit_id": "289e147c489c3d0c28d5ea55c95d2d08b2d781b0",
        "created_at": "2021-08-30T09:40:10Z",
        "updated_at": "2021-08-30T09:40:10Z"
      }
    ]
  },
  "slinkydeveloper": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61417295",
        "id": 61417295,
        "body": "> There's plenty of methods in here for which at this time we do not have corresponding assertj matches;\r\n\r\nBefore merging, we made 100% sure that every matcher here has an alternative in assertj.\r\n\r\n> and why not just migrate the existing usages that use the exception matchers\r\n\r\nLack of time. With the warnings, we're encouraging people to not use these matchers anymore, which is the point of encouraging people to use assertj.",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-06T08:23:56Z",
        "updated_at": "2021-12-06T08:23:56Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61417313",
        "id": 61417313,
        "body": "that's definitely a mistake on my side, sorry, will fix it.",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-06T08:24:30Z",
        "updated_at": "2021-12-06T08:24:30Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0452506b78db6c19a2e234581f2709d69ce516c6#r61417345",
        "id": 61417345,
        "body": "In order to be usable to manually extract the chain of throwables, in case one wants to execute custom assertions on it.",
        "commit_id": "0452506b78db6c19a2e234581f2709d69ce516c6",
        "created_at": "2021-12-06T08:25:25Z",
        "updated_at": "2021-12-06T08:25:25Z"
      }
    ]
  },
  "Jesuitry": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/0fbf88b30d26dc567070f2bd92e5aaa4f24a452d#commitcomment-63683807",
        "id": 63683807,
        "body": "@gyfora \r\nI don't think the Connector's code should be modified in order to obtain the KAKFA field. This will damage the source code a lot, and if there are many Connectors, this work is tedious and unnecessary. Key fields can be obtained through reflection",
        "commit_id": "0fbf88b30d26dc567070f2bd92e5aaa4f24a452d",
        "created_at": "2022-01-12T08:20:59Z",
        "updated_at": "2022-01-12T08:25:46Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/0fbf88b30d26dc567070f2bd92e5aaa4f24a452d#commitcomment-63683976",
        "id": 63683976,
        "body": "@gyfora \r\nObtain the key fields of FlinkKafkaConsumer through reflection without destroying the source code\r\n\r\n` /*\r\n    * @param\r\n    * @param funClass  reflection class\r\n    * @param filedName Get the fields of the reflected class\r\n    * @param <T>       Each field is a different type, encapsulated with generics\r\n    * @return Get the field type the user wants through the reflection class\r\n    * @throws Exception\r\n    * @author dong.yu\r\n    * @function reflection object\r\n    */\r\n    \r\n    public <T> T getFiled(Object function, Class funClass, String filedName) throws Exception {\r\n        Field filed = null;\r\n        try {\r\n            filed = funClass.getDeclaredField(filedName);\r\n            filed.setAccessible(true);\r\n        } catch (NoSuchFieldException e) {\r\n            e.printStackTrace();\r\n            LOG.error(\"getFiled\", e);\r\n        }\r\n        return (T) filed.get(function);\r\n    }\r\n    \r\n    if (functionClass.getName().equals(\"org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer\")) {\r\n        Object topicDescription = getFiled(function, functionClass.getSuperclass(), \"topicsDescriptor\");\r\n        Properties properties = getFiled(function, functionClass, \"properties\");\r\n        Object topics = topicDescription.getClass().getMethod(\"getFixedTopics\").invoke(topicDescription);\r\n    }`",
        "commit_id": "0fbf88b30d26dc567070f2bd92e5aaa4f24a452d",
        "created_at": "2022-01-12T08:24:46Z",
        "updated_at": "2022-01-12T08:25:36Z"
      }
    ]
  },
  "dmvk": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/dd6069fabf8a7ff65fbd9ff8dd7b0c47f492288f#r64314959",
        "id": 64314959,
        "body": "@tillrohrmann Should this really be treated as a failure?",
        "commit_id": "dd6069fabf8a7ff65fbd9ff8dd7b0c47f492288f",
        "created_at": "2022-01-21T10:45:13Z",
        "updated_at": "2022-01-21T10:45:13Z"
      }
    ]
  },
  "matriv": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/d9d72ef142a2343f37b8b10ca6e04dc7f6ca086e#r65922128",
        "id": 65922128,
        "body": "didn't know of that, I will fix it\r\n",
        "commit_id": "d9d72ef142a2343f37b8b10ca6e04dc7f6ca086e",
        "created_at": "2022-02-03T08:39:14Z",
        "updated_at": "2022-02-03T08:39:14Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/d9d72ef142a2343f37b8b10ca6e04dc7f6ca086e#r65922141",
        "id": 65922141,
        "body": "many thx for catching it",
        "commit_id": "d9d72ef142a2343f37b8b10ca6e04dc7f6ca086e",
        "created_at": "2022-02-03T08:39:29Z",
        "updated_at": "2022-02-03T08:39:29Z"
      }
    ]
  },
  "martin-g": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/89ba5b185d841a7ca477db1e60c2b96d007085b1#r71270251",
        "id": 71270251,
        "body": "No need of `.toString()`. Actually it is recommended to avoid it when using SLF4J placeholders (`{}`).",
        "commit_id": "89ba5b185d841a7ca477db1e60c2b96d007085b1",
        "created_at": "2022-04-14T10:51:26Z",
        "updated_at": "2022-04-14T10:51:26Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3dca1fae493170e5cd0128670b3e78d435d003c6#r71271215",
        "id": 71271215,
        "body": "What is the reason for these new configs ?\r\nI think you could use https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/config/#kubernetes-jobmanager-annotations and https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/config/#kubernetes-taskmanager-annotations",
        "commit_id": "3dca1fae493170e5cd0128670b3e78d435d003c6",
        "created_at": "2022-04-14T11:08:05Z",
        "updated_at": "2022-04-14T11:08:05Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3dca1fae493170e5cd0128670b3e78d435d003c6#r71271314",
        "id": 71271314,
        "body": "The last two lines are not really needed.",
        "commit_id": "3dca1fae493170e5cd0128670b3e78d435d003c6",
        "created_at": "2022-04-14T11:09:28Z",
        "updated_at": "2022-04-14T11:09:28Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3dca1fae493170e5cd0128670b3e78d435d003c6#r71271327",
        "id": 71271327,
        "body": "Ditto",
        "commit_id": "3dca1fae493170e5cd0128670b3e78d435d003c6",
        "created_at": "2022-04-14T11:09:35Z",
        "updated_at": "2022-04-14T11:09:35Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3dca1fae493170e5cd0128670b3e78d435d003c6#r71271402",
        "id": 71271402,
        "body": "In Spark the preference was to use the [PodTemplate](https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/config/#kubernetes-pod-template-file) instead of adding extra config settings and logic in the code.",
        "commit_id": "3dca1fae493170e5cd0128670b3e78d435d003c6",
        "created_at": "2022-04-14T11:10:59Z",
        "updated_at": "2022-04-14T11:10:59Z"
      }
    ]
  },
  "liujingmao": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/f9ba9d10f53515d904680327ea4bbd07a9e3bfab#commitcomment-81401247",
        "id": 81401247,
        "body": "good job",
        "commit_id": "f9ba9d10f53515d904680327ea4bbd07a9e3bfab",
        "created_at": "2022-08-17T09:26:28Z",
        "updated_at": "2022-08-17T09:26:28Z"
      }
    ]
  },
  "XComp": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/cb442936156583d6cf42550f3d9187da427b9c68#r88179355",
        "id": 88179355,
        "body": "Good point. I could have do a more thorough check of the docs. Thanks for reviewing it. I'm gonna provide another hotfix PR",
        "commit_id": "cb442936156583d6cf42550f3d9187da427b9c68",
        "created_at": "2022-10-28T11:24:55Z",
        "updated_at": "2022-10-28T11:25:12Z"
      }
    ]
  },
  "HuangXingBo": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/87c33711fa3a4844598772ceafd66dd4a776eea9#commitcomment-88275029",
        "id": 88275029,
        "body": "@zentol Thanks for the hotfix. Sorry for the inconvenience. \r\n",
        "commit_id": "87c33711fa3a4844598772ceafd66dd4a776eea9",
        "created_at": "2022-10-29T13:20:04Z",
        "updated_at": "2022-10-29T13:20:04Z"
      }
    ]
  },
  "gaborgsomogyi": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/278d28edbfbcbaff630bc73bd8a9e0691fd2863a#r93530621",
        "id": 93530621,
        "body": "+1, this provides better understanding what is the intention.",
        "commit_id": "278d28edbfbcbaff630bc73bd8a9e0691fd2863a",
        "created_at": "2022-12-19T10:19:33Z",
        "updated_at": "2022-12-19T10:19:33Z"
      }
    ]
  },
  "ramkrish86": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/06435cec2e510d0592e8ad868a1d0ea3e83c1b35#r96464347",
        "id": 96464347,
        "body": "Thanks @Xingtonsong. This should be 'ABFS'.",
        "commit_id": "06435cec2e510d0592e8ad868a1d0ea3e83c1b35",
        "created_at": "2023-01-17T10:17:17Z",
        "updated_at": "2023-01-17T10:17:17Z"
      }
    ]
  },
  "snuyanzin": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/99ff3ae89bde4999a0c3cd1e96eefe24e80f15ad#r100989492",
        "id": 100989492,
        "body": "`Aggregate.indicator` was deprecated at https://issues.apache.org/jira/browse/CALCITE-2944\r\nMoreover it's always false\r\nhttps://github.com/apache/calcite/blob/cd5229b9a371e20de207231d55bcbddf1ff39ec2/core/src/main/java/org/apache/calcite/rel/core/Aggregate.java#L111-L112",
        "commit_id": "99ff3ae89bde4999a0c3cd1e96eefe24e80f15ad",
        "created_at": "2023-02-17T08:45:02Z",
        "updated_at": "2023-02-17T08:45:22Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/99ff3ae89bde4999a0c3cd1e96eefe24e80f15ad#r100990414",
        "id": 100990414,
        "body": "Current call of `LogicalAggregate#create` https://github.com/apache/calcite/blob/cd5229b9a371e20de207231d55bcbddf1ff39ec2/core/src/main/java/org/apache/calcite/rel/logical/LogicalAggregate.java#L87-L91 is identical to this one with empty hint list https://github.com/apache/calcite/blob/cd5229b9a371e20de207231d55bcbddf1ff39ec2/core/src/main/java/org/apache/calcite/rel/logical/LogicalAggregate.java#L64-L73",
        "commit_id": "99ff3ae89bde4999a0c3cd1e96eefe24e80f15ad",
        "created_at": "2023-02-17T08:54:10Z",
        "updated_at": "2023-02-17T08:54:10Z"
      }
    ]
  },
  "wangfanming": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/f3fec9e543c71fed1f6006e9410d17848c7cfdeb#commitcomment-120830922",
        "id": 120830922,
        "body": "\r\nThe EventType class and User class already exist in the source code, but there is a related class schema file user.avsc in the resources/avro directory. Additionally, the avro-maven-plugin is not removed from the pom.xml file. This can lead to a \"class duplication\" error during compilation of the source code.",
        "commit_id": "f3fec9e543c71fed1f6006e9410d17848c7cfdeb",
        "created_at": "2023-07-06T14:06:36Z",
        "updated_at": "2023-07-06T14:06:36Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/f3fec9e543c71fed1f6006e9410d17848c7cfdeb#r120831427",
        "id": 120831427,
        "body": "\u8bf7\u79fb\u9664avro-maven-plugin\u63d2\u4ef6\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u63d2\u4ef6\u4f1a\u5bfc\u81f4resources/avro/user.avsc\u751f\u6210\u7684\u7c7b\u4e0e\u6e90\u7801\u91cc\u7684\u7c7b\u91cd\u590d\uff0c\u5bfc\u81f4mvn\u7f16\u8bd1\u51fa\u9519\u3002\u540c\u6837\u7684\u95ee\u9898\u8fd8\u51fa\u73b0\u5728flink-formats\u6a21\u5757\u91cc\u3002",
        "commit_id": "f3fec9e543c71fed1f6006e9410d17848c7cfdeb",
        "created_at": "2023-07-06T14:10:56Z",
        "updated_at": "2023-07-06T14:10:56Z"
      }
    ]
  },
  "davidradl": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/6d62f9918ea2cbb8a10c705a25a4ff6deab60711#commitcomment-128732026",
        "id": 128732026,
        "body": "This is now fixed in master https://github.com/apache/flink/commit/6d62f9918ea2cbb8a10c705a25a4ff6deab60711 . I suggest this is closed ",
        "commit_id": "6d62f9918ea2cbb8a10c705a25a4ff6deab60711",
        "created_at": "2023-09-29T14:32:38Z",
        "updated_at": "2023-09-29T14:32:38Z"
      }
    ]
  },
  "Tao-Zhang9876": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/ad2ae8ab6047a4b694b169e05566827e7cbc431c#commitcomment-132285473",
        "id": 132285473,
        "body": "Hello there,\r\nI just fixed the bug of issue id [FLINK-33524](https://issues.apache.org/jira/browse/FLINK-33524) where i just mentioned on website\r\n \r\ntao zhang,\r\nMany thanks",
        "commit_id": "ad2ae8ab6047a4b694b169e05566827e7cbc431c",
        "created_at": "2023-11-11T04:09:05Z",
        "updated_at": "2023-11-11T04:09:05Z"
      }
    ]
  },
  "singhravidutt": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/7c609007959cfdc2d3e6bd9634c1576b437a611a#r135097791",
        "id": 135097791,
        "body": "isn't that risky, given it's a common module and someone might be dependent on guava getting provided from shaded jar?",
        "commit_id": "7c609007959cfdc2d3e6bd9634c1576b437a611a",
        "created_at": "2023-12-15T16:15:53Z",
        "updated_at": "2023-12-15T16:15:53Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/7c609007959cfdc2d3e6bd9634c1576b437a611a#r135097902",
        "id": 135097902,
        "body": "what about other modules whcih guava pulls in i.e. `checkerframework`, `j2objc` etc?",
        "commit_id": "7c609007959cfdc2d3e6bd9634c1576b437a611a",
        "created_at": "2023-12-15T16:17:17Z",
        "updated_at": "2023-12-15T16:17:17Z"
      }
    ]
  },
  "reswqa": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/439d1091daa12803268bb8ff7c0642bcc5f9127c#r137411250",
        "id": 137411250,
        "body": "No,  it's not necessary. Fix is coming.",
        "commit_id": "439d1091daa12803268bb8ff7c0642bcc5f9127c",
        "created_at": "2024-01-19T05:34:50Z",
        "updated_at": "2024-01-19T05:34:50Z"
      }
    ]
  },
  "masteryhx": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/3a957ff549517b8d356881da306ea5d59a04ee36#r141100318",
        "id": 141100318,
        "body": "nit: Also describe UK",
        "commit_id": "3a957ff549517b8d356881da306ea5d59a04ee36",
        "created_at": "2024-04-18T07:51:52Z",
        "updated_at": "2024-04-18T07:52:11Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3a957ff549517b8d356881da306ea5d59a04ee36#r141100345",
        "id": 141100345,
        "body": "ValueState -> MapState",
        "commit_id": "3a957ff549517b8d356881da306ea5d59a04ee36",
        "created_at": "2024-04-18T07:53:06Z",
        "updated_at": "2024-04-18T07:53:06Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3a957ff549517b8d356881da306ea5d59a04ee36#r141100539",
        "id": 141100539,
        "body": "-> for the user key ?",
        "commit_id": "3a957ff549517b8d356881da306ea5d59a04ee36",
        "created_at": "2024-04-18T08:00:51Z",
        "updated_at": "2024-04-18T08:00:51Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/3a957ff549517b8d356881da306ea5d59a04ee36#r141100619",
        "id": 141100619,
        "body": "Could this be extracted to a test util since it's used in both `InternalKeyedStateTestBase` and `AsyncExecutionControllerTest` ?",
        "commit_id": "3a957ff549517b8d356881da306ea5d59a04ee36",
        "created_at": "2024-04-18T08:04:03Z",
        "updated_at": "2024-04-18T08:04:03Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/72c02daa23fa5ce5fab282f54e94df1b0f56af63#r141102943",
        "id": 141102943,
        "body": "StateDescriptor<T> -> StateDescriptor<List<T>>",
        "commit_id": "72c02daa23fa5ce5fab282f54e94df1b0f56af63",
        "created_at": "2024-04-18T09:10:20Z",
        "updated_at": "2024-04-18T09:10:20Z"
      },
      {
        "html_url": "https://github.com/apache/flink/commit/72c02daa23fa5ce5fab282f54e94df1b0f56af63#r141102972",
        "id": 141102972,
        "body": "Wrap with ListSerializer ?",
        "commit_id": "72c02daa23fa5ce5fab282f54e94df1b0f56af63",
        "created_at": "2024-04-18T09:11:36Z",
        "updated_at": "2024-04-18T09:11:36Z"
      }
    ]
  },
  "slankka": {
    "commit_comments": [
      {
        "html_url": "https://github.com/apache/flink/commit/a0227e20430ee9eaff59464023de2385378f71ea#r145401620",
        "id": 145401620,
        "body": "Why change this, it will cause\r\nhttps://issues.apache.org/jira/browse/FLINK-29797\r\n\r\nand please be aware of that similar code below is correct.\r\n```\r\nnew Path(tmpJobGraphFile.toURI()),\r\n```\r\n",
        "commit_id": "a0227e20430ee9eaff59464023de2385378f71ea",
        "created_at": "2024-08-15T02:11:47Z",
        "updated_at": "2024-08-15T02:25:14Z"
      }
    ]
  }
}